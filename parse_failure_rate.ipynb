{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import io\n",
    "import shutil\n",
    "import TexSoup\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to .tar.gz files\n",
    "LOCAL_DATA_PATH = \"./data\"\n",
    "LOCAL_FILE_PATH = \"2201_01_all\"\n",
    "LOCAL_GAR_PATH = os.path.join(LOCAL_DATA_PATH, LOCAL_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "# pretty print all cell's output and not just the last one\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directly written here because parse_bad_file.py syntax has issues\n",
    "def pre_format(text):\n",
    "    '''Apply some substititions to make LaTeX easier to parse'''\n",
    "    source_text = (\n",
    "        text\n",
    "        .replace('\\\\}\\\\', '\\\\} \\\\')  # Due to escape rules \\\\ is equivalent to \\\n",
    "        .replace(')}', ') }')\n",
    "        .replace(')$', ') $')\n",
    "    )\n",
    "    return source_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_main_tex_source(path):\n",
    "    # assuming path is a directory containing unzipped tex source etc\n",
    "    tex_files = [f for f in os.listdir(path) if f.endswith('.tex')]\n",
    "    if len(tex_files) == 1:\n",
    "        return(os.path.join(path, tex_files[0]))\n",
    "    else:\n",
    "        main_files = {}\n",
    "        for tf in tex_files:\n",
    "            file = open(os.path.join(path, tf), \"r\")\n",
    "            for line in file:\n",
    "                if re.search(r\"^\\s*\\\\document(?:style|class)\", line):\n",
    "                    # https://arxiv.org/help/faq/mistakes#wrongtex\n",
    "                    # according to this page, there should only be one tex file with a \\documentclass - the main file ?\n",
    "                    if tf == \"paper.tex\" or tf == \"main.tex\" or tf == \"ms.tex\" or tf == \"article.tex\":\n",
    "                        main_files[tf] = 1\n",
    "                    else:\n",
    "                        main_files[tf] = 0\n",
    "                    break\n",
    "            file.close\n",
    "        if len(main_files) == 1:\n",
    "           return(os.path.join(path, list(main_files)[0]))\n",
    "        else:\n",
    "            # account for the two main ways of creating multi-file submissions on overleaf (standalone, subfiles)\n",
    "            for mf in main_files:\n",
    "                file = open(os.path.join(path, mf), \"r\")\n",
    "                for line in file:\n",
    "                    if re.search(r\"^\\s*\\\\document(?:style|class).*(?:\\{standalone\\}|\\{subfiles\\})\", line):\n",
    "                        main_files[mf] = -99999\n",
    "                        break\n",
    "                        # document class of main should not be standalone or subfiles (the main file is just {article} or something else)\n",
    "                file.close\n",
    "            return(os.path.join(path, max(main_files, key=main_files.get)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncompress all .tar.gz files and get all tex files\n",
    "LOCAL_TEX_PATH = os.path.join(LOCAL_DATA_PATH, LOCAL_FILE_PATH+\"_tex\")\n",
    "\n",
    "for file_name in os.listdir(LOCAL_GAR_PATH):\n",
    "    path = os.path.join(LOCAL_GAR_PATH, file_name)\n",
    "    if tarfile.is_tarfile(path):        # .tar.gz check to avoid error\n",
    "        file = tarfile.open(path, \"r\")\n",
    "        for name in file.getnames():\n",
    "            if name.endswith(\".tex\"):   # tex file check\n",
    "                if not os.path.exists(LOCAL_TEX_PATH):      # tex folder check\n",
    "                    os.mkdir(LOCAL_TEX_PATH)\n",
    "                sub_tex_path = os.path.join(LOCAL_TEX_PATH, file_name.strip(\".tar.gz\"))\n",
    "                if not os.path.exists(sub_tex_path):       # sub tex folder check\n",
    "                    os.mkdir(sub_tex_path)\n",
    "                file.extract(name, sub_tex_path)       # tex file extraction\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2201.01576v2', '2201.01228v3', '2201.01829v2', '2201.01287v1', '2201.01797v2', '2201.01120v1', '2201.01064v1', '2201.01840v1', '2201.01823v2', '2201.01778v2', '2201.01324v1', '2201.01347v2', '2201.01322v3', '2201.01734v1', '2201.01360v1', '2201.01804v1', '2201.01020v2', '2201.01888v1', '2201.01538v2', '2201.01105v2', '2201.01551v1', '2201.01415v2', '2201.01385v4', '2201.01925v1', '2201.01222v2', '2201.01305v1', '2201.01389v4', '2201.01411v1', '2201.01886v1', '2201.01026v2', '2201.01228v3', '2201.01364v1', '2201.01385v4', '2201.01264v1', '2201.01320v1', '2201.01774v1', '2201.01385v4', '2201.01511v1', '2201.01289v1', '2201.01341v1', '2201.01322v3', '2201.01961v1', '2201.01825v1', '2201.01902v2', '2201.01812v3', '2201.01871v2', '2201.01741v1', '2201.01666v2', '2201.01251v2', '2201.01647v3', '2201.01689v2', '2201.01810v1', '2201.01664v2', '2201.01683v1', '2201.01424v1', '2201.01070v1', '2201.01549v3', '2201.01293v6', '2201.01330v1', '2201.01274v1', '2201.01353v2', '2201.01620v1', '2201.01764v1', '2201.01854v1', '2201.01293v6', '2201.01996v2', '2201.01501v2', '2201.01445v2', '2201.01351v1', '2201.01215v1', '2201.01641v1', '2201.01441v1', '2201.01015v1', '2201.01151v1', '2201.01831v1', '2201.01211v1', '2201.01589v1', '2201.01787v1', '2201.01074v1', '2201.01130v2', '2201.01583v1', '2201.01812v3', '2201.01334v1', '2201.01647v3', '2201.01760v1', '2201.01724v1', '2201.01370v1', '2201.01933v2', '2201.01877v2', '2201.01898v2', '2201.01687v1', '2201.01397v1', '2201.01601v1', '2201.01489v1', '2201.01199v1', '2201.01931v1', '2201.01875v1', '2201.01892v1', '2201.01405v1', '2201.01549v3', '2201.01490v1', '2201.01308v1', '2201.01920v2', '2201.01227v1', '2201.01498v2', '2201.01384v1', '2201.01048v2', '2201.01533v1', '2201.01369v1', '2201.01246v1', '2201.01302v2', '2201.01225v3', '2201.01756v1', '2201.01029v1', '2201.01539v1', '2201.01552v1', '2201.01981v2', '2201.01656v2', '2201.01849v1', '2201.01346v1', '2201.01202v2', '2201.01905v2', '2201.01779v1', '2201.01577v1', '2201.01458v1', '2201.01794v1', '2201.01344v2', '2201.01200v2', '2201.01773v1', '2201.01327v2', '2201.01263v1', '2201.01080v2', '2201.01907v1', '2201.01790v1', '2201.01000v2', '2201.01348v1', '2201.01084v1', '2201.01594v1', '2201.01225v3', '2201.01777v2', '2201.01267v1', '2201.01650v2', '2201.01985v1', '2201.01329v1', '2201.01652v1', '2201.01775v2', '2201.01809v1', '2201.01862v1', '2201.01161v2', '2201.01885v1', '2201.01471v2', '2201.01102v1', '2201.01382v2', '2201.01367v3', '2201.01677v1', '2201.01758v4', '2201.01248v1', '2201.01537v3', '2201.01163v1', '2201.01780v1', '2201.01508v1', '2201.01018v1', '2201.01073v1', '2201.01427v1', '2201.01648v1', '2201.01704v2', '2201.01079v2', '2201.01339v1', '2201.01629v1', '2201.01216v2', '2201.01352v2', '2201.01316v1', '2201.01742v1', '2201.01811v2', '2201.01895v1', '2201.01546v1', '2201.01014v3', '2201.01112v1', '2201.01682v2', '2201.01604v2', '2201.01377v4', '2201.01625v3', '2201.01813v1', '2201.01194v2', '2201.01463v1', '2201.01390v2', '2201.01680v1', '2201.01817v1', '2201.01953v1', '2201.01608v1', '2201.01480v1', '2201.01373v1', '2201.01938v1', '2201.01663v2', '2201.01394v1', '2201.01540v2', '2201.01893v2', '2201.01033v1', '2201.01379v1', '2201.01256v1', '2201.01602v1', '2201.01116v2', '2201.01565v2', '2201.01016v1', '2201.01991v1', '2201.01131v2', '2201.01506v1', '2201.01859v3', '2201.01625v3', '2201.01440v2', '2201.01014v3', '2201.01763v2', '2201.01838v1', '2201.01337v2', '2201.01580v1', '2201.01708v1', '2201.01020v2', '2201.01538v2', '2201.01303v1', '2201.01613v1', '2201.01476v1', '2201.01105v2', '2201.01022v1', '2201.01415v2', '2201.01385v4', '2201.01842v1', '2201.01636v1', '2201.01829v2', '2201.01262v1', '2201.01459v1', '2201.01149v1', '2201.01576v2', '2201.01823v2', '2201.01778v2', '2201.01389v4', '2201.01848v1', '2201.01347v2', '2201.01203v1', '2201.01438v1', '2201.01797v2', '2201.01453v1', '2201.01980v1', '2201.01389v4', '2201.01908v1', '2201.01207v1', '2201.01328v1', '2201.01638v1', '2201.01513v1', '2201.01578v1', '2201.01632v1', '2201.01776v1', '2201.01322v3', '2201.01902v2', '2201.01062v1', '2201.01472v1', '2201.01389v4', '2201.01026v2', '2201.01946v1', '2201.01222v2', '2201.01366v1', '2201.01676v1', '2201.01413v1', '2201.01884v1', '2201.01103v1', '2201.01863v1', '2201.01643v1', '2201.01918v1', '2201.01217v1', '2201.01353v2', '2201.01628v1', '2201.01293v6', '2201.01157v1', '2201.01994v1', '2201.01134v3', '2201.01503v1', '2201.01293v6', '2201.01568v1', '2201.01622v1', '2201.01649v1', '2201.01856v1', '2201.01136v1', '2201.01996v2', '2201.01445v2', '2201.01501v2', '2201.01562v1', '2201.01781v1', '2201.01291v1', '2201.01391v1', '2201.01409v1', '2201.01526v1', '2201.01896v2', '2201.01689v2', '2201.01749v1', '2201.01812v3', '2201.01956v1', '2201.01871v2', '2201.01232v1', '2201.01666v2', '2201.01722v1', '2201.01251v2', '2201.01547v1', '2201.01113v1', '2201.01873v1', '2201.01664v2', '2201.01117v1', '2201.01898v2', '2201.01038v1', '2201.01257v1', '2201.01877v2', '2201.01933v2', '2201.01378v1', '2201.01134v3', '2201.01395v1', '2201.01549v3', '2201.01293v6', '2201.01726v1', '2201.01293v6', '2201.01481v1', '2201.01609v1', '2201.01319v1', '2201.01581v1', '2201.01839v1', '2201.01336v1', '2201.01422v1', '2201.01647v3', '2201.01357v1', '2201.01443v1', '2201.01130v2', '2201.01656v2', '2201.01261v1', '2201.01202v2', '2201.01635v1', '2201.01367v3', '2201.01905v2', '2201.01841v1', '2201.01758v4', '2201.01431v1', '2201.01981v2', '2201.01537v3', '2201.01758v4', '2201.01200v2', '2201.01344v2', '2201.01598v1', '2201.01327v2', '2201.01080v2', '2201.01820v1', '2201.01514v1', '2201.01140v1', '2201.01048v2', '2201.01040v1', '2201.01920v2', '2201.01498v2', '2201.01754v1', '2201.01165v1', '2201.01302v2', '2201.01225v3', '2201.01161v2', '2201.01471v2', '2201.01692v1', '2201.01382v2', '2201.01675v1', '2201.01365v1', '2201.01221v1', '2201.01537v3', '2201.01044v1', '2201.01887v1', '2201.01554v1', '2201.01614v1', '2201.01750v1', '2201.01367v3', '2201.01758v4', '2201.01924v1', '2201.01960v1', '2201.01777v2', '2201.01340v1', '2201.01650v2', '2201.01144v1', '2201.01000v2', '2201.01901v1', '2201.01845v1', '2201.01086v1', '2201.01265v1', '2201.01775v2', '2201.01435v1', '2201.01061v1', '2201.01461v1', '2201.01682v2', '2201.01392v1', '2201.01811v2', '2201.01110v1', '2201.01688v1', '2201.01400v1', '2201.01390v2', '2201.01604v2', '2201.01377v4', '2201.01859v3', '2201.01194v2', '2201.01970v1', '2201.01704v2', '2201.01788v1', '2201.01352v2', '2201.01216v2', '2201.01782v1', '2201.01079v2', '2201.01859v3', '2201.01625v3', '2201.01377v4', '2201.01582v1', '2201.01092v1', '2201.01565v2', '2201.01377v4', '2201.01421v1', '2201.01131v2', '2201.01296v1', '2201.01786v1', '2201.01763v2', '2201.01644v1', '2201.01337v2', '2201.01974v1', '2201.01504v1', '2201.01440v2', '2201.01014v3', '2201.01050v1', '2201.01540v2', '2201.01893v2', '2201.01663v2', '2201.01310v1', '2201.01116v2', '2201.01521v1', '2201.01669v2', '2201.01815v1']\n"
     ]
    }
   ],
   "source": [
    "# remove earlier version of articles\n",
    "# shuold probably do it before uncompression, will reformat in the future if needed\n",
    "file_list = []\n",
    "for file in os.listdir(LOCAL_TEX_PATH):\n",
    "    r = re.compile(\"^\"+file[:-1]+\"\\d+$\")\n",
    "    file_list.append(file[:-1]+max([f[-1] for f in filter(r.match, os.listdir(LOCAL_TEX_PATH))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all main tex files\n",
    "# bit a of dumb way to do it, but works for now\n",
    "# shutil.copy seemingly always print out copy results\n",
    "LOCAL_MAIN_TEX_PATH = os.path.join(LOCAL_DATA_PATH, LOCAL_FILE_PATH+\"_main_tex\")\n",
    "for folder_name in file_list:\n",
    "    if not os.path.exists(LOCAL_MAIN_TEX_PATH):\n",
    "        os.mkdir(LOCAL_MAIN_TEX_PATH)\n",
    "    main_tex_file_path = find_main_tex_source(os.path.join(LOCAL_TEX_PATH, folder_name))\n",
    "    main_tex_sub_folder_path = os.path.join(LOCAL_MAIN_TEX_PATH, folder_name)\n",
    "    if not os.path.exists(main_tex_sub_folder_path):\n",
    "        os.mkdir(main_tex_sub_folder_path)\n",
    "    shutil.copy(main_tex_file_path, main_tex_sub_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='./data/2201_01_all_main_tex/2201.01576v2/KitaevTable_v8.tex' encoding='utf-8'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't concat str to bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-fe9ecfa7a72a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mwrapped_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextIOWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_tex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# universal newlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#         source_text = pre_format(wrapped_file.read())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#         try:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't concat str to bytes"
     ]
    }
   ],
   "source": [
    "# parse main tex files\n",
    "import logging\n",
    "import traceback\n",
    "\n",
    "exception_ct = 0\n",
    "for folder in os.listdir(LOCAL_MAIN_TEX_PATH):\n",
    "    for file in os.listdir(os.path.join(LOCAL_MAIN_TEX_PATH, folder)):\n",
    "        with open(os.path.join(LOCAL_MAIN_TEX_PATH, folder, file), \"r\") as in_tex:\n",
    "            # in_tex = open(os.path.join(LOCAL_MAIN_TEX_PATH, folder, file), \"r\")\n",
    "            wrapped_file = io.TextIOWrapper(in_tex, newline=None, encoding=\"utf-8\") # universal newlines\n",
    "            print(wrapped_file)\n",
    "            print(wrapped_file.read())\n",
    "#         source_text = pre_format(wrapped_file.read())\n",
    "#         try: \n",
    "#             soup = TexSoup.TexSoup(source_text)\n",
    "#         except Exception as e: \n",
    "#             exception_ct += 1\n",
    "#             # logging.error(traceback.format_exc())\n",
    "# print(exception_ct)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
