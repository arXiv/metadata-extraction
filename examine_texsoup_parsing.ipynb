{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5385a6ff-0507-42ae-8ed7-090bc79688be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/chrisjcameron/TexSoup.git@nested-math\n",
      "  Cloning https://github.com/chrisjcameron/TexSoup.git (to revision nested-math) to /private/var/folders/c3/ngb99f4x0mjgbx34rbsw18x40000gn/T/pip-req-build-ehc5orj5\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/chrisjcameron/TexSoup.git /private/var/folders/c3/ngb99f4x0mjgbx34rbsw18x40000gn/T/pip-req-build-ehc5orj5\n",
      "  Running command git checkout -b nested-math --track origin/nested-math\n",
      "  Switched to a new branch 'nested-math'\n",
      "  branch 'nested-math' set up to track 'origin/nested-math'.\n",
      "  Resolved https://github.com/chrisjcameron/TexSoup.git to commit e7f05893d62ec6457173b6b6cc5a8d62f82682b9\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: TexSoup\n",
      "  Building wheel for TexSoup (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for TexSoup: filename=TexSoup-0.3.1-py3-none-any.whl size=30272 sha256=b506f8cbfe38cf5088656cd48f377886ae6d2b8d0b44a3479b6671f5f6b06fe7\n",
      "  Stored in directory: /private/var/folders/c3/ngb99f4x0mjgbx34rbsw18x40000gn/T/pip-ephem-wheel-cache-ffme6fu4/wheels/f6/86/9e/70d7a9c1623dba993a9ccf7adac66c99fe9e9fdbb3d3bc18b6\n",
      "Successfully built TexSoup\n",
      "Installing collected packages: TexSoup\n",
      "  Attempting uninstall: TexSoup\n",
      "    Found existing installation: TexSoup 0.3.1\n",
      "    Uninstalling TexSoup-0.3.1:\n",
      "      Successfully uninstalled TexSoup-0.3.1\n",
      "Successfully installed TexSoup-0.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --force-reinstall --no-deps git+https://github.com/chrisjcameron/TexSoup.git@nested-math\n",
    "#! pip install --editable /Users/cjc73/gits/arxiv/TexSoup/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cf5d0dc-f846-4026-973f-fc35f5488c1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import zipfile\n",
    "import tarfile\n",
    "import io\n",
    "import importlib\n",
    "import os\n",
    "import regex as re\n",
    "import glob\n",
    "import pandas as pd\n",
    "import itertools as itr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8e8fd8a-40da-4c8b-b4a5-2a9e753c85eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyperclip   #copy text to clipboard for inspecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9229d15f-0f9a-46fb-8de4-2e6bc4f31736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d172ce28-bd35-4aa2-b7e9-0566d744ae17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "# pretty print all cell's output and not just the last one\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0482c820-371e-4b81-a97c-2f10cd5fd72f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import TexSoup as TS\n",
    "from TexSoup.tokens import MATH_ENV_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6458ec55-853e-4571-a3c4-f075d15a67d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/cjc73/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/__init__.py'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TS.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b6edafa-3ecb-4b38-b727-d26d6696235d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importlib.reload(TS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5171153-1316-4310-9251-ee1627762470",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pre_format(text):\n",
    "    '''Apply some substititions to make LaTeX easier to parse'''\n",
    "    source_text = (\n",
    "        text\n",
    "        .replace('\\\\}\\\\', '\\\\} \\\\')  # Due to escape rules \\\\ is equivalent to \\\n",
    "        .replace(')}', ') }')\n",
    "        .replace(')$', ') $')\n",
    "        #.replace(r'\\left [', r'\\left[ ')\n",
    "        #.replace(r'\\left (', r'\\left( ')\n",
    "        #.replace(r'\\left \\{', r'\\left\\{ ')\n",
    "    )\n",
    "    return source_text\n",
    "    #clean_lines = []\n",
    "    #for line in source_text.splitlines(False):\n",
    "    #    cleanline = line.strip()\n",
    "    #    if cleanline.startswith(r'\\newcommand'):\n",
    "    #        cleanline = r'%' + cleanline\n",
    "    #    elif cleanline.startswith(r'\\def'):\n",
    "    #        cleanline = r'%' + cleanline\n",
    "    #    clean_lines.append(cleanline)\n",
    "    #return '\\n'.join(clean_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6324bc82-02a7-4032-b3e5-de19e751be34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_doc_class(wrapped_file, name_match=False):\n",
    "    '''Search for document class related lines in a file  and return a code to represent the type'''\n",
    "    doc_class_pat = re.compile(r\"^\\s*\\\\document(?:style|class)\")\n",
    "    sub_doc_class = re.compile(r\"^\\s*\\\\document(?:style|class).*(?:\\{standalone\\}|\\{subfiles\\})\")\n",
    "\n",
    "    for line in wrapped_file:\n",
    "        if doc_class_pat.search(line):\n",
    "            if name_match:\n",
    "                # we can miss if there are two or more lines with documentclass \n",
    "                # and the first one is not the one that has standalone/subfile\n",
    "                if sub_doc_class.search(line):\n",
    "                    return -99999\n",
    "                return 1 #main_files[tf] = 1\n",
    "            \n",
    "    return 0 #main_files[tf] = 0\n",
    "\n",
    "\n",
    "def find_main_tex_source_in_tar(tar_path, encoding='uft-8'):\n",
    "    '''Identify the main Tex file in a tarfile.\n",
    "    \n",
    "    Args:\n",
    "        tar_path: A gzipped tar archive of a directory containing tex source and support files.\n",
    "    '''\n",
    "    \n",
    "    tex_names = set([\"paper\", \"main\", \"ms.\", \"article\"])\n",
    "\n",
    "    with tarfile.open(tar_path, 'r') as in_tar:\n",
    "        tex_files = [f for f in in_tar.getnames() if f.endswith('.tex')]\n",
    "        \n",
    "        # got one file\n",
    "        if len(tex_files) == 1:\n",
    "            return tex_files[0]\n",
    "\n",
    "        main_files = {}\n",
    "        for tf in tex_files:\n",
    "            depth = len(tf.split('/')) - 1\n",
    "            has_main_name = any(kw in tf for kw in tex_names)\n",
    "            fp = in_tar.extractfile(tf)\n",
    "            wrapped_file = io.TextIOWrapper(fp, newline=None, encoding=encoding) #universal newlines\n",
    "            # does it have a doc class?\n",
    "            # get the type\n",
    "            main_files[tf] = find_doc_class(wrapped_file, name_match = has_main_name) - depth \n",
    "            wrapped_file.close() \n",
    "        \n",
    "        # got one file with doc class\n",
    "        if len(main_files) == 1:\n",
    "            return(main_files.keys()[0])\n",
    "        \n",
    "        # account for multi-file submissions\n",
    "        return(max(main_files, key=main_files.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ae8ad8b-8fdd-45f0-92c2-70075213f2d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def soup_from_tar(tar_path, encoding='utf-8', tolerance=0):\n",
    "    tex_main = find_main_tex_source_in_tar(tar_path, encoding=encoding)\n",
    "    with tarfile.open(tar_path, 'r') as in_tar:\n",
    "        fp = in_tar.extractfile(tex_main)\n",
    "        wrapped_file = io.TextIOWrapper(fp, newline=None, encoding=encoding) #universal newlines\n",
    "        source_text = pre_format(wrapped_file.read())\n",
    "        soup = TS.TexSoup(source_text, tolerance=tolerance, skip_envs=MATH_ENV_NAMES)\n",
    "        return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2720a35-9ddd-487d-8c83-ea8e41b6e5cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def source_from_tar(tar_path, encoding='utf-8'):\n",
    "    tex_main = find_main_tex_source_in_tar(tar_path, encoding=encoding)\n",
    "    with tarfile.open(tar_path, 'r') as in_tar:\n",
    "        fp = in_tar.extractfile(tex_main)\n",
    "        wrapped_file = io.TextIOWrapper(fp, newline=None, encoding=encoding) #universal newlines\n",
    "        source_text = pre_format(wrapped_file.read())\n",
    "        return source_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c08ab516-5348-44a0-9f83-2ffc2ab73f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "swap = itr.cycle([True, False])\n",
    "\n",
    "def find_bad(current_text_lines):\n",
    "    mid = int(len(current_text_lines)/2)\n",
    "    part_a = current_text_lines[0:mid]\n",
    "    part_b = current_text_lines[mid:]\n",
    "    if next(swap):\n",
    "        part_b, part_a = part_a, part_b\n",
    "    bad = \"\"\n",
    "    try:\n",
    "        soup = TS.TexSoup(\"\\n\".join(part_a), tolerance=tolerance, skip_envs=MATH_ENV_NAMES)\n",
    "    except KeyboardInterrupt:\n",
    "        raise\n",
    "    except:\n",
    "        return part_a\n",
    "    try:\n",
    "        soup = TS.TexSoup(\"\\n\".join(part_b), tolerance=tolerance, skip_envs=MATH_ENV_NAMES)\n",
    "    except KeyboardInterrupt:\n",
    "        raise\n",
    "    except:\n",
    "        return part_b\n",
    "    return \"--\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5409e9e-2bfe-45fe-ba2e-68c4f50a035d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_bad_lines(tar_path, encoding='utf-8'):\n",
    "    tex_main = find_main_tex_source_in_tar(tar_path, encoding=encoding)\n",
    "    with tarfile.open(tar_path, 'r') as in_tar:\n",
    "        fp = in_tar.extractfile(tex_main)\n",
    "        wrapped_file = io.TextIOWrapper(fp, newline=None, encoding=encoding) #universal newlines\n",
    "        source_text = pre_format(wrapped_file.read())\n",
    "        current_text = source_text.splitlines()\n",
    "\n",
    "    while len(current_text) > 1:\n",
    "        bad_half = find_bad(current_text)\n",
    "        if current_text == bad_half:\n",
    "            break\n",
    "        current_text = bad_half\n",
    "        \n",
    "    return bad_half"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec617d2c-3d30-4546-8d1e-0e3215b32355",
   "metadata": {},
   "source": [
    "## Check a file with parse errors"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a6b801fc-d594-48dd-a522-f187ffe08a55",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "343e9028-84fb-48f8-b9bf-35220d6dd0cd",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "source": [
    "infile_path = \"./data/2201_00_all/2201.00001v1.tar.gz\" #'./data/2201_samp/2201.00048v1.tar.gz'\n",
    "\n",
    "text = source_from_tar(infile_path)\n",
    "pyperclip.copy(text)\n",
    "soup = soup_from_tar(infile_path, tolerance=1)\n",
    "\n",
    "\n",
    "title = soup.find('title')\n",
    "if title: print(f\"{title.name}: {title.text}\")\n",
    "for sec in soup.find_all('section'):\n",
    "    print(f' {sec.name}: {sec.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c3ebacc-89eb-454a-97c9-5068f77a0d71",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "LOCAL_DATA_PATH = './data/2201_01_all/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f6753f-a9f5-4f79-b054-87d4c46afeb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa1d579-88e1-4d9f-be77-efbf09f60e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab5bcbf9-305b-41a7-b283-39562489fe7c",
   "metadata": {},
   "source": [
    "## Quick check a folder of tar files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "999be077-8fdc-48e3-bdd3-65563e0b6e76",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7c0f52e447404b8b0a15bdc2a76b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "errors:   0%|          | 0/431 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ffbd9bfa1194976802f3a395e890228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/431 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = glob.glob(f'{LOCAL_DATA_PATH}/*.tar.gz')\n",
    "files_count = len(files)\n",
    "utf_count = 0\n",
    "latin_count = 0 \n",
    "err_files = {}\n",
    "\n",
    "TOLERANCE = 1\n",
    "\n",
    "with tqdm(total=files_count, desc=\"errors\") as err_prog:\n",
    "    for tar_file in tqdm(files, desc=\"Progress\", display=True):\n",
    "        # Is it unicode?\n",
    "        try:\n",
    "            soup = soup_from_tar(tar_file, encoding='utf-8', tolerance=TOLERANCE)\n",
    "            utf_count += 1\n",
    "            continue\n",
    "        except EOFError as eof:\n",
    "            err_files[tar_file] = type(eof)\n",
    "            _ = err_prog.update(1)\n",
    "            continue\n",
    "        except UnicodeDecodeError as ue:\n",
    "            pass\n",
    "        except KeyboardInterrupt as KB_err:\n",
    "            break\n",
    "        except Exception as e:\n",
    "            err_files[tar_file] = type(e)\n",
    "            _ = err_prog.update(1)\n",
    "            continue\n",
    "\n",
    "        # Is it something else?\n",
    "        try:\n",
    "            soup = soup_from_tar(tar_file, encoding='latin-1', tolerance=TOLERANCE)\n",
    "            latin_count += 1\n",
    "            continue\n",
    "        except KeyboardInterrupt as KB_err:\n",
    "            break\n",
    "        except Exception as e:\n",
    "            err_files[tar_file] = type(e)\n",
    "            _ = err_prog.update(1)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4a830f1-7cfa-4f64-9a50-e2e911b2c9e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431 processed, 13 failures.\n",
      "UTF8: 410; Latin1: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'./data/2201_01_all/2201.01352v1.tar.gz': EOFError,\n",
       " './data/2201_01_all/2201.01829v2.tar.gz': EOFError,\n",
       " './data/2201_01_all/2201.01576v2.tar.gz': EOFError,\n",
       " './data/2201_01_all/2201.01508v1.tar.gz': AssertionError,\n",
       " './data/2201_01_all/2201.01708v1.tar.gz': EOFError,\n",
       " './data/2201_01_all/2201.01194v1.tar.gz': AssertionError,\n",
       " './data/2201_01_all/2201.01576v1.tar.gz': EOFError,\n",
       " './data/2201_01_all/2201.01848v1.tar.gz': EOFError,\n",
       " './data/2201_01_all/2201.01352v2.tar.gz': EOFError,\n",
       " './data/2201_01_all/2201.01211v1.tar.gz': AssertionError,\n",
       " './data/2201_01_all/2201.01829v1.tar.gz': EOFError,\n",
       " './data/2201_01_all/2201.01194v2.tar.gz': AssertionError,\n",
       " './data/2201_01_all/2201.01594v1.tar.gz': EOFError}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{files_count} processed, {len(err_files)} failures.\")\n",
    "print(f\"UTF8: {utf_count}; Latin1: {latin_count}\")\n",
    "err_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e85ffb-2596-412a-9cfb-8ef432a52c67",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "source": [
    "## Scratch below here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19a3cc8-662e-4593-8c93-adaad218541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "infile_path = \"./data/2201_00_all/2201.00740v1.tar.gz\" #'./data/2201_samp/2201.00048v1.tar.gz'\n",
    "#infile_path = \"./data/2201_01_all/2201.01050v1.tar.gz\" #'./data/2201_samp/2201.00048v1.tar.gz'\n",
    "\n",
    "text = source_from_tar(infile_path)\n",
    "pyperclip.copy(text)\n",
    "soup = soup_from_tar(infile_path, tolerance=1)\n",
    "\n",
    "\n",
    "title = soup.find('title')\n",
    "if title: print(f\"{title.name}: {title.text}\")\n",
    "for sec in soup.find_all('section'):\n",
    "    print(f' {sec.name}: {sec.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95c00797-7e35-42b9-a4b3-faef921d68b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\t\\\\end{align*}']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infile_path = \"./data/2201_00_all/2201.00489v2.tar.gz\" #'./data/2201_samp/2201.00048v1.tar.gz'\n",
    "\n",
    "bad_text = find_bad_lines(infile_path)\n",
    "bad_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcf6ba56-8143-418f-b8ff-6a341d3036c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tar_path = \"./data/2201_samp/2201.00008v2.tar.gz\"\n",
    "encoding = \"utf-8\"\n",
    "with tarfile.open(tar_path, 'r') as in_tar:\n",
    "    tex_files = [f for f in in_tar.getnames() if f.endswith('.tex')]\n",
    "\n",
    "    # got one file\n",
    "    if len(tex_files) == 1:\n",
    "        pass #return tex_files[0]\n",
    "\n",
    "    main_files = {}\n",
    "    for tf in tex_files:\n",
    "        fp = in_tar.extractfile(tf)\n",
    "        wrapped_file = io.TextIOWrapper(fp, newline=None, encoding=encoding) #universal newlines\n",
    "        # does it have a doc class?\n",
    "        # get the type\n",
    "        main_files[tf] = find_doc_class(wrapped_file)\n",
    "        wrapped_file.close() \n",
    "\n",
    "    # got one file with doc class\n",
    "    if len(main_files) == 1:\n",
    "        pass #return(main_files.keys()[0])\n",
    "\n",
    "    # account for multi-file submissions\n",
    "    #return(max(main_files, key=main_files.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66887585-19d1-4123-b7f3-033669132321",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a976e7d-0b45-493c-a11a-332475a297ed",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc_class_pat = re.compile(r\"^\\s*\\\\document(?:style|class)\")\n",
    "\n",
    "with tarfile.open(tar_path, 'r', encoding='utf-8') as in_tar:\n",
    "    #in_tar.getnames()\n",
    "    fp = in_tar.extractfile('main.tex')\n",
    "    wrapped_file = io.TextIOWrapper(fp, newline=None, encoding='utf-8') #universal newlines\n",
    "    for line in wrapped_file:\n",
    "        if doc_class_pat.search(line):\n",
    "            print(line)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d91077a-6e59-4b2e-a18a-f6e42308260a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "next(wrapped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c8b266-bf93-4630-96cc-7df4384ea622",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3537486a-b084-4984-ac94-98d7d57e8f12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c109f4-c5f0-4203-a6ac-2e01d52cbce7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "7fc63084-89a4-4025-b281-37484cfe6f8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Discover the file list:\n",
    "input_zip = '2201.00007v1.zip'\n",
    "infile_path = os.path.join(LOCAL_DATA_PATH, input_zip)\n",
    "if True: #False:\n",
    "    with zipfile.ZipFile(infile_path, \"r\") as in_zip:\n",
    "        files = in_zip.infolist()\n",
    "        for file_info in files:\n",
    "            if not '/.' in file_info.filename:\n",
    "                print(file_info.filename)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "42c354ee-5fbf-4fdb-a9ae-5a6734811272",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "source": [
    "main_tex = '2201.00007v1/main.tex'\n",
    "with zipfile.ZipFile(infile_path, \"r\") as in_zip:\n",
    "    with in_zip.open('2201.00007v1/main.tex') as in_tex:\n",
    "        #print(in_tex.read())\n",
    "        wrapped_file = io.TextIOWrapper(in_tex, newline=None, encoding='utf-8') #universal newlines\n",
    "        source_text = pre_format(wrapped_file.read())\n",
    "        soup = TS.TexSoup(source_text)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f76d8f8a-1108-427d-8ba0-8929708576ef",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "source": [
    "title = soup.find('title')\n",
    "print(f\"{title.name}: {title.text}\")\n",
    "for sec in soup.find_all('section'):\n",
    "    print(f' {sec.name}: {sec.text}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee9c4d1-97a9-4f76-8766-3f44fe3d30a5",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_example=r\"\"\"\n",
    "\\documentclass{article}\n",
    "\\begin{document}\n",
    "% \\renewcommand{\\shorttitle}{Avoiding Catastrophe}\n",
    "\\end{document}\n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828170bf-8ecd-42d9-8d7a-72ea96882d76",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "TS.TexSoup(r'\\newcommand{\\bra}[1]{\\left\\langle#1\\right|}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e9a622-30ec-494e-a74e-bc0bc3e71cda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TS.TexSoup(r'\\def\\be{\\foo{equation}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27395fa4-dafb-44c1-a1a6-9ef62e920672",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "TS.TexSoup(r'\\renewcommand{\\shorttitle}{Avoiding Catastrophe}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7f5085-5f09-4642-a45d-e9215eb3f508",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_example = r\"\\newenvironment{inlinemath}{$}{$}\".strip()\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88d4883-0e0c-48c8-a2f1-3f03623dc975",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_example = r\"In practice, the matrix $\\left [ 4 \\right]\\Inv\\M{D}^{(1)}_n $\".strip()\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef35d04-3cb7-4c84-8f27-10cfd07060f7",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_example = r\"In practice, the matrix $\\left[ 4 \\right]\\Inv\\M{D}^{(1)}_n $\"\n",
    "\n",
    "\n",
    "cats = TS.category.categorize(min_example)\n",
    "tokens = list(TS.tokens.tokenize(cats))\n",
    "\n",
    "char_codes = list(TS.category.categorize(min_example))\n",
    "\n",
    "buf = TS.reader.Buffer(TS.tokens.tokenize(TS.category.categorize(r'\\left[ 4 \\right]')))\n",
    "TS.reader.read_command(buf, n_required_args=-1, mode='mode:math', skip=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0b9deadd-c5ab-49f2-b955-5820e7cbc2d1",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>char</th>\n",
       "      <td>$</td>\n",
       "      <td></td>\n",
       "      <td>t</td>\n",
       "      <td></td>\n",
       "      <td>\\</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td></td>\n",
       "      <td>[</td>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>1</td>\n",
       "      <td>]</td>\n",
       "      <td></td>\n",
       "      <td>$</td>\n",
       "      <td>$</td>\n",
       "      <td></td>\n",
       "      <td>t</td>\n",
       "      <td></td>\n",
       "      <td>\\</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td></td>\n",
       "      <td>[</td>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>1</td>\n",
       "      <td>]</td>\n",
       "      <td></td>\n",
       "      <td>$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1   2   3  4   5   6   7   8   9   10  11  12  13 14 15  16  17  18  \\\n",
       "char  $      t       \\  i   n       [   0   ,   1   ]       $  $      t        \n",
       "code  4  11  12  11  1  12  12  11  19  13  13  13  20  11  4  4  11  12  11   \n",
       "\n",
       "     19  20  21  22  23  24  25  26  27  28 29  \n",
       "char  \\  i   n       [   0   ,   1   ]       $  \n",
       "code  1  12  12  11  19  13  13  13  20  11  4  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0,1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0,1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tokens\n",
       "0   $    \n",
       "1    t   \n",
       "2   \\    \n",
       "3   in   \n",
       "4        \n",
       "5   [    \n",
       "6   0,1  \n",
       "7   ]    \n",
       "8        \n",
       "9   $    \n",
       "10  $    \n",
       "11   t   \n",
       "12  \\    \n",
       "13  in   \n",
       "14       \n",
       "15  [    \n",
       "16  0,1  \n",
       "17  ]    \n",
       "18       \n",
       "19  $    "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('in', [])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "([TexMathModeEnv('$', [' t ', TexCmd('in'), ' ', '[', '0,1', ']', ' '], []), TexMathModeEnv('$', [' t ', TexCmd('in'), ' ', '[', '0,1', ']', ' '], [])],\n",
       " '$ t \\\\in [0,1] $$ t \\\\in [0,1] $')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_example = r\"$ t \\in [0,1] $$ t \\in [0,1] $\"\n",
    "\n",
    "\n",
    "cats = TS.category.categorize(min_example)\n",
    "tokens = list(TS.tokens.tokenize(cats))\n",
    "\n",
    "char_codes = list(TS.category.categorize(min_example))\n",
    "\n",
    "with pd.option_context('display.max.columns', None, 'display.max_colwidth', 0):\n",
    "    pd.DataFrame({'char':char_codes, 'code':(x.category for x in char_codes)}).transpose()\n",
    "    pd.DataFrame({'tokens':tokens})\n",
    "\n",
    "buf = TS.reader.Buffer(TS.tokens.tokenize(TS.category.categorize(min_example)))\n",
    "TS.reader.read_command(buf, n_required_args=-1, mode='mode:math', skip=3, tolerance=1)\n",
    "\n",
    "buf = TS.reader.Buffer(TS.tokens.tokenize(TS.category.categorize(min_example)))\n",
    "TS.read(buf, tolerance=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a69f130-a920-4bb7-aa06-aa4c9befa418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max.columns', None, 'display.max_colwidth', 0):\n",
    "    pd.DataFrame({'char':char_codes, 'code':(x.category for x in char_codes)}).transpose()\n",
    "    pd.DataFrame({'tokens':tokens})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257478aa-2037-49ef-8b70-d5cde86ad095",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_example = r\"In practice, the matrix $\\left [\\M{D}^{(1)}_n(\\M{D}^{(1)}_n)\\Tra\\right]\\Inv\\M{D}^{(1)}_n $\"\n",
    "print(min_example)\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "TS.TexSoup(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4658922-e3ad-4407-b85b-a28a49778c4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_example=r\"\"\"\n",
    "\\documentclass{article}\n",
    "\\begin{document}\n",
    "% \\renewcommand{\\shorttitle}{Avoiding Catastrophe}\n",
    "\\end{document}\n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737d580c-1063-4beb-b86c-742533e87c7b",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_example=r\"\"\"\n",
    "\\def\\bean {\\begin{foo}}  \\def\\eean {\\end{foo}}\n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "TS.TexSoup(min_example)\n",
    "print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d7528b67-1e5e-46e3-81eb-eebb20f02f2a",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "we {use $A=8B$ and $s=1$, then the scalar field becomes same with (\\Ref{scalarfield}) and}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we {use $A=8B$ and $s=1$, then the scalar field becomes same with (\\Ref{scalarfield}) and\n"
     ]
    }
   ],
   "source": [
    "min_example=r\"\"\"\n",
    "we {use $A=8B$ and $s=1$, then the scalar field becomes same with (\\Ref{scalarfield}) and\n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#TS.TexSoup(min_example)\n",
    "print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2c5821fc-c981-4408-a05c-5f5f0f02094f",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we {use $A=8B$ and $s=1$, then the scalar field becomes same with (\\Ref{scalarfield}) and\n"
     ]
    }
   ],
   "source": [
    "print(pre_format(min_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "09ca3e54",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Big (',\n",
       " 'Big )',\n",
       " 'Big .',\n",
       " 'Big .|',\n",
       " 'Big <',\n",
       " 'Big >',\n",
       " 'Big [',\n",
       " 'Big \\\\langle',\n",
       " 'Big \\\\lbrack',\n",
       " 'Big \\\\lceil',\n",
       " 'Big \\\\lfloor',\n",
       " 'Big \\\\rangle',\n",
       " 'Big \\\\rbrack',\n",
       " 'Big \\\\rceil',\n",
       " 'Big \\\\rfloor',\n",
       " 'Big \\\\ulcorner',\n",
       " 'Big \\\\urcorner',\n",
       " 'Big \\\\{',\n",
       " 'Big \\\\}',\n",
       " 'Big ]',\n",
       " 'Big {',\n",
       " 'Big |',\n",
       " 'Big }',\n",
       " 'Big(',\n",
       " 'Big)',\n",
       " 'Big.',\n",
       " 'Big.|',\n",
       " 'Big<',\n",
       " 'Big>',\n",
       " 'Big[',\n",
       " 'Big\\\\langle',\n",
       " 'Big\\\\lbrack',\n",
       " 'Big\\\\lceil',\n",
       " 'Big\\\\lfloor',\n",
       " 'Big\\\\rangle',\n",
       " 'Big\\\\rbrack',\n",
       " 'Big\\\\rceil',\n",
       " 'Big\\\\rfloor',\n",
       " 'Big\\\\ulcorner',\n",
       " 'Big\\\\urcorner',\n",
       " 'Big\\\\{',\n",
       " 'Big\\\\}',\n",
       " 'Big]',\n",
       " 'Bigg (',\n",
       " 'Bigg )',\n",
       " 'Bigg .',\n",
       " 'Bigg .|',\n",
       " 'Bigg <',\n",
       " 'Bigg >',\n",
       " 'Bigg [',\n",
       " 'Bigg \\\\langle',\n",
       " 'Bigg \\\\lbrack',\n",
       " 'Bigg \\\\lceil',\n",
       " 'Bigg \\\\lfloor',\n",
       " 'Bigg \\\\rangle',\n",
       " 'Bigg \\\\rbrack',\n",
       " 'Bigg \\\\rceil',\n",
       " 'Bigg \\\\rfloor',\n",
       " 'Bigg \\\\ulcorner',\n",
       " 'Bigg \\\\urcorner',\n",
       " 'Bigg \\\\{',\n",
       " 'Bigg \\\\}',\n",
       " 'Bigg ]',\n",
       " 'Bigg {',\n",
       " 'Bigg |',\n",
       " 'Bigg }',\n",
       " 'Bigg(',\n",
       " 'Bigg)',\n",
       " 'Bigg.',\n",
       " 'Bigg.|',\n",
       " 'Bigg<',\n",
       " 'Bigg>',\n",
       " 'Bigg[',\n",
       " 'Bigg\\\\langle',\n",
       " 'Bigg\\\\lbrack',\n",
       " 'Bigg\\\\lceil',\n",
       " 'Bigg\\\\lfloor',\n",
       " 'Bigg\\\\rangle',\n",
       " 'Bigg\\\\rbrack',\n",
       " 'Bigg\\\\rceil',\n",
       " 'Bigg\\\\rfloor',\n",
       " 'Bigg\\\\ulcorner',\n",
       " 'Bigg\\\\urcorner',\n",
       " 'Bigg\\\\{',\n",
       " 'Bigg\\\\}',\n",
       " 'Bigg]',\n",
       " 'Bigg{',\n",
       " 'Bigg|',\n",
       " 'Bigg}',\n",
       " 'Big{',\n",
       " 'Big|',\n",
       " 'Big}',\n",
       " 'big (',\n",
       " 'big )',\n",
       " 'big .',\n",
       " 'big .|',\n",
       " 'big <',\n",
       " 'big >',\n",
       " 'big [',\n",
       " 'big \\\\langle',\n",
       " 'big \\\\lbrack',\n",
       " 'big \\\\lceil',\n",
       " 'big \\\\lfloor',\n",
       " 'big \\\\rangle',\n",
       " 'big \\\\rbrack',\n",
       " 'big \\\\rceil',\n",
       " 'big \\\\rfloor',\n",
       " 'big \\\\ulcorner',\n",
       " 'big \\\\urcorner',\n",
       " 'big \\\\{',\n",
       " 'big \\\\}',\n",
       " 'big ]',\n",
       " 'big {',\n",
       " 'big |',\n",
       " 'big }',\n",
       " 'big(',\n",
       " 'big)',\n",
       " 'big.',\n",
       " 'big.|',\n",
       " 'big<',\n",
       " 'big>',\n",
       " 'big[',\n",
       " 'big\\\\langle',\n",
       " 'big\\\\lbrack',\n",
       " 'big\\\\lceil',\n",
       " 'big\\\\lfloor',\n",
       " 'big\\\\rangle',\n",
       " 'big\\\\rbrack',\n",
       " 'big\\\\rceil',\n",
       " 'big\\\\rfloor',\n",
       " 'big\\\\ulcorner',\n",
       " 'big\\\\urcorner',\n",
       " 'big\\\\{',\n",
       " 'big\\\\}',\n",
       " 'big]',\n",
       " 'bigg (',\n",
       " 'bigg )',\n",
       " 'bigg .',\n",
       " 'bigg .|',\n",
       " 'bigg <',\n",
       " 'bigg >',\n",
       " 'bigg [',\n",
       " 'bigg \\\\langle',\n",
       " 'bigg \\\\lbrack',\n",
       " 'bigg \\\\lceil',\n",
       " 'bigg \\\\lfloor',\n",
       " 'bigg \\\\rangle',\n",
       " 'bigg \\\\rbrack',\n",
       " 'bigg \\\\rceil',\n",
       " 'bigg \\\\rfloor',\n",
       " 'bigg \\\\ulcorner',\n",
       " 'bigg \\\\urcorner',\n",
       " 'bigg \\\\{',\n",
       " 'bigg \\\\}',\n",
       " 'bigg ]',\n",
       " 'bigg {',\n",
       " 'bigg |',\n",
       " 'bigg }',\n",
       " 'bigg(',\n",
       " 'bigg)',\n",
       " 'bigg.',\n",
       " 'bigg.|',\n",
       " 'bigg<',\n",
       " 'bigg>',\n",
       " 'bigg[',\n",
       " 'bigg\\\\langle',\n",
       " 'bigg\\\\lbrack',\n",
       " 'bigg\\\\lceil',\n",
       " 'bigg\\\\lfloor',\n",
       " 'bigg\\\\rangle',\n",
       " 'bigg\\\\rbrack',\n",
       " 'bigg\\\\rceil',\n",
       " 'bigg\\\\rfloor',\n",
       " 'bigg\\\\ulcorner',\n",
       " 'bigg\\\\urcorner',\n",
       " 'bigg\\\\{',\n",
       " 'bigg\\\\}',\n",
       " 'bigg]',\n",
       " 'bigg{',\n",
       " 'bigg|',\n",
       " 'bigg}',\n",
       " 'big{',\n",
       " 'big|',\n",
       " 'big}',\n",
       " 'left (',\n",
       " 'left )',\n",
       " 'left .',\n",
       " 'left .|',\n",
       " 'left <',\n",
       " 'left >',\n",
       " 'left [',\n",
       " 'left \\\\langle',\n",
       " 'left \\\\lbrack',\n",
       " 'left \\\\lceil',\n",
       " 'left \\\\lfloor',\n",
       " 'left \\\\rangle',\n",
       " 'left \\\\rbrack',\n",
       " 'left \\\\rceil',\n",
       " 'left \\\\rfloor',\n",
       " 'left \\\\ulcorner',\n",
       " 'left \\\\urcorner',\n",
       " 'left \\\\{',\n",
       " 'left \\\\}',\n",
       " 'left ]',\n",
       " 'left {',\n",
       " 'left |',\n",
       " 'left }',\n",
       " 'left(',\n",
       " 'left)',\n",
       " 'left.',\n",
       " 'left.|',\n",
       " 'left<',\n",
       " 'left>',\n",
       " 'left[',\n",
       " 'left\\\\langle',\n",
       " 'left\\\\lbrack',\n",
       " 'left\\\\lceil',\n",
       " 'left\\\\lfloor',\n",
       " 'left\\\\rangle',\n",
       " 'left\\\\rbrack',\n",
       " 'left\\\\rceil',\n",
       " 'left\\\\rfloor',\n",
       " 'left\\\\ulcorner',\n",
       " 'left\\\\urcorner',\n",
       " 'left\\\\{',\n",
       " 'left\\\\}',\n",
       " 'left]',\n",
       " 'left{',\n",
       " 'left|',\n",
       " 'left}',\n",
       " 'right (',\n",
       " 'right )',\n",
       " 'right .',\n",
       " 'right .|',\n",
       " 'right <',\n",
       " 'right >',\n",
       " 'right [',\n",
       " 'right \\\\langle',\n",
       " 'right \\\\lbrack',\n",
       " 'right \\\\lceil',\n",
       " 'right \\\\lfloor',\n",
       " 'right \\\\rangle',\n",
       " 'right \\\\rbrack',\n",
       " 'right \\\\rceil',\n",
       " 'right \\\\rfloor',\n",
       " 'right \\\\ulcorner',\n",
       " 'right \\\\urcorner',\n",
       " 'right \\\\{',\n",
       " 'right \\\\}',\n",
       " 'right ]',\n",
       " 'right {',\n",
       " 'right |',\n",
       " 'right }',\n",
       " 'right(',\n",
       " 'right)',\n",
       " 'right.',\n",
       " 'right.|',\n",
       " 'right<',\n",
       " 'right>',\n",
       " 'right[',\n",
       " 'right\\\\langle',\n",
       " 'right\\\\lbrack',\n",
       " 'right\\\\lceil',\n",
       " 'right\\\\lfloor',\n",
       " 'right\\\\rangle',\n",
       " 'right\\\\rbrack',\n",
       " 'right\\\\rceil',\n",
       " 'right\\\\rfloor',\n",
       " 'right\\\\ulcorner',\n",
       " 'right\\\\urcorner',\n",
       " 'right\\\\{',\n",
       " 'right\\\\}',\n",
       " 'right]',\n",
       " 'right{',\n",
       " 'right|',\n",
       " 'right}'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BRACKETS_DELIMITERS = {\n",
    "    '(', ')', '<', '>', '[', ']', '{', '}', r'\\{', r'\\}', '.' '|', r'\\langle',\n",
    "    r'\\rangle', r'\\lfloor', r'\\rfloor', r'\\lceil', r'\\rceil', r'\\ulcorner',\n",
    "    r'\\urcorner', r'\\lbrack', r'\\rbrack'\n",
    "}\n",
    "# TODO: looks like left-right do have to match\n",
    "SIZE_PREFIX = ('left', 'right', 'big', 'Big', 'bigg', 'Bigg')\n",
    "PUNCTUATION_COMMANDS = {command + opt_space + bracket\n",
    "                        for command in SIZE_PREFIX\n",
    "                        for opt_space in {'', ' '}\n",
    "                        for bracket in BRACKETS_DELIMITERS.union({'|', '.'})}\n",
    "PUNCTUATION_COMMANDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0c83d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2c2cc0-fb23-4e5e-af5a-f97ba0eeeea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77ff873e-9a41-4291-bd8f-d7c760c4cef2",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\\def\\bean{\\begin{eqnarray*}}  \\def\\eean {\\end{eqnarray*}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_example=r\"\"\"\n",
    "\\def\\bean {\\begin{eqnarray*}}  \\def\\eean {\\end{eqnarray*}}\n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4148d5a9-5626-4819-9d50-bd95219177c7",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the interval $t\\in[0,1) $."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_example=r\"\"\"\n",
    "the interval $t\\in[0,1)$. \n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "07c83316-e0bb-4e25-8635-b256bf837edb",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\\beq\n",
       "[\\chF,\\chG\\}=\\{\\partial\\chF,\\chG\\}.\n",
       "\\eeq\n",
       "\n",
       "derivation $\\CA\\mapsto [\\CB,\\CA]$. \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "The following characterizations of UAL chains are all equivalent:\n",
       "\\begin{itemize}\n",
       "    \\item[(1)] A skew-symmetric function $\\cha:\\Lambda^{q+1}\\ra\\mfkdal$ defines an element of $C_{q}(\\mfkdal) $ if $\\|\\cha\\|_{\\alpha}<\\infty$ for any $\\alpha \\in \\NN$.\n",
       "    \\item[(2)] A skew-symmetric function $\\cha:\\Lambda^{q+1}\\ra\\mfkdal$ defines an element of $C_{q}(\\mfkdal) $ if there is a function $b(r) \\in \\Orf$  such that for any $j_0,...,j_q$ the observable $\\cha_{j_0...j_q}$ is $b$-localized at $j_a$ for any $a \\in \\{0,1,...,q\\}$.\n",
       "    \\item[(3)] $C_{q}(\\mfkdal) $ is the completion of $C_q(\\mfkdl) $ with respect to the norms $\\|\\cdot\\|_{\\alpha}$.\n",
       "\\end{itemize}\n",
       "\\end{lemma}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_example=r\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\\beq\n",
    "[\\chF,\\chG\\}=\\{\\partial\\chF,\\chG\\}.\n",
    "\\eeq\n",
    "\n",
    "derivation $\\CA\\mapsto [\\CB,\\CA]$. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The following characterizations of UAL chains are all equivalent:\n",
    "\\begin{itemize}\n",
    "    \\item[(1)] A skew-symmetric function $\\cha:\\Lambda^{q+1}\\ra\\mfkdal$ defines an element of $C_{q}(\\mfkdal) $ if $\\|\\cha\\|_{\\alpha}<\\infty$ for any $\\alpha \\in \\NN$.\n",
    "    \\item[(2)] A skew-symmetric function $\\cha:\\Lambda^{q+1}\\ra\\mfkdal$ defines an element of $C_{q}(\\mfkdal) $ if there is a function $b(r) \\in \\Orf$  such that for any $j_0,...,j_q$ the observable $\\cha_{j_0...j_q}$ is $b$-localized at $j_a$ for any $a \\in \\{0,1,...,q\\}$.\n",
    "    \\item[(3)] $C_{q}(\\mfkdal) $ is the completion of $C_q(\\mfkdl) $ with respect to the norms $\\|\\cdot\\|_{\\alpha}$.\n",
    "\\end{itemize}\n",
    "\\end{lemma}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7311649a-3864-430f-9fcd-f8f15204b8aa",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\\newcommand\\const{\\operatorname{const}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_example=r\"\"\"\n",
    "\\newcommand\\const{\\operatorname{const}}\n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac29f7c5-97ef-485e-ba31-d333f2b4b9da",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\\newcommand{\\beq}{\\begin{equation}}\n",
       "\\newcommand{\\eeq}{\\end{equation}}\n",
       "\\newcommand{\\chF}{{\\mathsf f}}\n",
       "\\newcommand{\\chG}{{\\mathsf g}}\n",
       "\\beq  \n",
       "[\\chF,\\chG\\}=\\{\\partial\\chF,\\chG\\}.\n",
       "\\eeq\n",
       "derivation $\\CA\\mapsto [\\CB,\\CA]$."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_example=r\"\"\"\n",
    "\\newcommand{\\beq}{\\begin{equation}}\n",
    "\\newcommand{\\eeq}{\\end{equation}}\n",
    "\\newcommand{\\chF}{{\\mathsf f}}\n",
    "\\newcommand{\\chG}{{\\mathsf g}}\n",
    "\\beq  \n",
    "[\\chF,\\chG\\}=\\{\\partial\\chF,\\chG\\}.\n",
    "\\eeq\n",
    "derivation $\\CA\\mapsto [\\CB,\\CA]$. \n",
    "\"\"\".strip().replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d72f01a6-23a6-42aa-a97c-ca67cb105861",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\\[\n",
       "r_p=d(p,\\cdot)\\colon \\Gamma \\to [0,\\infty)|~ p \\in M\\}\n",
       "\\]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_example=r\"\"\"\n",
    "\\[\n",
    "r_p=d(p,\\cdot)\\colon \\Gamma \\to [0,\\infty)|~ p \\in M\\}\n",
    "\\]\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2a4b795-603a-4f45-8fd6-967414de6514",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$\\bigl[ a \\bigr) $"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_example=r\"\"\"\n",
    "$\\bigl[ a \\bigr)$\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb82b287-0b71-42da-b29c-8e351133a722",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$\\varepsilon\\in]0,\\varepsilon_\\star[$,"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_example=r\"\"\"\n",
    "\n",
    "$\\varepsilon\\in]0,\\varepsilon_\\star[$,  \n",
    "\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddaea408-fa6d-4b0b-a7db-1d8c4830e00a",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\\[\n",
       "i\\colon [0,\\infty) \n",
       "\\]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_example=r\"\"\"\n",
    "\\[\n",
    "i\\colon [0,\\infty) \n",
    "\\]\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fc98177-9a34-4dbf-8117-8906e71d72dc",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cmd name not recognized in \\newcommand{\\}{1}.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\\newcommand{\\}{1}{{\\mathds 1}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_example=r\"\"\"\n",
    "\\newcommand\\1{{\\mathds 1}}\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91f919f8-73ed-49e0-ba51-016f9b93c5a8",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\\newcommand{\\linebreakand}{%\n",
       "    \\end{@IEEEauthorhalign}\n",
       "    \\hfill\\mbox{}\\par\n",
       "    \\mbox{}\\hfill\\begin{@IEEEauthorhalign}\n",
       "    }\\end{@IEEEauthorhalign}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !! This bug was specific to my fork\n",
    "min_example=r\"\"\"\n",
    "\\newcommand{\\linebreakand}{%\n",
    "    \\end{@IEEEauthorhalign}\n",
    "    \\hfill\\mbox{}\\par\n",
    "    \\mbox{}\\hfill\\begin{@IEEEauthorhalign}\n",
    "    }\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c3bbc1f-bd0f-45c8-9491-f053fe385e55",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$S \\subseteq \\{0\\} \\bigcup [1,\\infty) $ if $z^*_2=1$."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_example=r\"\"\"\n",
    " $S \\subseteq \\{0\\} \\bigcup [1,\\infty) $ if $z^*_2=1$.  \n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b60b5d80-5e79-42de-9c64-c19e24c13a33",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$\\rm{W_{cyc} }\\geq 0$$\\;\\;\\square$"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# two inline math envs next to eachother\n",
    "# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\n",
    "min_example=r\"\"\"\n",
    "$\\rm{W_{cyc} }\\geq 0$$\\;\\;\\square$\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b96d15d6-3c87-4672-a4f9-9a8156fb19bb",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "[Line: 0, Offset: 6] \"$\" env expecting $. Reached end of file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# \\verb{char}...{char} is also an issue for parser\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m min_example\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mverb+$TEXMF/tex/latex/elsevier/+, \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;66;03m#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mTS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTexSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmin_example\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#print(min_example)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/__init__.py:89\u001b[0m, in \u001b[0;36mTexSoup\u001b[0;34m(tex_code, skip_envs, tolerance)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mAt a high-level, parses provided Tex into a navigable, searchable\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03mstructure. This is accomplished in two steps:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03mSOUP\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     88\u001b[0m MathModeTracker\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m---> 89\u001b[0m parsed, src \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtex_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_envs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_envs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TexNode(parsed, src\u001b[38;5;241m=\u001b[39msrc)\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/tex.py:22\u001b[0m, in \u001b[0;36mread\u001b[0;34m(tex, skip_envs, tolerance)\u001b[0m\n\u001b[1;32m     20\u001b[0m buf \u001b[38;5;241m=\u001b[39m tokenize(buf)\n\u001b[1;32m     21\u001b[0m buf \u001b[38;5;241m=\u001b[39m read_tex(buf, skip_envs\u001b[38;5;241m=\u001b[39mskip_envs, tolerance\u001b[38;5;241m=\u001b[39mtolerance)\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTexEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m[tex]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbegin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m, tex\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/data.py:897\u001b[0m, in \u001b[0;36mTexEnv.__init__\u001b[0;34m(self, name, begin, end, contents, args, preserve_whitespace, position)\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, begin, end, contents\u001b[38;5;241m=\u001b[39m(), args\u001b[38;5;241m=\u001b[39m(),\n\u001b[1;32m    877\u001b[0m              preserve_whitespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    878\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Initialization for Tex environment.\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \n\u001b[1;32m    880\u001b[0m \u001b[38;5;124;03m    :param str name: name of environment\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;124;03m    '^^\\\\$**'\u001b[39;00m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 897\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_whitespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_begin \u001b[38;5;241m=\u001b[39m begin\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_end \u001b[38;5;241m=\u001b[39m end\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/data.py:646\u001b[0m, in \u001b[0;36mTexExpr.__init__\u001b[0;34m(self, name, contents, args, preserve_whitespace, position)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m TexArgs(args)\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 646\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_contents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreserve_whitespace \u001b[38;5;241m=\u001b[39m preserve_whitespace\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition \u001b[38;5;241m=\u001b[39m position\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/reader.py:227\u001b[0m, in \u001b[0;36mread_tex\u001b[0;34m(buf, skip_envs, tolerance)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Parse all expressions in buffer\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m:param Buffer buf: a buffer of tokens\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03m:rtype: Iterable[TexExpr]\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m buf\u001b[38;5;241m.\u001b[39mhasNext():\n\u001b[0;32m--> 227\u001b[0m     expr \u001b[38;5;241m=\u001b[39m \u001b[43mread_expr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mskip_envs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSKIP_ENV_NAMES\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mskip_envs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m# update signatures for newly discovered commands\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     update_signatures(expr)\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/reader.py:274\u001b[0m, in \u001b[0;36mread_expr\u001b[0;34m(src, skip_envs, tolerance, mode, is_arg)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m is_arg) \u001b[38;5;129;01mand\u001b[39;00m c\u001b[38;5;241m.\u001b[39mcategory \u001b[38;5;129;01min\u001b[39;00m MATH_TOKEN_TO_ENV\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    273\u001b[0m     expr \u001b[38;5;241m=\u001b[39m MATH_TOKEN_TO_ENV[c\u001b[38;5;241m.\u001b[39mcategory]([], position\u001b[38;5;241m=\u001b[39mc\u001b[38;5;241m.\u001b[39mposition)\n\u001b[0;32m--> 274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mread_math_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m c\u001b[38;5;241m.\u001b[39mcategory \u001b[38;5;241m==\u001b[39m TC\u001b[38;5;241m.\u001b[39mEscape:\n\u001b[1;32m    276\u001b[0m     name, args \u001b[38;5;241m=\u001b[39m read_command(src, tolerance\u001b[38;5;241m=\u001b[39mtolerance, mode\u001b[38;5;241m=\u001b[39mmode)\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/reader.py:394\u001b[0m, in \u001b[0;36mread_math_env\u001b[0;34m(src, expr, tolerance)\u001b[0m\n\u001b[1;32m    391\u001b[0m     contents\u001b[38;5;241m.\u001b[39mappend(read_expr(src, tolerance\u001b[38;5;241m=\u001b[39mtolerance, mode\u001b[38;5;241m=\u001b[39mMODE_MATH))\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m src\u001b[38;5;241m.\u001b[39mhasNext() \u001b[38;5;129;01mor\u001b[39;00m src\u001b[38;5;241m.\u001b[39mpeek()\u001b[38;5;241m.\u001b[39mcategory \u001b[38;5;241m!=\u001b[39m expr\u001b[38;5;241m.\u001b[39mtoken_end:\n\u001b[0;32m--> 394\u001b[0m     \u001b[43munclosed_env_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpeek\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28mnext\u001b[39m(src)\n\u001b[1;32m    396\u001b[0m expr\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m*\u001b[39mcontents)\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/reader.py:367\u001b[0m, in \u001b[0;36munclosed_env_handler\u001b[0;34m(src, expr, end)\u001b[0m\n\u001b[1;32m    365\u001b[0m explanation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInstead got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m end \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReached end of file.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    366\u001b[0m line, offset \u001b[38;5;241m=\u001b[39m clo(src\u001b[38;5;241m.\u001b[39mposition)\n\u001b[0;32m--> 367\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[Line: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, Offset: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m env expecting \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    368\u001b[0m     line, offset, expr\u001b[38;5;241m.\u001b[39mname, expr\u001b[38;5;241m.\u001b[39mend, explanation))\n",
      "\u001b[0;31mEOFError\u001b[0m: [Line: 0, Offset: 6] \"$\" env expecting $. Reached end of file."
     ]
    }
   ],
   "source": [
    "# \\verb{char}...{char} is also an issue for parser\n",
    "# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\n",
    "min_example=r\"\"\"\n",
    "\\verb+$TEXMF/tex/latex/elsevier/+, %$%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec142f53-1371-43a4-aade-483fb01fb539",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$\\sqrt{\\frac{3}{2}} >p >1$"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# does not handle missing optional braces around arguments\n",
    "min_example=r\"\"\"\n",
    "$\\sqrt {\\frac 3 2} >p >1$\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c7e17698-be31-4eff-9e3a-bc1e73b2514e",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "&$\\rm{N_{Diskbb}}$$(\\times 10^4) $"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \\verb{char}...{char} is also an issue for parser\n",
    "# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\n",
    "min_example=r\"\"\"\n",
    "&$\\rm{N_{Diskbb}}$$(\\times 10^4) $\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b8aa1625-0ba4-4ffb-ac6a-cbe1d32cad6f",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$\\frac{j+1+\\epsilon}{m^{\\alpha}}[$"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \\verb{char}...{char} is also an issue for parser\n",
    "# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\n",
    "min_example=r\"\"\"\n",
    "$\\frac{j+1+\\epsilon}{m^{\\alpha}}[$\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62bcafac-4179-4524-b682-ff901aaedbd1",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$1\\le k< \\frac{n}{2}$"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \\verb{char}...{char} is also an issue for parser\n",
    "# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\n",
    "min_example=r\"\"\"\n",
    "$1\\le k< \\frac n2 $ \n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "918c3c98-2b72-4991-ae99-d8b90cc94520",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>char</th>\n",
       "      <td>$</td>\n",
       "      <td>O</td>\n",
       "      <td>(</td>\n",
       "      <td>\\</td>\n",
       "      <td>n</td>\n",
       "      <td>^</td>\n",
       "      <td>{</td>\n",
       "      <td>-</td>\n",
       "      <td>\\</td>\n",
       "      <td>f</td>\n",
       "      <td>r</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>}</td>\n",
       "      <td>)</td>\n",
       "      <td></td>\n",
       "      <td>$</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1   2  3   4  5  6   7  8   9   10  11  12  13  14 15  16  17 18  19\n",
       "char  $  O   (   \\  n   ^  {  -   \\  f   r   a   c   1   2   }  )       $  , \n",
       "code  4  12  21  1  12  8  2  13  1  12  12  12  12  13  13  3  22  11  4  13"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>^</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>frac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tokens\n",
       "0   $    \n",
       "1   O(   \n",
       "2   \\    \n",
       "3   n    \n",
       "4   ^    \n",
       "5   {    \n",
       "6   -    \n",
       "7   \\    \n",
       "8   frac \n",
       "9   12   \n",
       "10  }    \n",
       "11  )    \n",
       "12  $    \n",
       "13  ,    "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('n', [])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "([TexMathModeEnv('$', ['O(', TexCmd('n'), '^', BraceGroup('-', TexCmd('frac', [BraceGroup('1'), BraceGroup('2')])), ') '], []), ','],\n",
       " '$O(\\\\n^{-\\\\frac12}) $,')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \\verb{char}...{char} is also an issue for parser\n",
    "# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\n",
    "min_example=r\"\"\"\n",
    "$O(\\n^{-\\frac12}) $, \n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "\n",
    "cats = TS.category.categorize(min_example)\n",
    "tokens = list(TS.tokens.tokenize(cats))\n",
    "\n",
    "char_codes = list(TS.category.categorize(min_example))\n",
    "\n",
    "with pd.option_context('display.max.columns', None, 'display.max_colwidth', 0):\n",
    "    pd.DataFrame({'char':char_codes, 'code':(x.category for x in char_codes)}).transpose()\n",
    "    pd.DataFrame({'tokens':tokens})\n",
    "\n",
    "buf = TS.reader.Buffer(TS.tokens.tokenize(TS.category.categorize(min_example)))\n",
    "TS.reader.read_command(buf, n_required_args=-1, mode='mode:math', skip=3, tolerance=1)\n",
    "\n",
    "buf = TS.reader.Buffer(TS.tokens.tokenize(TS.category.categorize(min_example)))\n",
    "TS.read(buf, tolerance=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d3676c-42f7-4434-bd47-cccb4009d6d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "009dc975-bb83-47b4-af8c-5709076be5ff",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$$[T\\tensor*[]{]}{_{\\CT}^{\\sp}}$$"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \\verb{char}...{char} is also an issue for parser\n",
    "# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\n",
    "min_example=r\"\"\"\n",
    "$$[T\\tensor*[]{]}{_{\\CT}^{\\sp}}$$\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=0)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4dcc5064-6a42-4c34-8b2e-085bf0c746e5",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$O(\\n^{-\\frac{1}{2}}) $,"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \\verb{char}...{char} is also an issue for parser\n",
    "# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\n",
    "min_example=r\"\"\"\n",
    "$O(\\n^{-\\frac{1}{2}}) $, \n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c7d8975-44c5-4b0f-89da-20e0ed8ccf97",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "[Line: 0, Offset: 73] \"displaymath\" env expecting \\]. Reached end of file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# \\verb{char}...{char} is also an issue for parser\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m min_example\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m\\\u001b[39m\u001b[38;5;124musepackage\u001b[39m\u001b[38;5;132;01m{mathtools}\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDeclarePairedDelimiter\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mceil\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mlceil}\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mrceil}\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m]\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;66;03m#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mTS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTexSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmin_example\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#print(min_example)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/__init__.py:89\u001b[0m, in \u001b[0;36mTexSoup\u001b[0;34m(tex_code, skip_envs, tolerance)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mAt a high-level, parses provided Tex into a navigable, searchable\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03mstructure. This is accomplished in two steps:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03mSOUP\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     88\u001b[0m MathModeTracker\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m---> 89\u001b[0m parsed, src \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtex_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_envs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_envs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TexNode(parsed, src\u001b[38;5;241m=\u001b[39msrc)\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/tex.py:22\u001b[0m, in \u001b[0;36mread\u001b[0;34m(tex, skip_envs, tolerance)\u001b[0m\n\u001b[1;32m     20\u001b[0m buf \u001b[38;5;241m=\u001b[39m tokenize(buf)\n\u001b[1;32m     21\u001b[0m buf \u001b[38;5;241m=\u001b[39m read_tex(buf, skip_envs\u001b[38;5;241m=\u001b[39mskip_envs, tolerance\u001b[38;5;241m=\u001b[39mtolerance)\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTexEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m[tex]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbegin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m, tex\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/data.py:897\u001b[0m, in \u001b[0;36mTexEnv.__init__\u001b[0;34m(self, name, begin, end, contents, args, preserve_whitespace, position)\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, begin, end, contents\u001b[38;5;241m=\u001b[39m(), args\u001b[38;5;241m=\u001b[39m(),\n\u001b[1;32m    877\u001b[0m              preserve_whitespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    878\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Initialization for Tex environment.\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \n\u001b[1;32m    880\u001b[0m \u001b[38;5;124;03m    :param str name: name of environment\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;124;03m    '^^\\\\$**'\u001b[39;00m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 897\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_whitespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_begin \u001b[38;5;241m=\u001b[39m begin\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_end \u001b[38;5;241m=\u001b[39m end\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/data.py:646\u001b[0m, in \u001b[0;36mTexExpr.__init__\u001b[0;34m(self, name, contents, args, preserve_whitespace, position)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m TexArgs(args)\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 646\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_contents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreserve_whitespace \u001b[38;5;241m=\u001b[39m preserve_whitespace\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition \u001b[38;5;241m=\u001b[39m position\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/reader.py:227\u001b[0m, in \u001b[0;36mread_tex\u001b[0;34m(buf, skip_envs, tolerance)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Parse all expressions in buffer\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m:param Buffer buf: a buffer of tokens\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03m:rtype: Iterable[TexExpr]\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m buf\u001b[38;5;241m.\u001b[39mhasNext():\n\u001b[0;32m--> 227\u001b[0m     expr \u001b[38;5;241m=\u001b[39m \u001b[43mread_expr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mskip_envs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSKIP_ENV_NAMES\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mskip_envs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m# update signatures for newly discovered commands\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     update_signatures(expr)\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/reader.py:274\u001b[0m, in \u001b[0;36mread_expr\u001b[0;34m(src, skip_envs, tolerance, mode, is_arg)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m is_arg) \u001b[38;5;129;01mand\u001b[39;00m c\u001b[38;5;241m.\u001b[39mcategory \u001b[38;5;129;01min\u001b[39;00m MATH_TOKEN_TO_ENV\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    273\u001b[0m     expr \u001b[38;5;241m=\u001b[39m MATH_TOKEN_TO_ENV[c\u001b[38;5;241m.\u001b[39mcategory]([], position\u001b[38;5;241m=\u001b[39mc\u001b[38;5;241m.\u001b[39mposition)\n\u001b[0;32m--> 274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mread_math_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m c\u001b[38;5;241m.\u001b[39mcategory \u001b[38;5;241m==\u001b[39m TC\u001b[38;5;241m.\u001b[39mEscape:\n\u001b[1;32m    276\u001b[0m     name, args \u001b[38;5;241m=\u001b[39m read_command(src, tolerance\u001b[38;5;241m=\u001b[39mtolerance, mode\u001b[38;5;241m=\u001b[39mmode)\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/reader.py:394\u001b[0m, in \u001b[0;36mread_math_env\u001b[0;34m(src, expr, tolerance)\u001b[0m\n\u001b[1;32m    391\u001b[0m     contents\u001b[38;5;241m.\u001b[39mappend(read_expr(src, tolerance\u001b[38;5;241m=\u001b[39mtolerance, mode\u001b[38;5;241m=\u001b[39mMODE_MATH))\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m src\u001b[38;5;241m.\u001b[39mhasNext() \u001b[38;5;129;01mor\u001b[39;00m src\u001b[38;5;241m.\u001b[39mpeek()\u001b[38;5;241m.\u001b[39mcategory \u001b[38;5;241m!=\u001b[39m expr\u001b[38;5;241m.\u001b[39mtoken_end:\n\u001b[0;32m--> 394\u001b[0m     \u001b[43munclosed_env_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpeek\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28mnext\u001b[39m(src)\n\u001b[1;32m    396\u001b[0m expr\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m*\u001b[39mcontents)\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/reader.py:367\u001b[0m, in \u001b[0;36munclosed_env_handler\u001b[0;34m(src, expr, end)\u001b[0m\n\u001b[1;32m    365\u001b[0m explanation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInstead got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m end \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReached end of file.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    366\u001b[0m line, offset \u001b[38;5;241m=\u001b[39m clo(src\u001b[38;5;241m.\u001b[39mposition)\n\u001b[0;32m--> 367\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[Line: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, Offset: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m env expecting \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    368\u001b[0m     line, offset, expr\u001b[38;5;241m.\u001b[39mname, expr\u001b[38;5;241m.\u001b[39mend, explanation))\n",
      "\u001b[0;31mEOFError\u001b[0m: [Line: 0, Offset: 73] \"displaymath\" env expecting \\]. Reached end of file."
     ]
    }
   ],
   "source": [
    "# \\verb{char}...{char} is also an issue for parser\n",
    "# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\n",
    "min_example=r\"\"\"\n",
    "\\usepackage{mathtools}\n",
    "\\DeclarePairedDelimiter\\ceil{\\lceil}{\\rceil}\n",
    "\n",
    "\\[\n",
    "c_{n+1} = m_{n} \\text{ and }r_{n+1} = \\ceil[\\Big]{\\frac{f(c_{n+1}) }{t_{n}(c_{n+1} - c_{n}) }}.\n",
    "\\]\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b4b882d6-67f6-4748-9d90-91b40dee3d25",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>char</th>\n",
       "      <td>\\</td>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "      <td>g</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>{</td>\n",
       "      <td>e</td>\n",
       "      <td>q</td>\n",
       "      <td>u</td>\n",
       "      <td>a</td>\n",
       "      <td>t</td>\n",
       "      <td>i</td>\n",
       "      <td>o</td>\n",
       "      <td>n</td>\n",
       "      <td>}</td>\n",
       "      <td>\\n</td>\n",
       "      <td>\\</td>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "      <td>g</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>{</td>\n",
       "      <td>a</td>\n",
       "      <td>l</td>\n",
       "      <td>i</td>\n",
       "      <td>g</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>}</td>\n",
       "      <td>[</td>\n",
       "      <td>t</td>\n",
       "      <td>]</td>\n",
       "      <td>\\n</td>\n",
       "      <td>[</td>\n",
       "      <td>T</td>\n",
       "      <td>\\</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>*</td>\n",
       "      <td>[</td>\n",
       "      <td>]</td>\n",
       "      <td>{</td>\n",
       "      <td>]</td>\n",
       "      <td>}</td>\n",
       "      <td>{</td>\n",
       "      <td>_</td>\n",
       "      <td>{</td>\n",
       "      <td>\\</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>}</td>\n",
       "      <td>^</td>\n",
       "      <td>{</td>\n",
       "      <td>\\</td>\n",
       "      <td>s</td>\n",
       "      <td>p</td>\n",
       "      <td>}</td>\n",
       "      <td>}</td>\n",
       "      <td></td>\n",
       "      <td>\\</td>\n",
       "      <td>\\</td>\n",
       "      <td>\\n</td>\n",
       "      <td>\\</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>d</td>\n",
       "      <td>{</td>\n",
       "      <td>a</td>\n",
       "      <td>l</td>\n",
       "      <td>i</td>\n",
       "      <td>g</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>}</td>\n",
       "      <td>\\n</td>\n",
       "      <td>\\</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>d</td>\n",
       "      <td>{</td>\n",
       "      <td>e</td>\n",
       "      <td>q</td>\n",
       "      <td>u</td>\n",
       "      <td>a</td>\n",
       "      <td>t</td>\n",
       "      <td>i</td>\n",
       "      <td>o</td>\n",
       "      <td>n</td>\n",
       "      <td>}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1   2   3   4   5  6   7   8   9   10  11  12  13  14 15  16 17  18  \\\n",
       "char  \\  b   e   g   i   n   {  e   q   u   a   t   i   o   n   }  \\n  \\  b    \n",
       "code  1  12  12  12  12  12  2  12  12  12  12  12  12  12  12  3  6   1  12   \n",
       "\n",
       "      19  20  21  22 23  24  25  26  27  28  29  30 31  32  33  34  35  36  \\\n",
       "char  e   g   i   n   {  a   l   i   g   n   e   d   }  [   t   ]   \\n  [    \n",
       "code  12  12  12  12  2  12  12  12  12  12  12  12  3  19  12  20  6   19   \n",
       "\n",
       "      37 38  39  40  41  42  43  44  45  46  47 48  49 50 51 52 53 54  55  56  \\\n",
       "char  T   \\  t   e   n   s   o   r   *   [   ]   {  ]   }  {  _  {  \\  C   T    \n",
       "code  12  1  12  12  12  12  12  12  13  19  20  2  20  3  2  9  2  1  12  12   \n",
       "\n",
       "     57 58 59 60  61  62 63 64  65 66 67  68 69  70  71  72 73  74  75  76  \\\n",
       "char  }  ^  {  \\  s   p   }  }      \\  \\  \\n  \\  e   n   d   {  a   l   i    \n",
       "code  3  8  2  1  12  12  3  3  11  1  1  6   1  12  12  12  2  12  12  12   \n",
       "\n",
       "      77  78  79  80 81  82 83  84  85  86 87  88  89  90  91  92  93  94  95  \\\n",
       "char  g   n   e   d   }  \\n  \\  e   n   d   {  e   q   u   a   t   i   o   n    \n",
       "code  12  12  12  12  3  6   1  12  12  12  2  12  12  12  12  12  12  12  12   \n",
       "\n",
       "     96  \n",
       "char  }  \n",
       "code  3  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>begin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>equation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>begin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aligned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tensor*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>^</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>sp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>\\\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>{</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>aligned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>{</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>equation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tokens\n",
       "0   \\       \n",
       "1   begin   \n",
       "2   {       \n",
       "3   equation\n",
       "4   }       \n",
       "5   \\n      \n",
       "6   \\       \n",
       "7   begin   \n",
       "8   {       \n",
       "9   aligned \n",
       "10  }       \n",
       "11  [       \n",
       "12  t       \n",
       "13  ]       \n",
       "14  \\n      \n",
       "15  [       \n",
       "16  T       \n",
       "17  \\       \n",
       "18  tensor* \n",
       "19  [       \n",
       "20  ]       \n",
       "21  {       \n",
       "22  ]       \n",
       "23  }       \n",
       "24  {       \n",
       "25  _       \n",
       "26  {       \n",
       "27  \\       \n",
       "28  CT      \n",
       "29  }       \n",
       "30  ^       \n",
       "31  {       \n",
       "32  \\       \n",
       "33  sp      \n",
       "34  }       \n",
       "35  }       \n",
       "36          \n",
       "37  \\\\      \n",
       "38  \\n      \n",
       "39  \\       \n",
       "40  end     \n",
       "41  {       \n",
       "42  aligned \n",
       "43  }       \n",
       "44  \\n      \n",
       "45  \\       \n",
       "46  end     \n",
       "47  {       \n",
       "48  equation\n",
       "49  }       "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('equation', [])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "TypeError",
     "evalue": "[Line: 0, Offset 36] Malformed argument. First and last elements must match a valid argument format. In this case, TexSoup could not find matching punctuation for: [.\nJust finished parsing: ['[', 'T', TexCmd('tensor*', [BracketGroup(), BraceGroup(']'), BraceGroup('_', BraceGroup(TexCmd('CT')), '^', BraceGroup(TexCmd('sp')))]), ' ', '\\\\\\\\', '\\n', TexCmd('end', [BraceGroup('aligned')]), '\\n', TexCmd('end', [BraceGroup('equation')])]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m TS\u001b[38;5;241m.\u001b[39mreader\u001b[38;5;241m.\u001b[39mread_command(buf, n_required_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmode:math\u001b[39m\u001b[38;5;124m'\u001b[39m, skip\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     24\u001b[0m buf \u001b[38;5;241m=\u001b[39m TS\u001b[38;5;241m.\u001b[39mreader\u001b[38;5;241m.\u001b[39mBuffer(TS\u001b[38;5;241m.\u001b[39mtokens\u001b[38;5;241m.\u001b[39mtokenize(TS\u001b[38;5;241m.\u001b[39mcategory\u001b[38;5;241m.\u001b[39mcategorize(min_example)))\n\u001b[0;32m---> 25\u001b[0m \u001b[43mTS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/tex.py:22\u001b[0m, in \u001b[0;36mread\u001b[0;34m(tex, skip_envs, tolerance)\u001b[0m\n\u001b[1;32m     20\u001b[0m buf \u001b[38;5;241m=\u001b[39m tokenize(buf)\n\u001b[1;32m     21\u001b[0m buf \u001b[38;5;241m=\u001b[39m read_tex(buf, skip_envs\u001b[38;5;241m=\u001b[39mskip_envs, tolerance\u001b[38;5;241m=\u001b[39mtolerance)\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTexEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m[tex]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbegin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m, tex\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/data.py:897\u001b[0m, in \u001b[0;36mTexEnv.__init__\u001b[0;34m(self, name, begin, end, contents, args, preserve_whitespace, position)\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, begin, end, contents\u001b[38;5;241m=\u001b[39m(), args\u001b[38;5;241m=\u001b[39m(),\n\u001b[1;32m    877\u001b[0m              preserve_whitespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    878\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Initialization for Tex environment.\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \n\u001b[1;32m    880\u001b[0m \u001b[38;5;124;03m    :param str name: name of environment\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;124;03m    '^^\\\\$**'\u001b[39;00m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 897\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_whitespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_begin \u001b[38;5;241m=\u001b[39m begin\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_end \u001b[38;5;241m=\u001b[39m end\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/data.py:646\u001b[0m, in \u001b[0;36mTexExpr.__init__\u001b[0;34m(self, name, contents, args, preserve_whitespace, position)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m TexArgs(args)\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 646\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_contents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreserve_whitespace \u001b[38;5;241m=\u001b[39m preserve_whitespace\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition \u001b[38;5;241m=\u001b[39m position\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/reader.py:227\u001b[0m, in \u001b[0;36mread_tex\u001b[0;34m(buf, skip_envs, tolerance)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Parse all expressions in buffer\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m:param Buffer buf: a buffer of tokens\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03m:rtype: Iterable[TexExpr]\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m buf\u001b[38;5;241m.\u001b[39mhasNext():\n\u001b[0;32m--> 227\u001b[0m     expr \u001b[38;5;241m=\u001b[39m \u001b[43mread_expr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mskip_envs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSKIP_ENV_NAMES\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mskip_envs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m# update signatures for newly discovered commands\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     update_signatures(expr)\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/reader.py:290\u001b[0m, in \u001b[0;36mread_expr\u001b[0;34m(src, skip_envs, tolerance, mode, is_arg)\u001b[0m\n\u001b[1;32m    288\u001b[0m         read_skip_env(src, expr, is_arg)\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 290\u001b[0m         \u001b[43mread_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_envs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_envs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    292\u001b[0m     expr \u001b[38;5;241m=\u001b[39m TexCmd(name, args\u001b[38;5;241m=\u001b[39margs, position\u001b[38;5;241m=\u001b[39mc\u001b[38;5;241m.\u001b[39mposition)\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/reader.py:459\u001b[0m, in \u001b[0;36mread_env\u001b[0;34m(src, expr, skip_envs, tolerance, mode)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m src\u001b[38;5;241m.\u001b[39mhasNext():\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m src\u001b[38;5;241m.\u001b[39mpeek()\u001b[38;5;241m.\u001b[39mcategory \u001b[38;5;241m==\u001b[39m TC\u001b[38;5;241m.\u001b[39mEscape:\n\u001b[0;32m--> 459\u001b[0m         name, args \u001b[38;5;241m=\u001b[39m \u001b[43mmake_read_peek\u001b[49m\u001b[43m(\u001b[49m\u001b[43mread_command\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m            \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    461\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    462\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/reader.py:255\u001b[0m, in \u001b[0;36mmake_read_peek.<locals>.wrapper\u001b[0;34m(buf, *args, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(buf, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    254\u001b[0m     start \u001b[38;5;241m=\u001b[39m buf\u001b[38;5;241m.\u001b[39mposition\n\u001b[0;32m--> 255\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m     buf\u001b[38;5;241m.\u001b[39mbackward(buf\u001b[38;5;241m.\u001b[39mposition \u001b[38;5;241m-\u001b[39m start)\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/reader.py:740\u001b[0m, in \u001b[0;36mread_command\u001b[0;34m(buf, n_required_args, n_optional_args, skip, tolerance, mode)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_required_args \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m n_optional_args \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    739\u001b[0m     n_required_args, n_optional_args \u001b[38;5;241m=\u001b[39m SIGNATURES\u001b[38;5;241m.\u001b[39mget(name, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 740\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[43mread_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_required_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_optional_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m name, args\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/reader.py:526\u001b[0m, in \u001b[0;36mread_args\u001b[0;34m(src, n_required, n_optional, args, tolerance, mode)\u001b[0m\n\u001b[1;32m    523\u001b[0m n_required \u001b[38;5;241m=\u001b[39m read_arg_required(src, args, n_required, tolerance, mode)\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m src\u001b[38;5;241m.\u001b[39mhasNext() \u001b[38;5;129;01mand\u001b[39;00m src\u001b[38;5;241m.\u001b[39mpeek()\u001b[38;5;241m.\u001b[39mcategory \u001b[38;5;241m==\u001b[39m TC\u001b[38;5;241m.\u001b[39mBracketBegin:\n\u001b[0;32m--> 526\u001b[0m     n_optional \u001b[38;5;241m=\u001b[39m \u001b[43mread_arg_optional\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_optional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m src\u001b[38;5;241m.\u001b[39mhasNext() \u001b[38;5;129;01mand\u001b[39;00m src\u001b[38;5;241m.\u001b[39mpeek()\u001b[38;5;241m.\u001b[39mcategory \u001b[38;5;241m==\u001b[39m TC\u001b[38;5;241m.\u001b[39mGroupBegin:\n\u001b[1;32m    528\u001b[0m     n_required \u001b[38;5;241m=\u001b[39m read_arg_required(src, args, n_required, tolerance, mode)\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/reader.py:557\u001b[0m, in \u001b[0;36mread_arg_optional\u001b[0;34m(src, args, n_optional, tolerance, mode)\u001b[0m\n\u001b[1;32m    555\u001b[0m             src\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    556\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 557\u001b[0m     args\u001b[38;5;241m.\u001b[39mappend(\u001b[43mread_arg\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    558\u001b[0m     n_optional \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_optional\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/reader.py:666\u001b[0m, in \u001b[0;36mread_arg\u001b[0;34m(src, c, tolerance, mode)\u001b[0m\n\u001b[1;32m    664\u001b[0m     clo \u001b[38;5;241m=\u001b[39m CharToLineOffset(\u001b[38;5;28mstr\u001b[39m(src))\n\u001b[1;32m    665\u001b[0m     line, offset \u001b[38;5;241m=\u001b[39m clo(c\u001b[38;5;241m.\u001b[39mposition)\n\u001b[0;32m--> 666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    667\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[Line: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, Offset \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m] Malformed argument. First and last elements \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    668\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmust match a valid argument format. In this case, TexSoup\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    669\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m could not find matching punctuation for: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    670\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJust finished parsing: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    671\u001b[0m         (line, offset, c, content))\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arg(\u001b[38;5;241m*\u001b[39mcontent[\u001b[38;5;241m1\u001b[39m:], position\u001b[38;5;241m=\u001b[39mc\u001b[38;5;241m.\u001b[39mposition)\n",
      "\u001b[0;31mTypeError\u001b[0m: [Line: 0, Offset 36] Malformed argument. First and last elements must match a valid argument format. In this case, TexSoup could not find matching punctuation for: [.\nJust finished parsing: ['[', 'T', TexCmd('tensor*', [BracketGroup(), BraceGroup(']'), BraceGroup('_', BraceGroup(TexCmd('CT')), '^', BraceGroup(TexCmd('sp')))]), ' ', '\\\\\\\\', '\\n', TexCmd('end', [BraceGroup('aligned')]), '\\n', TexCmd('end', [BraceGroup('equation')])]"
     ]
    }
   ],
   "source": [
    "#2201.00740v1\n",
    "# \\verb{char}...{char} is also an issue for parser\n",
    "# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\n",
    "min_example=r\"\"\"\n",
    "\\begin{equation}\n",
    "\\begin{aligned}[t]\n",
    "[T\\tensor*[]{]}{_{\\CT}^{\\sp}} \\\\\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    " \"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "\n",
    "cats = TS.category.categorize(min_example)\n",
    "tokens = list(TS.tokens.tokenize(cats))\n",
    "\n",
    "char_codes = list(TS.category.categorize(min_example))\n",
    "\n",
    "with pd.option_context('display.max.columns', None, 'display.max_colwidth', 0, 'display.max.rows', None):\n",
    "    pd.DataFrame({'char':char_codes, 'code':(x.category for x in char_codes)}).transpose()\n",
    "    pd.DataFrame({'tokens':tokens})\n",
    "\n",
    "buf = TS.reader.Buffer(TS.tokens.tokenize(TS.category.categorize(min_example)))\n",
    "TS.reader.read_command(buf, n_required_args=-1, mode='mode:math', skip=3, tolerance=1)\n",
    "\n",
    "buf = TS.reader.Buffer(TS.tokens.tokenize(TS.category.categorize(min_example)))\n",
    "TS.read(buf, tolerance=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "424afec7-aa41-431b-acec-31f3e1c7517b",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\\rightarrow\t[T\\tensor*[]{]}{_{\\CT}^{\\sp}}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\rightarrow\t[T\\tensor*[]{]}{_{\\CT}^{\\sp}}\n"
     ]
    }
   ],
   "source": [
    "# \\verb{char}...{char} is also an issue for parser\n",
    "# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\n",
    "min_example=r\"\"\"\n",
    "\\rightarrow\t[T\\tensor*[]{]}{_{\\CT}^{\\sp}}\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "try:\n",
    "    TS.TexSoup(pre_format(min_example), tolerance=0)\n",
    "except AssertionError as e:\n",
    "    print(e)\n",
    "print(TS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "20bdb560-5818-4d75-9186-8387125c23af",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "[Line: 0, Offset 57] Malformed argument. First and last elements must match a valid argument format. In this case, TexSoup could not find matching punctuation for: [.\nJust finished parsing: ['[', 'T', TexCmd('tensor*', [BracketGroup(), BraceGroup(']'), BraceGroup('_', BraceGroup(TexCmd('CT')), '^', BraceGroup(TexCmd('sp')))]), '\\n', '\\\\]', '\\n', TexCmd('end', [BraceGroup('equation')])]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 13\u001b[0m\n\u001b[1;32m      3\u001b[0m min_example\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;132;01m{equation}\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;66;03m#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m     \u001b[43mTS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTexSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmin_example\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(e)\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/__init__.py:89\u001b[0m, in \u001b[0;36mTexSoup\u001b[0;34m(tex_code, skip_envs, tolerance)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mAt a high-level, parses provided Tex into a navigable, searchable\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03mstructure. This is accomplished in two steps:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03mSOUP\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     88\u001b[0m MathModeTracker\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m---> 89\u001b[0m parsed, src \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtex_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_envs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_envs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TexNode(parsed, src\u001b[38;5;241m=\u001b[39msrc)\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/tex.py:22\u001b[0m, in \u001b[0;36mread\u001b[0;34m(tex, skip_envs, tolerance)\u001b[0m\n\u001b[1;32m     20\u001b[0m buf \u001b[38;5;241m=\u001b[39m tokenize(buf)\n\u001b[1;32m     21\u001b[0m buf \u001b[38;5;241m=\u001b[39m read_tex(buf, skip_envs\u001b[38;5;241m=\u001b[39mskip_envs, tolerance\u001b[38;5;241m=\u001b[39mtolerance)\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTexEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m[tex]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbegin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m, tex\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/data.py:897\u001b[0m, in \u001b[0;36mTexEnv.__init__\u001b[0;34m(self, name, begin, end, contents, args, preserve_whitespace, position)\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, begin, end, contents\u001b[38;5;241m=\u001b[39m(), args\u001b[38;5;241m=\u001b[39m(),\n\u001b[1;32m    877\u001b[0m              preserve_whitespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    878\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Initialization for Tex environment.\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \n\u001b[1;32m    880\u001b[0m \u001b[38;5;124;03m    :param str name: name of environment\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;124;03m    '^^\\\\$**'\u001b[39;00m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 897\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_whitespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_begin \u001b[38;5;241m=\u001b[39m begin\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_end \u001b[38;5;241m=\u001b[39m end\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/data.py:646\u001b[0m, in \u001b[0;36mTexExpr.__init__\u001b[0;34m(self, name, contents, args, preserve_whitespace, position)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m TexArgs(args)\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 646\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_contents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreserve_whitespace \u001b[38;5;241m=\u001b[39m preserve_whitespace\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition \u001b[38;5;241m=\u001b[39m position\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/reader.py:227\u001b[0m, in \u001b[0;36mread_tex\u001b[0;34m(buf, skip_envs, tolerance)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Parse all expressions in buffer\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m:param Buffer buf: a buffer of tokens\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03m:rtype: Iterable[TexExpr]\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m buf\u001b[38;5;241m.\u001b[39mhasNext():\n\u001b[0;32m--> 227\u001b[0m     expr \u001b[38;5;241m=\u001b[39m \u001b[43mread_expr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mskip_envs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSKIP_ENV_NAMES\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mskip_envs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m# update signatures for newly discovered commands\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     update_signatures(expr)\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/reader.py:290\u001b[0m, in \u001b[0;36mread_expr\u001b[0;34m(src, skip_envs, tolerance, mode, is_arg)\u001b[0m\n\u001b[1;32m    288\u001b[0m         read_skip_env(src, expr, is_arg)\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 290\u001b[0m         \u001b[43mread_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_envs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_envs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    292\u001b[0m     expr \u001b[38;5;241m=\u001b[39m TexCmd(name, args\u001b[38;5;241m=\u001b[39margs, position\u001b[38;5;241m=\u001b[39mc\u001b[38;5;241m.\u001b[39mposition)\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/reader.py:463\u001b[0m, in \u001b[0;36mread_env\u001b[0;34m(src, expr, skip_envs, tolerance, mode)\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    462\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 463\u001b[0m     contents\u001b[38;5;241m.\u001b[39mappend(\u001b[43mread_expr\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_envs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_envs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    464\u001b[0m error \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m src\u001b[38;5;241m.\u001b[39mhasNext() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstring \u001b[38;5;241m!=\u001b[39m expr\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mand\u001b[39;00m tolerance \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/reader.py:274\u001b[0m, in \u001b[0;36mread_expr\u001b[0;34m(src, skip_envs, tolerance, mode, is_arg)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m is_arg) \u001b[38;5;129;01mand\u001b[39;00m c\u001b[38;5;241m.\u001b[39mcategory \u001b[38;5;129;01min\u001b[39;00m MATH_TOKEN_TO_ENV\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    273\u001b[0m     expr \u001b[38;5;241m=\u001b[39m MATH_TOKEN_TO_ENV[c\u001b[38;5;241m.\u001b[39mcategory]([], position\u001b[38;5;241m=\u001b[39mc\u001b[38;5;241m.\u001b[39mposition)\n\u001b[0;32m--> 274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mread_math_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m c\u001b[38;5;241m.\u001b[39mcategory \u001b[38;5;241m==\u001b[39m TC\u001b[38;5;241m.\u001b[39mEscape:\n\u001b[1;32m    276\u001b[0m     name, args \u001b[38;5;241m=\u001b[39m read_command(src, tolerance\u001b[38;5;241m=\u001b[39mtolerance, mode\u001b[38;5;241m=\u001b[39mmode)\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/reader.py:391\u001b[0m, in \u001b[0;36mread_math_env\u001b[0;34m(src, expr, tolerance)\u001b[0m\n\u001b[1;32m    389\u001b[0m contents \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m src\u001b[38;5;241m.\u001b[39mhasNext() \u001b[38;5;129;01mand\u001b[39;00m src\u001b[38;5;241m.\u001b[39mpeek()\u001b[38;5;241m.\u001b[39mcategory \u001b[38;5;241m!=\u001b[39m expr\u001b[38;5;241m.\u001b[39mtoken_end:\n\u001b[0;32m--> 391\u001b[0m     contents\u001b[38;5;241m.\u001b[39mappend(\u001b[43mread_expr\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODE_MATH\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m src\u001b[38;5;241m.\u001b[39mhasNext() \u001b[38;5;129;01mor\u001b[39;00m src\u001b[38;5;241m.\u001b[39mpeek()\u001b[38;5;241m.\u001b[39mcategory \u001b[38;5;241m!=\u001b[39m expr\u001b[38;5;241m.\u001b[39mtoken_end:\n\u001b[1;32m    394\u001b[0m     unclosed_env_handler(src, expr, src\u001b[38;5;241m.\u001b[39mpeek())\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/reader.py:276\u001b[0m, in \u001b[0;36mread_expr\u001b[0;34m(src, skip_envs, tolerance, mode, is_arg)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m read_math_env(src, expr, tolerance\u001b[38;5;241m=\u001b[39mtolerance)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m c\u001b[38;5;241m.\u001b[39mcategory \u001b[38;5;241m==\u001b[39m TC\u001b[38;5;241m.\u001b[39mEscape:\n\u001b[0;32m--> 276\u001b[0m     name, args \u001b[38;5;241m=\u001b[39m \u001b[43mread_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m mode \u001b[38;5;241m!=\u001b[39m MODE_MATH, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCommand \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mitem invalid in math mode.\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/reader.py:740\u001b[0m, in \u001b[0;36mread_command\u001b[0;34m(buf, n_required_args, n_optional_args, skip, tolerance, mode)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_required_args \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m n_optional_args \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    739\u001b[0m     n_required_args, n_optional_args \u001b[38;5;241m=\u001b[39m SIGNATURES\u001b[38;5;241m.\u001b[39mget(name, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 740\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[43mread_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_required_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_optional_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m name, args\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/reader.py:522\u001b[0m, in \u001b[0;36mread_args\u001b[0;34m(src, n_required, n_optional, args, tolerance, mode)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_required \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m n_optional \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m args\n\u001b[0;32m--> 522\u001b[0m n_optional \u001b[38;5;241m=\u001b[39m \u001b[43mread_arg_optional\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_optional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m n_required \u001b[38;5;241m=\u001b[39m read_arg_required(src, args, n_required, tolerance, mode)\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m src\u001b[38;5;241m.\u001b[39mhasNext() \u001b[38;5;129;01mand\u001b[39;00m src\u001b[38;5;241m.\u001b[39mpeek()\u001b[38;5;241m.\u001b[39mcategory \u001b[38;5;241m==\u001b[39m TC\u001b[38;5;241m.\u001b[39mBracketBegin:\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/reader.py:557\u001b[0m, in \u001b[0;36mread_arg_optional\u001b[0;34m(src, args, n_optional, tolerance, mode)\u001b[0m\n\u001b[1;32m    555\u001b[0m             src\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    556\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 557\u001b[0m     args\u001b[38;5;241m.\u001b[39mappend(\u001b[43mread_arg\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    558\u001b[0m     n_optional \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_optional\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/site-packages/TexSoup/reader.py:666\u001b[0m, in \u001b[0;36mread_arg\u001b[0;34m(src, c, tolerance, mode)\u001b[0m\n\u001b[1;32m    664\u001b[0m     clo \u001b[38;5;241m=\u001b[39m CharToLineOffset(\u001b[38;5;28mstr\u001b[39m(src))\n\u001b[1;32m    665\u001b[0m     line, offset \u001b[38;5;241m=\u001b[39m clo(c\u001b[38;5;241m.\u001b[39mposition)\n\u001b[0;32m--> 666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    667\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[Line: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, Offset \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m] Malformed argument. First and last elements \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    668\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmust match a valid argument format. In this case, TexSoup\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    669\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m could not find matching punctuation for: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    670\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJust finished parsing: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    671\u001b[0m         (line, offset, c, content))\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arg(\u001b[38;5;241m*\u001b[39mcontent[\u001b[38;5;241m1\u001b[39m:], position\u001b[38;5;241m=\u001b[39mc\u001b[38;5;241m.\u001b[39mposition)\n",
      "\u001b[0;31mTypeError\u001b[0m: [Line: 0, Offset 57] Malformed argument. First and last elements must match a valid argument format. In this case, TexSoup could not find matching punctuation for: [.\nJust finished parsing: ['[', 'T', TexCmd('tensor*', [BracketGroup(), BraceGroup(']'), BraceGroup('_', BraceGroup(TexCmd('CT')), '^', BraceGroup(TexCmd('sp')))]), '\\n', '\\\\]', '\\n', TexCmd('end', [BraceGroup('equation')])]"
     ]
    }
   ],
   "source": [
    "# \\verb{char}...{char} is also an issue for parser\n",
    "# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\n",
    "min_example=r\"\"\"\n",
    "\n",
    "\\begin{equation}\n",
    "\\[\n",
    "T\\tensor[]{]}{_{\\CT}} &\\longmapsfrom [T\\tensor*[]{]}{_{\\CT}^{\\sp}}\n",
    "\\]\n",
    "\\end{equation} \n",
    "\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "try:\n",
    "    TS.TexSoup(pre_format(min_example), tolerance=0)\n",
    "except AssertionError as e:\n",
    "    print(e)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4ab697d6-f2b8-421a-845d-dfd73a288c0c",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command \\item invalid in math mode.\n"
     ]
    }
   ],
   "source": [
    "# \\verb{char}...{char} is also an issue for parser\n",
    "# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\n",
    "min_example1=r\"\"\"\n",
    "%% \n",
    "%% Copyright 2007-2019 Elsevier Ltd\n",
    "%% \n",
    "%% This file is part of the 'Elsarticle Bundle'.\n",
    "%% ---------------------------------------------\n",
    "%% \n",
    "%% It may be distributed under the conditions of the LaTeX Project Public\n",
    "%% License, either version 1.2 of this license or (at your option) any\n",
    "%% later version.  The latest version of this license is in\n",
    "%%    http://www.latex-project.org/lppl.txt\n",
    "%% and version 1.2 or later is part of all distributions of LaTeX\n",
    "%% version 1999/12/01 or later.\n",
    "%% \n",
    "%% The list of all files belonging to the 'Elsarticle Bundle' is\n",
    "%% given in the file `manifest.txt'.\n",
    "%%\n",
    "%% $Id: elsdoc.tex 160 2019-01-14 09:25:49Z rishi $\n",
    "%%\n",
    "\\documentclass[a4paper,12pt]{article}\n",
    "\n",
    "\\usepackage[xcolor,qtwo]{rvdtx}\n",
    "\\usepackage{multicol}\n",
    "\\usepackage{color}\n",
    "\\usepackage{xspace}\n",
    "\\usepackage{pdfwidgets}\n",
    "\\usepackage{enumerate}\n",
    "\n",
    "\\def\\ttdefault{cmtt}\n",
    "\n",
    "\\headsep4pc\n",
    "\n",
    "\\makeatletter\n",
    "\\def\\bs{\\expandafter\\@gobble\\string\\\\}\n",
    "\\def\\lb{\\expandafter\\@gobble\\string\\{}\n",
    "\\def\\rb{\\expandafter\\@gobble\\string\\}}\n",
    "\\def\\@pdfauthor{C.V.Radhakrishnan}\n",
    "\\def\\@pdftitle{elsarticle.cls -- A documentation}\n",
    "\\def\\@pdfsubject{Document formatting with elsarticle.cls}\n",
    "\\def\\@pdfkeywords{LaTeX, Elsevier Ltd, document class}\n",
    "\\def\\file#1{\\textsf{#1}\\xspace}\n",
    "\n",
    "%\\def\\LastPage{19}\n",
    "\n",
    "\\DeclareRobustCommand{\\LaTeX}{L\\kern-.26em%\n",
    "        {\\sbox\\z@ T%\n",
    "         \\vbox to\\ht\\z@{\\hbox{\\check@mathfonts\n",
    "           \\fontsize\\sf@size\\z@\n",
    "           \\math@fontsfalse\\selectfont\n",
    "          A\\,}%\n",
    "         \\vss}%\n",
    "        }%\n",
    "     \\kern-.15em%\n",
    "    \\TeX}\n",
    "\\makeatother\n",
    "\n",
    "\\def\\figurename{Clip}\n",
    "\n",
    "\\setcounter{tocdepth}{1}\n",
    "\n",
    "\\begin{document}\n",
    "\n",
    "\\def\\testa{This is a specimen document. }\n",
    "\\def\\testc{\\testa\\testa\\testa\\testa}\n",
    "\\def\\testb{\\testc\\testc\\testc\\testc\\testc}\n",
    "\\long\\def\\test{\\testb\\par\\testb\\par\\testb\\par}\n",
    "\n",
    "\\pinclude{\\copy\\contbox\\printSq{\\LastPage}}\n",
    "\n",
    "\\title{elsarticle.cls -- A better way to format your document}\n",
    "\n",
    "\\author{Elsevier Ltd}\n",
    "\\contact{elsarticle@stmdocs.in}\n",
    "\n",
    "\\version{3.2}\n",
    "\\date{\\today}\n",
    "\\maketitle\n",
    "\n",
    "\\section{Introduction}\n",
    "\n",
    "\\file{elsarticle.cls} is a thoroughly re-written document class\n",
    "for formatting \\LaTeX{} submissions to Elsevier journals.\n",
    "The class uses the environments and commands defined in \\LaTeX{} kernel\n",
    "without any change in the signature so that clashes with other\n",
    "contributed \\LaTeX{} packages such as \\file{hyperref.sty},\n",
    "\\file{preview-latex.sty}, etc., will be minimal.\n",
    "\\file{elsarticle.cls} is primarily built upon the default\n",
    "\\file{article.cls}.  This class depends on the following packages\n",
    "for its proper functioning:\n",
    "\n",
    "\\begin{enumerate}\n",
    "\\item \\file{natbib.sty} for citation processing;\n",
    "\\item \\file{geometry.sty} for margin settings;\n",
    "\\item \\file{fleqn.clo} for left aligned equations;\n",
    "\\item \\file{graphicx.sty} for graphics inclusion;\n",
    "\\item \\file{txfonts.sty} optional font package, if the document is to\n",
    "  be formatted with Times and compatible math fonts;\n",
    "\\item \\file{hyperref.sty} optional packages if hyperlinking is\n",
    "  required in the document;\n",
    "%*%\n",
    "\\item \\file{endfloat.sty} optional packages if floats to be placed at\n",
    " end of the PDF.\n",
    "\\end{enumerate}\n",
    "\n",
    "All the above packages (except some optional packages) are part of any\n",
    "standard \\LaTeX{} installation. Therefore, the users need not be\n",
    "bothered about downloading any extra packages.  Furthermore, users are\n",
    "free to make use of \\textsc{ams} math packages such as\n",
    "\\file{amsmath.sty}, \\file{amsthm.sty}, \\file{amssymb.sty},\n",
    "\\file{amsfonts.sty}, etc., if they want to.  All these packages work in\n",
    "tandem with \\file{elsarticle.cls} without any problems.\n",
    "\n",
    "\\section{Major Differences}\n",
    "\n",
    "Following are the major differences between \\file{elsarticle.cls}\n",
    "and its predecessor package, \\file{elsart.cls}:\n",
    "\n",
    "\\begin{enumerate}[\\textbullet]\n",
    "\\item \\file{elsarticle.cls} is built upon \\file{article.cls}\n",
    "while \\file{elsart.cls} is not. \\file{elsart.cls} redefines\n",
    "many of the commands in the \\LaTeX{} classes/kernel, which can\n",
    "possibly cause surprising clashes with other contributed\n",
    "\\LaTeX{} packages;\n",
    "\n",
    "\\item provides preprint document formatting by default, and\n",
    "optionally formats the document as per the final\n",
    "style of models $1+$, $3+$ and $5+$ of Elsevier journals;\n",
    "\n",
    "\\item some easier ways for formatting \\verb+list+ and\n",
    "\\verb+theorem+ environments are provided while people can still\n",
    "use \\file{amsthm.sty} package;\n",
    "\n",
    "\\item \\file{natbib.sty} is the main citation processing package\n",
    "  which can comprehensively handle all kinds of citations and\n",
    "works perfectly with \\file{hyperref.sty} in combination with\n",
    "\\file{hypernat.sty};\n",
    "\n",
    "\\item long title pages are processed correctly in preprint and\n",
    "  final formats.\n",
    "\n",
    "\\end{enumerate}\n",
    "\n",
    "\\section{Installation}\n",
    "\n",
    "The package is available at author resources page at Elsevier\n",
    "(\\url{http://www.elsevier.com/locate/latex}).\n",
    "It can also be found in any of the nodes of the Comprehensive\n",
    "\\TeX{} Archive Network (\\textsc{ctan}), one of the primary nodes\n",
    "being\n",
    "\\url{http://tug.ctan.org/tex-archive/macros/latex/contrib/elsarticle/}.\n",
    "Please download the \\file{elsarticle.dtx} which is a composite\n",
    "class with documentation and \\file{elsarticle.ins} which is the\n",
    "\\LaTeX{} installer file. When we compile the\n",
    "\\file{elsarticle.ins} with \\LaTeX{} it provides the class file,\n",
    "\\file{elsarticle.cls} by\n",
    "stripping off all the documentation from the \\verb+*.dtx+ file.\n",
    "The class may be moved or copied to a place, usually,\n",
    "\\verb+$TEXMF/tex/latex/elsevier/+, %$%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "or a folder which will be read                   \n",
    "by \\LaTeX{} during document compilation.  The \\TeX{} file\n",
    "database needs updation after moving/copying class file.  Usually,\n",
    "we use commands like \\verb+mktexlsr+ or \\verb+texhash+ depending\n",
    "upon the distribution and operating system.\n",
    "\n",
    "\n",
    "\\section{Usage}\\label{sec:usage}\n",
    "The class should be loaded with the command:\n",
    "\n",
    "\\begin{vquote}\n",
    " \\documentclass[<options>]{elsarticle}\n",
    "\\end{vquote}\n",
    "\n",
    "\\noindent where the \\verb+options+ can be the following:\n",
    "\n",
    "\n",
    "\\begin{description}\n",
    "\n",
    "\\item [{\\tt\\color{verbcolor} preprint}]  default option which format the\n",
    "  document for submission to Elsevier journals.\n",
    "\n",
    "\\item [{\\tt\\color{verbcolor} review}]  similar to the \\verb+preprint+\n",
    "option, but increases the baselineskip to facilitate easier review\n",
    "process.\n",
    "\n",
    "\\item [{\\tt\\color{verbcolor} 1p}]  formats the article to the look and\n",
    "feel of the final format of model 1+ journals. This is always single\n",
    "column style.\n",
    "\n",
    "\\item [{\\tt\\color{verbcolor} 3p}] formats the article to the look and\n",
    "feel of the final format of model 3+ journals. If the journal is a two\n",
    "column model, use \\verb+twocolumn+ option in combination.\n",
    "\n",
    "\\item [{\\tt\\color{verbcolor} 5p}] formats for model 5+ journals. This\n",
    "is always of two column style.\n",
    "\n",
    "\\item [{\\tt\\color{verbcolor} authoryear}] author-year citation style of\n",
    "\\file{natbib.sty}. If you want to add extra options of\n",
    "\\file{natbib.sty}, you may use the options as comma delimited strings\n",
    "as arguments to \\verb+\\biboptions+ command. An example would be:\n",
    "\\end{description}\n",
    "\n",
    "\\begin{vquote}\n",
    " \\biboptions{longnamesfirst,angle,semicolon}\n",
    "\\end{vquote}\n",
    "\n",
    "\\begin{description}\n",
    "\\item [{\\tt\\color{verbcolor} number}] numbered citation style. Extra options\n",
    "  can be loaded with\\linebreak \\verb+\\biboptions+ command.\n",
    "\n",
    "\\item [{\\tt\\color{verbcolor} sort\\&compress}] sorts and compresses the\n",
    "numbered citations. For example, citation [1,2,3] will become [1--3].\n",
    "\n",
    "\\item [{\\tt\\color{verbcolor} longtitle}] if front matter is unusually long, use\n",
    "  this option to split the title page across pages with the correct\n",
    "placement of title and author footnotes in the first page.\n",
    "\n",
    "\\item [{\\tt\\color{verbcolor} times}] loads \\file{txfonts.sty}, if\n",
    "available in the system to use Times and compatible math fonts.\n",
    "\n",
    "%*%\n",
    "\\item [{\\tt\\color{verbcolor} reversenotenum}] Use alphabets as\n",
    "author--affiliation linking labels and use numbers for author\n",
    "footnotes. By default, numbers will be used as author--affiliation\n",
    "linking labels and alphabets for author footnotes. \n",
    "\n",
    "\\item [{\\tt\\color{verbcolor} lefttitle}] To move title and\n",
    "author/affiliation block to flushleft. \\verb+centertitle+ is the\n",
    "default option which produces center alignment.\n",
    "\n",
    "\\item [{\\tt\\color{verbcolor} endfloat}] To place all floats at the end\n",
    "of the document.\n",
    "\n",
    "\\item [{\\tt\\color{verbcolor} nonatbib}] To unload natbib.sty.\n",
    "%*%\n",
    "\n",
    "\\item [{\\tt\\color{verbcolor} doubleblind}] To hide author name, \n",
    "affiliation, email address etc. for double blind refereeing purpose.\n",
    "%*%\n",
    "\n",
    "\\item[] All options of \\file{article.cls} can be used with this\n",
    "  document class.\n",
    "\n",
    "\\item[] The default options loaded are \\verb+a4paper+, \\verb+10pt+,\n",
    "  \\verb+oneside+, \\verb+onecolumn+ and \\verb+preprint+.\n",
    "\n",
    "\\end{description}\n",
    "\n",
    "\\section{Frontmatter}\n",
    "\n",
    "There are two types of frontmatter coding:\n",
    "\\begin{enumerate}[(1)]\n",
    "\\item each author is\n",
    "connected to an affiliation with a footnote marker; hence all\n",
    "authors are grouped together and affiliations follow;\n",
    "\\pagebreak\n",
    "\\item authors of same affiliations are grouped together and the\n",
    "relevant affiliation follows this group. \n",
    "\\end{enumerate}\n",
    "\n",
    "An example of coding the first type is provided below.\n",
    "\n",
    "\\begin{vquote}\n",
    " \\title{This is a specimen title\\tnoteref{t1,t2}}\n",
    " \\tnotetext[t1]{This document is the results of the research\n",
    "    project funded by the National Science Foundation.}\n",
    " \\tnotetext[t2]{The second title footnote which is a longer \n",
    "    text matter to fill through the whole text width and \n",
    "    overflow into another line in the footnotes area of the \n",
    "    first page.}\n",
    "\\end{vquote}\n",
    "\n",
    "\\begin{vquote}\n",
    "\\author[1]{Jos Migchielsen\\corref{cor1}%\n",
    "  \\fnref{fn1}}\n",
    "\\ead{J.Migchielsen@elsevier.com}\n",
    "\n",
    "\\author[2]{CV Radhakrishnan\\fnref{fn2}}\n",
    "\\ead{cvr@sayahna.org}\n",
    "\n",
    "\\author[3]{CV Rajagopal\\fnref{fn1,fn3}}\n",
    "\\ead[url]{www.stmdocs.in}\n",
    "\\end{vquote}\n",
    "\n",
    "\\begin{vquote}\n",
    " \\cortext[cor1]{Corresponding author}\n",
    " \\fntext[fn1]{This is the first author footnote.}\n",
    " \\fntext[fn2]{Another author footnote, this is a very long \n",
    "   footnote and it should be a really long footnote. But this \n",
    "   footnote is not yet sufficiently long enough to make two \n",
    "   lines of footnote text.}\n",
    " \\fntext[fn3]{Yet another author footnote.}\n",
    "\n",
    " \\address[1]{Elsevier B.V., Radarweg 29, 1043 NX Amsterdam, \n",
    "   The Netherlands}\n",
    " \\address[2]{Sayahna Foundations, JWRA 34, Jagathy, \n",
    "   Trivandrum 695014, India}\n",
    " \\address[3]{STM Document Engineering Pvt Ltd., Mepukada,\n",
    "   Malayinkil, Trivandrum 695571, India}\n",
    "\\end{vquote}\n",
    "\n",
    "The output of the above \\TeX{} source is given in Clips~\\ref{clip1} and\n",
    "\\ref{clip2}. The header portion or title area is given in\n",
    "Clip~\\ref{clip1} and the footer area is given in Clip~\\ref{clip2}.\n",
    "\n",
    "\\def\\rulecolor{blue!70}\n",
    "\\src{Header of the title page.}\n",
    "\\includeclip{1}{130 612 477 707}{1psingleauthorgroup.pdf}%%{elstest-1p.pdf}%single author group\n",
    "\\def\\rulecolor{orange}\n",
    "\n",
    "\\def\\rulecolor{blue!70}\n",
    "\\src{Footer of the title page.}\n",
    "\\includeclip{1}{93 135 499 255}{1pseperateaug.pdf}%%{elstest-1p.pdf}%single author group\n",
    "\\def\\rulecolor{orange}\n",
    "\n",
    "Most of the commands such as \\verb+\\title+, \\verb+\\author+,\n",
    "\\verb+\\address+ are self explanatory.  Various components are\n",
    "linked to each other by a label--reference mechanism; for\n",
    "instance, title footnote is linked to the title with a footnote\n",
    "mark generated by referring to the \\verb+\\label+ string of\n",
    "the \\verb=\\tnotetext=.  We have used similar commands\n",
    "such as \\verb=\\tnoteref= (to link title note to title);\n",
    "\\verb=\\corref= (to link corresponding author text to\n",
    "corresponding author); \\verb=\\fnref= (to link footnote text to\n",
    "the relevant author names).  \\TeX{} needs two compilations to\n",
    "resolve the footnote marks in the preamble part.  \n",
    "Given below are the syntax of various note marks and note texts.\n",
    "\n",
    "\n",
    "\\begin{vquote}\n",
    "  \\tnoteref{<label(s)>}\n",
    "  \\corref{<label(s)>}\n",
    "  \\fnref{<label(s)>}\n",
    "  \\tnotetext[<label>]{<title note text>}\n",
    "  \\cortext[<label>]{<corresponding author note text>}\n",
    "  \\fntext[<label>]{<author footnote text>}\n",
    "\\end{vquote}\n",
    "\n",
    "\\noindent where \\verb=<label(s)>= can be either one or more comma\n",
    "delimited label strings. The optional arguments to the\n",
    "\\verb=\\author= command holds the ref label(s) of the address(es)\n",
    "to which the author is affiliated while each \\verb=\\address=\n",
    "command can have an optional argument of a label. In the same\n",
    "manner, \\verb=\\tnotetext=, \\verb=\\fntext=, \\verb=\\cortext= will\n",
    "have optional arguments as their respective labels and note text\n",
    "as their mandatory argument.\n",
    "\n",
    "The following example code provides the markup of the second type\n",
    "of author-affiliation.\n",
    "\n",
    "\\begin{vquote}\n",
    "\\author{Jos Migchielsen\\corref{cor1}%\n",
    "  \\fnref{fn1}}\n",
    "\\ead{J.Migchielsen@elsevier.com}\n",
    " \\address{Elsevier B.V., Radarweg 29, 1043 NX Amsterdam, \n",
    "          The Netherlands}\n",
    "\n",
    "\\author{CV Radhakrishnan\\fnref{fn2}}\n",
    "\\ead{cvr@sayahna.org}\n",
    " \\address{Sayahna Foundations, JWRA 34, Jagathy, \n",
    "    Trivandrum 695014, India}\n",
    "\n",
    "\\author{CV Rajagopal\\fnref{fn1,fn3}}\n",
    "\\ead[url]{www.stmdocs.in}\n",
    "  \\address{STM Document Engineering Pvt Ltd., Mepukada,\n",
    "    Malayinkil, Trivandrum 695571, India}\n",
    "\\end{vquote}\n",
    "\n",
    "\\vspace*{-.5pc}\n",
    "\n",
    "\\begin{vquote}\n",
    "\\cortext[cor1]{Corresponding author}\n",
    "\\fntext[fn1]{This is the first author footnote.}\n",
    "\\fntext[fn2]{Another author footnote, this is a very long \n",
    "  footnote and it should be a really long footnote. But this \n",
    "  footnote is not yet sufficiently long enough to make two lines \n",
    "  of footnote text.}\n",
    "\\end{vquote}\n",
    "\n",
    "The output of the above \\TeX{} source is given in Clip~\\ref{clip3}.\n",
    "\n",
    "\\def\\rulecolor{blue!70}\n",
    "\\src{Header of the title page..}\n",
    "\\includeclip{1}{119 563 468 709}{1pseperateaug.pdf}%%{elstest-1p.pdf}%seperate author groups\n",
    "\\def\\rulecolor{orange}\n",
    "\\pagebreak\n",
    "\n",
    "Clip~\\ref{clip4} shows the output after giving \\verb+doubleblind+ class option. \n",
    "\n",
    "\\def\\rulecolor{blue!70}\n",
    "\\src{Double blind article}\n",
    "\\includeclip{1}{124 567 477 670}{elstest-1pdoubleblind.pdf}%%{elstest-1p.pdf}%single author group%%doubleblind\n",
    "\\def\\rulecolor{orange}\n",
    "\n",
    "\\vspace*{-.5pc}\n",
    "The frontmatter part has further environments such as abstracts and\n",
    "keywords.  These can be marked up in the following manner:\n",
    "\n",
    "\\begin{vquote}\n",
    " \\begin{abstract}\n",
    "  In this work we demonstrate the formation of a new type of \n",
    "  polariton on the interface between a ....\n",
    " \\end{abstract}\n",
    "\\end{vquote} \n",
    "\n",
    "\\vspace*{-.5pc}\n",
    "\\begin{vquote}\n",
    " \\begin{keyword}\n",
    "  quadruple exiton \\sep polariton \\sep WGM\n",
    " \\end{keyword}\n",
    "\\end{vquote}\n",
    "\n",
    "\\noindent Each keyword shall be separated by a \\verb+\\sep+ command.\n",
    "\\textsc{msc} classifications shall be provided in \n",
    "the keyword environment with the commands\n",
    "\\verb+\\MSC+. \\verb+\\MSC+ accepts an optional\n",
    "argument to accommodate future revisions.\n",
    "eg., \\verb=\\MSC[2008]=. The default is 2000.\\looseness=-1\n",
    "\n",
    "\\subsection{New page}\n",
    "Sometimes you may need to give a page-break and start a new page after\n",
    "title, author or abstract. Following commands can be used for this\n",
    "purpose.\n",
    "\n",
    "\\begin{vquote}\n",
    "  \\newpageafter{title}\n",
    "  \\newpageafter{author}\n",
    "  \\newpageafter{abstract}\n",
    "\\end{vquote}\n",
    "\n",
    "\n",
    "\\begin{itemize}\n",
    "\\leftskip-2pc\n",
    "\\item [] {\\tt\\color{verbcolor} \\verb+\\newpageafter{title}+} typeset the title alone on one page.\n",
    "\n",
    "\\item [] {\\tt\\color{verbcolor} \\verb+\\newpageafter{author}+}  typeset the title\n",
    "and author details on one page.\n",
    "\n",
    "\\item [] {\\tt\\color{verbcolor} \\verb+\\newpageafter{abstract}+}\n",
    "typeset the title,\n",
    "author details and abstract \\& keywords one one page.\n",
    "\n",
    "\\end{itemize}\n",
    "\n",
    "\\section{Floats}\n",
    "{Figures} may be included using the command, \\verb+\\includegraphics+ in\n",
    "combination with or without its several options to further control\n",
    "graphic. \\verb+\\includegraphics+ is provided by \\file{graphic[s,x].sty}\n",
    "which is part of any standard \\LaTeX{} distribution.\n",
    "\\file{graphicx.sty} is loaded by default. \\LaTeX{} accepts figures in\n",
    "the postscript format while pdf\\LaTeX{} accepts \\file{*.pdf},\n",
    "\\file{*.mps} (metapost), \\file{*.jpg} and \\file{*.png} formats. \n",
    "pdf\\LaTeX{} does not accept graphic files in the postscript format. \n",
    "\n",
    "The \\verb+table+ environment is handy for marking up tabular\n",
    "material. If users want to use \\file{multirow.sty},\n",
    "\\file{array.sty}, etc., to fine control/enhance the tables, they\n",
    "are welcome to load any package of their choice and\n",
    "\\file{elsarticle.cls} will work in combination with all loaded\n",
    "packages.\n",
    "\n",
    "\\section[Theorem and ...]{Theorem and theorem like environments}\n",
    "\n",
    "\\file{elsarticle.cls} provides a few shortcuts to format theorems and\n",
    "theorem-like environments with ease. In all commands the options that\n",
    "are used with the \\verb+\\newtheorem+ command will work exactly in the same\n",
    "manner. \\file{elsarticle.cls} provides three commands to format theorem or\n",
    "theorem-like environments: \n",
    "\n",
    "\\begin{vquote}\n",
    " \\newtheorem{thm}{Theorem}\n",
    " \\newtheorem{lem}[thm]{Lemma}\n",
    " \\newdefinition{rmk}{Remark}\n",
    " \\newproof{pf}{Proof}\n",
    " \\newproof{pot}{Proof of Theorem \\ref{thm2}}\n",
    "\\end{vquote}\n",
    "\n",
    "The \\verb+\\newtheorem+ command formats a\n",
    "theorem in \\LaTeX's default style with italicized font, bold font\n",
    "for theorem heading and theorem number at the right hand side of the\n",
    "theorem heading.  It also optionally accepts an argument which\n",
    "will be printed as an extra heading in parentheses. \n",
    "\n",
    "\\begin{vquote}\n",
    "  \\begin{thm} \n",
    "   For system (8), consensus can be achieved with \n",
    "   $\\|T_{\\omega z}$\n",
    "   ...\n",
    "     \\begin{eqnarray}\\label{10}\n",
    "     ....\n",
    "     \\end{eqnarray}\n",
    "  \\end{thm}\n",
    "\\end{vquote}  \n",
    "\n",
    "Clip~\\ref{clip5} will show you how some text enclosed between the\n",
    "above code\\goodbreak \\noindent looks like:\n",
    "\n",
    "\\vspace*{6pt}\n",
    "\\def\\rulecolor{blue!70}\n",
    "\\src{{\\ttfamily\\color{verbcolor}\\bs newtheorem}}\n",
    "\\includeclip{2}{1 1 453 120}{jfigs.pdf}\n",
    "\\def\\rulecolor{orange}\n",
    "\n",
    "The \\verb+\\newdefinition+ command is the same in\n",
    "all respects as its\\linebreak \\verb+\\newtheorem+ counterpart except that\n",
    "the font shape is roman instead of italic.  Both\n",
    "\\verb+\\newdefinition+ and \\verb+\\newtheorem+ commands\n",
    "automatically define counters for the environments defined.\n",
    "\n",
    "\\vspace*{6pt}\n",
    "\\def\\rulecolor{blue!70}\n",
    "\\src{{\\ttfamily\\color{verbcolor}\\bs newdefinition}}\n",
    "\\includeclip{1}{1 1 453 105}{jfigs.pdf}\n",
    "\\def\\rulecolor{orange}\n",
    "\n",
    "The \\verb+\\newproof+ command defines proof environments with\n",
    "upright font shape.  No counters are defined. \n",
    "\n",
    "\\vspace*{6pt}\n",
    "\\def\\rulecolor{blue!70}\n",
    "\\src{{\\ttfamily\\color{verbcolor}\\bs newproof}}\n",
    "\\includeclip{3}{1 1 453 65}{jfigs.pdf}\n",
    "\\def\\rulecolor{orange}\n",
    "\n",
    "Users can also make use of \\verb+amsthm.sty+ which will override\n",
    "all the default definitions described above.\n",
    "\n",
    "\\section[Enumerated ...]{Enumerated and Itemized Lists}\n",
    "\\file{elsarticle.cls} provides an extended list processing macros\n",
    "which makes the usage a bit more user friendly than the default\n",
    "\\LaTeX{} list macros.   With an optional argument to the\n",
    "\\verb+\\begin{enumerate}+ command, you can change the list counter\n",
    "type and its attributes.\n",
    "\n",
    "\\begin{vquote}\n",
    " \\begin{enumerate}[1.]\n",
    " \\item The enumerate environment starts with an optional\n",
    "   argument `1.', so that the item counter will be suffixed\n",
    "   by a period.\n",
    " \\item You can use `a)' for alphabetical counter and '(i)' for\n",
    "   roman counter.\n",
    "  \\begin{enumerate}[a)]\n",
    "    \\item Another level of list with alphabetical counter.\n",
    "    \\item One more item before we start another.\n",
    "\\end{vquote}\n",
    "\n",
    "\\def\\rulecolor{blue!70}\n",
    "\\src{List -- Enumerate}\n",
    "\\includeclip{4}{1 1 453 185}{jfigs.pdf}\n",
    "\\def\\rulecolor{orange}\n",
    "\n",
    "Further, the enhanced list environment allows one to prefix a\n",
    "string like `step' to all the item numbers.  \n",
    "\n",
    "\\begin{vquote}\n",
    " \\begin{enumerate}[Step 1.]\n",
    "  \\item This is the first step of the example list.\n",
    "  \\item Obviously this is the second step.\n",
    "  \\item The final step to wind up this example.\n",
    " \\end{enumerate}\n",
    "\\end{vquote}\n",
    "\n",
    "\\def\\rulecolor{blue!70}\n",
    "\\src{List -- enhanced}\n",
    "\\includeclip{5}{1 1 313 83}{jfigs.pdf}\n",
    "\\def\\rulecolor{orange}\n",
    "\n",
    "\n",
    "\\section{Cross-references}\n",
    "In electronic publications, articles may be internally\n",
    "hyperlinked. Hyperlinks are generated from proper\n",
    "cross-references in the article.  For example, the words\n",
    "\\textcolor{black!80}{Fig.~1} will never be more than simple text,\n",
    "whereas the proper cross-reference \\verb+\\ref{tiger}+ may be\n",
    "turned into a hyperlink to the figure itself:\n",
    "\\textcolor{blue}{Fig.~1}.  In the same way,\n",
    "the words \\textcolor{blue}{Ref.~[1]} will fail to turn into a\n",
    "hyperlink; the proper cross-reference is \\verb+\\cite{Knuth96}+.\n",
    "Cross-referencing is possible in \\LaTeX{} for sections,\n",
    "subsections, formulae, figures, tables, and literature\n",
    "references.\n",
    "\n",
    "\\section[Mathematical ...]{Mathematical symbols and formulae}\n",
    "\n",
    "Many physical/mathematical sciences authors require more\n",
    "mathematical symbols than the few that are provided in standard\n",
    "\\LaTeX. A useful package for additional symbols is the\n",
    "\\file{amssymb} package, developed by the American Mathematical\n",
    "Society. This package includes such oft-used symbols as\n",
    "$\\lesssim$ (\\verb+\\lesssim+), $\\gtrsim$ (\\verb+\\gtrsim+)  or \n",
    "$\\hbar$ (\\verb+\\hbar+). Note that your \\TeX{}\n",
    "system should have the \\file{msam} and \\file{msbm} fonts installed. If\n",
    "you need only a few symbols, such as $\\Box$ (\\verb+\\Box+), you might try the\n",
    "package \\file{latexsym}.\n",
    "\n",
    "Another point which would require authors' attention is the\n",
    "breaking up of long equations.  When you use\n",
    "\\file{elsarticle.cls} for formatting your submissions in the \n",
    "\\verb+preprint+ mode, the document is formatted in single column\n",
    "style with a text width of 384pt or 5.3in.  When this document is\n",
    "formatted for final print and if the journal happens to be a double column\n",
    "journal, the text width will be reduced to 224pt at for 3+\n",
    "double column and 5+ journals respectively. All the nifty \n",
    "fine-tuning in equation breaking done by the author goes to waste in\n",
    "such cases.  Therefore, authors are requested to check this\n",
    "problem by typesetting their submissions in final format as well\n",
    "just to see if their equations are broken at appropriate places,\n",
    "by changing appropriate options in the document class loading\n",
    "command, which is explained in section~\\ref{sec:usage},\n",
    "\\nameref{sec:usage}. This allows authors to fix any equation breaking\n",
    "problem before submission for publication.\n",
    "\\file{elsarticle.cls} supports formatting the author submission\n",
    "in different types of final format.  This is further discussed in\n",
    "section \\ref{sec:final}, \\nameref{sec:final}.\n",
    "\n",
    "\n",
    "\\subsection*{Displayed equations and double column journals}\n",
    "\n",
    "Many Elsevier journals print their text in two columns. Since\n",
    "the preprint layout uses a larger line width than such columns,\n",
    "the formulae are too wide for the line width in print. Here is an\n",
    "example of an equation  (see equation 6) which is perfect in a\n",
    "single column preprint format:\n",
    "\n",
    "\\bigskip\n",
    "\\setlength\\Sep{6pt}\n",
    "\\src{See equation (6) }\n",
    "\\def\\rulecolor{blue!70}\n",
    "%\\includeclip{<page>}{l b scale }{file.pdf}\n",
    "\\includeclip{4}{105 500 500 700}{1psingleauthorgroup.pdf}\n",
    "\\def\\rulecolor{orange}\n",
    "                 \t\n",
    "\\noindent When this document is typeset for publication in a\n",
    "model 3+ journal with double columns, the equation will overlap\n",
    "the second column text matter if the equation is not broken at\n",
    "the appropriate location.\n",
    "\n",
    "\\vspace*{6pt}\n",
    "\\def\\rulecolor{blue!70}\n",
    "\\src{See equation (6) overprints into second column}\n",
    "\\includeclip{3}{59 421 532 635}{elstest-3pd.pdf}\n",
    "\\def\\rulecolor{orange}\n",
    "\\vspace*{6pt}\n",
    "\n",
    "\\noindent The typesetter will try to break the equation which\n",
    "need not necessarily be to the liking of the author or as it\n",
    "happens, typesetter's break point may be semantically incorrect.\n",
    "Therefore, authors may check their submissions for the incidence\n",
    "of such long equations and break the equations at the correct\n",
    "places so that the final typeset copy will be as they wish.\n",
    "\n",
    "\\section{Bibliography}\n",
    "\n",
    "Three bibliographic style files (\\verb+*.bst+) are provided ---\n",
    "\\file{elsarticle-num.bst}, \\file{elsarticle-num-names.bst} and\n",
    "\\file{elsarticle-harv.bst} --- the first one can be used for the\n",
    "numbered scheme, second one for numbered with new options of \n",
    "\\file{natbib.sty}. The third one is for the author year\n",
    "scheme.\n",
    "\n",
    "In \\LaTeX{} literature, references are listed in the\n",
    "\\verb+thebibliography+ environment.  Each reference is a\n",
    "\\verb+\\bibitem+ and each \\verb+\\bibitem+ is identified by a label,\n",
    "by which it can be cited in the text:\n",
    "\n",
    "\\verb+\\bibitem[Elson et al.(1996)]{ESG96}+ is cited as\n",
    "\\verb+\\citet{ESG96}+. \n",
    "\n",
    "\\noindent In connection with cross-referencing and\n",
    "possible future hyperlinking it is not a good idea to collect\n",
    "more that one literature item in one \\verb+\\bibitem+.  The\n",
    "so-called Harvard or author-year style of referencing is enabled\n",
    "by the \\LaTeX{} package \\file{natbib}. With this package the\n",
    "literature can be cited as follows:\n",
    "\n",
    "\\begin{enumerate}[\\textbullet]\n",
    "\\item Parenthetical: \\verb+\\citep{WB96}+ produces (Wettig \\& Brown, 1996).\n",
    "\\item Textual: \\verb+\\citet{ESG96}+ produces Elson et al. (1996).\n",
    "\\item An affix and part of a reference:\n",
    "\\verb+\\citep[e.g.][Ch. 2]{Gea97}+ produces (e.g. Governato et\n",
    "al., 1997, Ch. 2).\n",
    "\\end{enumerate}\n",
    "\n",
    "In the numbered scheme of citation, \\verb+\\cite{<label>}+ is used,\n",
    "since \\verb+\\citep+ or \\verb+\\citet+ has no relevance in the numbered\n",
    "scheme.  \\file{natbib} package is loaded by \\file{elsarticle} with\n",
    "\\verb+numbers+ as default option.  You can change this to author-year\n",
    "or harvard scheme by adding option \\verb+authoryear+ in the class\n",
    "loading command.  If you want to use more options of the \\file{natbib}\n",
    "package, you can do so with the \\verb+\\biboptions+ command, which is\n",
    "described in the section \\ref{sec:usage}, \\nameref{sec:usage}.  For\n",
    "details of various options of the \\file{natbib} package, please take a\n",
    "look at the \\file{natbib} documentation, which is part of any standard\n",
    "\\LaTeX{} installation.\n",
    "\n",
    "In addition to the above standard \\verb+.bst+ files, there are 10\n",
    "journal-specific \\verb+.bst+ files also available.\n",
    "Instruction for using these \\verb+.bst+ files can be found at \n",
    "\\href{http://support.stmdocs.in/wiki/index.php?title=Model-wise_bibliographic_style_files}\n",
    "{http://support.stmdocs.in}\n",
    "\n",
    "\\section{Graphical abstract and highlights}\n",
    "A template for adding graphical abstract and highlights are available\n",
    "now. This will appear as the first two pages of the PDF before the\n",
    "article content begins.\n",
    "\n",
    "\\pagebreak\n",
    "Please refer below to see how to code them.\n",
    "\n",
    "\\begin{vquote}\n",
    "....\n",
    "....\n",
    "\n",
    "\\end{abstract}\n",
    "\n",
    "%%Graphical abstract\n",
    "\\begin{graphicalabstract}\n",
    "%\\includegraphics{grabs}\n",
    "\\end{graphicalabstract}\n",
    "\n",
    "%%Research highlights\n",
    "\\begin{highlights}\n",
    "\\item Research highlight 1\n",
    "\\item Research highlight 2\n",
    "\\end{highlights}\n",
    "\n",
    "\\begin{keyword}\n",
    "%% keywords here, in the form: keyword \\sep keyword\n",
    "....\n",
    "....\n",
    "\\end{vquote}\n",
    "\n",
    "\\section{Final print}\\label{sec:final}\n",
    "\n",
    "The authors can format their submission to the page size and margins\n",
    "of their preferred journal.  \\file{elsarticle} provides four\n",
    "class options for the same. But it does not mean that using these\n",
    "options you can emulate the exact page layout of the final print copy. \n",
    "\n",
    "\n",
    "\\lmrgn=3em\n",
    "\\begin{description}\n",
    "\\item [\\texttt{1p}:] $1+$ journals with a text area of\n",
    "384pt $\\times$ 562pt or 13.5cm $\\times$ 19.75cm or 5.3in $\\times$\n",
    "7.78in, single column style only.\n",
    "\n",
    "\\item [\\texttt{3p}:] $3+$ journals with a text area of 468pt\n",
    "$\\times$ 622pt or 16.45cm $\\times$ 21.9cm or 6.5in $\\times$\n",
    "8.6in, single column style.\n",
    "\n",
    "\\item [\\texttt{twocolumn}:] should be used along with 3p option if the\n",
    "journal is $3+$ with the same text area as above, but double column\n",
    "style. \n",
    "\n",
    "\\item [\\texttt{5p}:] $5+$ with text area of 522pt $\\times$\n",
    "682pt or 18.35cm $\\times$ 24cm or 7.22in $\\times$ 9.45in,\n",
    "double column style only.\n",
    "\\end{description}\n",
    "\n",
    "Following pages have the clippings of different parts of\n",
    "the title page of different journal models typeset in final\n",
    "format.\n",
    "\n",
    "Model $1+$ and $3+$  will have the same look and\n",
    "feel in the typeset copy when presented in this document. That is\n",
    "also the case with the double column $3+$ and $5+$ journal article\n",
    "pages. The only difference will be wider text width of\n",
    "higher models.  Therefore we will look at the\n",
    "different portions of a typical single column journal page and\n",
    "that of a double column article in the final format.\n",
    "\n",
    "\n",
    "\\begin{center}\n",
    "\\hypertarget{bsc}{}\n",
    "\\hyperlink{sc}{\n",
    "{\\bf [Specimen single column article -- Click here]}\n",
    "}\n",
    "\n",
    "\n",
    "\\hypertarget{bsc}{}\n",
    "\\hyperlink{dc}{\n",
    "{\\bf [Specimen double column article -- Click here]}\n",
    "}\n",
    "\\end{center}\n",
    "\n",
    "\\src{}\\hypertarget{sc}{}\n",
    "\\def\\rulecolor{blue!70}\n",
    "\\hyperlink{bsc}{\\includeclip{1}{88 120 514 724}{elstest-1p.pdf}}\n",
    "\\def\\rulecolor{orange}\n",
    "\n",
    "\\src{}\\hypertarget{dc}{}\n",
    "\\def\\rulecolor{blue!70}\n",
    "\\hyperlink{bsc}{\\includeclip{1}{27 61 562 758}{elstest-5p.pdf}}\n",
    "\\def\\rulecolor{orange}\n",
    "\n",
    "\\end{document}\n",
    "\n",
    "\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "try:\n",
    "    TS.TexSoup(pre_format(min_example1), tolerance=1)\n",
    "except AssertionError as e:\n",
    "    print(e)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ef8d4824-1402-410c-bcde-50499bd8d625",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command \\item invalid in math mode.\n"
     ]
    }
   ],
   "source": [
    "# \\verb{char}...{char} is also an issue for parser\n",
    "# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\n",
    "min_example2=r\"\"\"\n",
    "%% \n",
    "%% Copyright 2007-2019 Elsevier Ltd\n",
    "%% \n",
    "%% This file is part of the 'Elsarticle Bundle'.\n",
    "%% ---------------------------------------------\n",
    "%% \n",
    "%% It may be distributed under the conditions of the LaTeX Project Public\n",
    "%% License, either version 1.2 of this license or (at your option) any\n",
    "%% later version.  The latest version of this license is in\n",
    "%%    http://www.latex-project.org/lppl.txt\n",
    "%% and version 1.2 or later is part of all distributions of LaTeX\n",
    "%% version 1999/12/01 or later.\n",
    "%% \n",
    "%% The list of all files belonging to the 'Elsarticle Bundle' is\n",
    "%% given in the file `manifest.txt'.\n",
    "%%\n",
    "%% $Id: elsdoc.tex 160 2019-01-14 09:25:49Z rishi $\n",
    "%%\n",
    "\\documentclass[a4paper,12pt]{article}\n",
    "\n",
    "\\usepackage[xcolor,qtwo]{rvdtx}\n",
    "\\usepackage{multicol}\n",
    "\\usepackage{color}\n",
    "\\usepackage{xspace}\n",
    "\\usepackage{pdfwidgets}\n",
    "\\usepackage{enumerate}\n",
    "\n",
    "\\def\\ttdefault{cmtt}\n",
    "\n",
    "\\headsep4pc\n",
    "\n",
    "\\makeatletter\n",
    "\\def\\bs{\\expandafter\\@gobble\\string\\\\}\n",
    "\\def\\lb{\\expandafter\\@gobble\\string\\{}\n",
    "\\def\\rb{\\expandafter\\@gobble\\string\\}}\n",
    "\\def\\@pdfauthor{C.V.Radhakrishnan}\n",
    "\\def\\@pdftitle{elsarticle.cls -- A documentation}\n",
    "\\def\\@pdfsubject{Document formatting with elsarticle.cls}\n",
    "\\def\\@pdfkeywords{LaTeX, Elsevier Ltd, document class}\n",
    "\\def\\file#1{\\textsf{#1}\\xspace}\n",
    "\n",
    "%\\def\\LastPage{19}\n",
    "\n",
    "\\DeclareRobustCommand{\\LaTeX}{L\\kern-.26em%\n",
    "        {\\sbox\\z@ T%\n",
    "         \\vbox to\\ht\\z@{\\hbox{\\check@mathfonts\n",
    "           \\fontsize\\sf@size\\z@\n",
    "           \\math@fontsfalse\\selectfont\n",
    "          A\\,}%\n",
    "         \\vss}%\n",
    "        }%\n",
    "     \\kern-.15em%\n",
    "    \\TeX}\n",
    "\\makeatother\n",
    "\n",
    "\\def\\figurename{Clip}\n",
    "\n",
    "\\setcounter{tocdepth}{1}\n",
    "\n",
    "\\begin{document}\n",
    "\n",
    "\\def\\testa{This is a specimen document. }\n",
    "\\def\\testc{\\testa\\testa\\testa\\testa}\n",
    "\\def\\testb{\\testc\\testc\\testc\\testc\\testc}\n",
    "\\long\\def\\test{\\testb\\par\\testb\\par\\testb\\par}\n",
    "\n",
    "\\pinclude{\\copy\\contbox\\printSq{\\LastPage}}\n",
    "\n",
    "\\title{elsarticle.cls -- A better way to format your document}\n",
    "\n",
    "\\author{Elsevier Ltd}\n",
    "\\contact{elsarticle@stmdocs.in}\n",
    "\n",
    "\\version{3.2}\n",
    "\\date{\\today}\n",
    "\\maketitle\n",
    "\n",
    "\\section{Introduction}\n",
    "\n",
    "\\file{elsarticle.cls} is a thoroughly re-written document class\n",
    "for formatting \\LaTeX{} submissions to Elsevier journals.\n",
    "The class uses the environments and commands defined in \\LaTeX{} kernel\n",
    "without any change in the signature so that clashes with other\n",
    "contributed \\LaTeX{} packages such as \\file{hyperref.sty},\n",
    "\\file{preview-latex.sty}, etc., will be minimal.\n",
    "\\file{elsarticle.cls} is primarily built upon the default\n",
    "\\file{article.cls}.  This class depends on the following packages\n",
    "for its proper functioning:\n",
    "\n",
    "\\begin{enumerate}\n",
    "\\item \\file{natbib.sty} for citation processing;\n",
    "\\item \\file{geometry.sty} for margin settings;\n",
    "\\item \\file{fleqn.clo} for left aligned equations;\n",
    "\\item \\file{graphicx.sty} for graphics inclusion;\n",
    "\\item \\file{txfonts.sty} optional font package, if the document is to\n",
    "  be formatted with Times and compatible math fonts;\n",
    "\\item \\file{hyperref.sty} optional packages if hyperlinking is\n",
    "  required in the document;\n",
    "%*%\n",
    "\\item \\file{endfloat.sty} optional packages if floats to be placed at\n",
    " end of the PDF.\n",
    "\\end{enumerate}\n",
    "\n",
    "All the above packages (except some optional packages) are part of any\n",
    "standard \\LaTeX{} installation. Therefore, the users need not be\n",
    "bothered about downloading any extra packages.  Furthermore, users are\n",
    "free to make use of \\textsc{ams} math packages such as\n",
    "\\file{amsmath.sty}, \\file{amsthm.sty}, \\file{amssymb.sty},\n",
    "\\file{amsfonts.sty}, etc., if they want to.  All these packages work in\n",
    "tandem with \\file{elsarticle.cls} without any problems.\n",
    "\n",
    "\\section{Major Differences}\n",
    "\n",
    "Following are the major differences between \\file{elsarticle.cls}\n",
    "and its predecessor package, \\file{elsart.cls}:\n",
    "\n",
    "\\begin{enumerate}[\\textbullet]\n",
    "\\item \\file{elsarticle.cls} is built upon \\file{article.cls}\n",
    "while \\file{elsart.cls} is not. \\file{elsart.cls} redefines\n",
    "many of the commands in the \\LaTeX{} classes/kernel, which can\n",
    "possibly cause surprising clashes with other contributed\n",
    "\\LaTeX{} packages;\n",
    "\n",
    "\\item provides preprint document formatting by default, and\n",
    "optionally formats the document as per the final\n",
    "style of models $1+$, $3+$ and $5+$ of Elsevier journals;\n",
    "\n",
    "\\item some easier ways for formatting \\verb+list+ and\n",
    "\\verb+theorem+ environments are provided while people can still\n",
    "use \\file{amsthm.sty} package;\n",
    "\n",
    "\\item \\file{natbib.sty} is the main citation processing package\n",
    "  which can comprehensively handle all kinds of citations and\n",
    "works perfectly with \\file{hyperref.sty} in combination with\n",
    "\\file{hypernat.sty};\n",
    "\n",
    "\\item long title pages are processed correctly in preprint and\n",
    "  final formats.\n",
    "\n",
    "\\end{enumerate}\n",
    "\n",
    "\\section{Installation}\n",
    "\n",
    "The package is available at author resources page at Elsevier\n",
    "(\\url{http://www.elsevier.com/locate/latex}).\n",
    "It can also be found in any of the nodes of the Comprehensive\n",
    "\\TeX{} Archive Network (\\textsc{ctan}), one of the primary nodes\n",
    "being\n",
    "\\url{http://tug.ctan.org/tex-archive/macros/latex/contrib/elsarticle/}.\n",
    "Please download the \\file{elsarticle.dtx} which is a composite\n",
    "class with documentation and \\file{elsarticle.ins} which is the\n",
    "\\LaTeX{} installer file. When we compile the\n",
    "\\file{elsarticle.ins} with \\LaTeX{} it provides the class file,\n",
    "\\file{elsarticle.cls} by\n",
    "stripping off all the documentation from the \\verb+*.dtx+ file.\n",
    "The class may be moved or copied to a place, usually,\n",
    "\\verb+$TEXMF/tex/latex/elsevier/+, %$%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "or a folder which will be read                   \n",
    "by \\LaTeX{} during document compilation.  The \\TeX{} file\n",
    "database needs updation after moving/copying class file.  Usually,\n",
    "we use commands like \\verb+mktexlsr+ or \\verb+texhash+ depending\n",
    "upon the distribution and operating system.\n",
    "\n",
    "\n",
    "\\section{Usage}\\label{sec:usage}\n",
    "The class should be loaded with the command:\n",
    "\n",
    "\\begin{vquote}\n",
    " \\documentclass[<options>]{elsarticle}\n",
    "\\end{vquote}\n",
    "\n",
    "\\noindent where the \\verb+options+ can be the following:\n",
    "\n",
    "\n",
    "\\begin{description}\n",
    "\n",
    "\\item [{\\tt\\color{verbcolor} preprint}]  default option which format the\n",
    "  document for submission to Elsevier journals.\n",
    "\n",
    "\\item [{\\tt\\color{verbcolor} review}]  similar to the \\verb+preprint+\n",
    "option, but increases the baselineskip to facilitate easier review\n",
    "process.\n",
    "\n",
    "\\item [{\\tt\\color{verbcolor} 1p}]  formats the article to the look and\n",
    "feel of the final format of model 1+ journals. This is always single\n",
    "column style.\n",
    "\n",
    "\\item [{\\tt\\color{verbcolor} 3p}] formats the article to the look and\n",
    "feel of the final format of model 3+ journals. If the journal is a two\n",
    "column model, use \\verb+twocolumn+ option in combination.\n",
    "\n",
    "\\item [{\\tt\\color{verbcolor} 5p}] formats for model 5+ journals. This\n",
    "is always of two column style.\n",
    "\n",
    "\\item [{\\tt\\color{verbcolor} authoryear}] author-year citation style of\n",
    "\\file{natbib.sty}. If you want to add extra options of\n",
    "\\file{natbib.sty}, you may use the options as comma delimited strings\n",
    "as arguments to \\verb+\\biboptions+ command. An example would be:\n",
    "\\end{description}\n",
    "\n",
    "\\begin{vquote}\n",
    " \\biboptions{longnamesfirst,angle,semicolon}\n",
    "\\end{vquote}\n",
    "\n",
    "\\begin{description}\n",
    "\\item [{\\tt\\color{verbcolor} number}] numbered citation style. Extra options\n",
    "  can be loaded with\\linebreak \\verb+\\biboptions+ command.\n",
    "\n",
    "\\item [{\\tt\\color{verbcolor} sort\\&compress}] sorts and compresses the\n",
    "numbered citations. For example, citation [1,2,3] will become [1--3].\n",
    "\n",
    "\\item [{\\tt\\color{verbcolor} longtitle}] if front matter is unusually long, use\n",
    "  this option to split the title page across pages with the correct\n",
    "placement of title and author footnotes in the first page.\n",
    "\n",
    "\\item [{\\tt\\color{verbcolor} times}] loads \\file{txfonts.sty}, if\n",
    "available in the system to use Times and compatible math fonts.\n",
    "\n",
    "%*%\n",
    "\\item [{\\tt\\color{verbcolor} reversenotenum}] Use alphabets as\n",
    "author--affiliation linking labels and use numbers for author\n",
    "footnotes. By default, numbers will be used as author--affiliation\n",
    "linking labels and alphabets for author footnotes. \n",
    "\n",
    "\\item [{\\tt\\color{verbcolor} lefttitle}] To move title and\n",
    "author/affiliation block to flushleft. \\verb+centertitle+ is the\n",
    "default option which produces center alignment.\n",
    "\n",
    "\\item [{\\tt\\color{verbcolor} endfloat}] To place all floats at the end\n",
    "of the document.\n",
    "\n",
    "\\item [{\\tt\\color{verbcolor} nonatbib}] To unload natbib.sty.\n",
    "%*%\n",
    "\n",
    "\\item [{\\tt\\color{verbcolor} doubleblind}] To hide author name, \n",
    "affiliation, email address etc. for double blind refereeing purpose.\n",
    "%*%\n",
    "\n",
    "\\item[] All options of \\file{article.cls} can be used with this\n",
    "  document class.\n",
    "\n",
    "\\item[] The default options loaded are \\verb+a4paper+, \\verb+10pt+,\n",
    "  \\verb+oneside+, \\verb+onecolumn+ and \\verb+preprint+.\n",
    "\n",
    "\\end{description}\n",
    "\n",
    "\\section{Frontmatter}\n",
    "\n",
    "There are two types of frontmatter coding:\n",
    "\\begin{enumerate}[(1)]\n",
    "\\item each author is\n",
    "connected to an affiliation with a footnote marker; hence all\n",
    "authors are grouped together and affiliations follow;\n",
    "\\pagebreak\n",
    "\\item authors of same affiliations are grouped together and the\n",
    "relevant affiliation follows this group. \n",
    "\\end{enumerate}\n",
    "\n",
    "An example of coding the first type is provided below.\n",
    "\n",
    "\\begin{vquote}\n",
    " \\title{This is a specimen title\\tnoteref{t1,t2}}\n",
    " \\tnotetext[t1]{This document is the results of the research\n",
    "    project funded by the National Science Foundation.}\n",
    " \\tnotetext[t2]{The second title footnote which is a longer \n",
    "    text matter to fill through the whole text width and \n",
    "    overflow into another line in the footnotes area of the \n",
    "    first page.}\n",
    "\\end{vquote}\n",
    "\n",
    "\\begin{vquote}\n",
    "\\author[1]{Jos Migchielsen\\corref{cor1}%\n",
    "  \\fnref{fn1}}\n",
    "\\ead{J.Migchielsen@elsevier.com}\n",
    "\n",
    "\\author[2]{CV Radhakrishnan\\fnref{fn2}}\n",
    "\\ead{cvr@sayahna.org}\n",
    "\n",
    "\\author[3]{CV Rajagopal\\fnref{fn1,fn3}}\n",
    "\\ead[url]{www.stmdocs.in}\n",
    "\\end{vquote}\n",
    "\n",
    "\\begin{vquote}\n",
    " \\cortext[cor1]{Corresponding author}\n",
    " \\fntext[fn1]{This is the first author footnote.}\n",
    " \\fntext[fn2]{Another author footnote, this is a very long \n",
    "   footnote and it should be a really long footnote. But this \n",
    "   footnote is not yet sufficiently long enough to make two \n",
    "   lines of footnote text.}\n",
    " \\fntext[fn3]{Yet another author footnote.}\n",
    "\n",
    " \\address[1]{Elsevier B.V., Radarweg 29, 1043 NX Amsterdam, \n",
    "   The Netherlands}\n",
    " \\address[2]{Sayahna Foundations, JWRA 34, Jagathy, \n",
    "   Trivandrum 695014, India}\n",
    " \\address[3]{STM Document Engineering Pvt Ltd., Mepukada,\n",
    "   Malayinkil, Trivandrum 695571, India}\n",
    "\\end{vquote}\n",
    "\n",
    "The output of the above \\TeX{} source is given in Clips~\\ref{clip1} and\n",
    "\\ref{clip2}. The header portion or title area is given in\n",
    "Clip~\\ref{clip1} and the footer area is given in Clip~\\ref{clip2}.\n",
    "\n",
    "\\def\\rulecolor{blue!70}\n",
    "\\src{Header of the title page.}\n",
    "\\includeclip{1}{130 612 477 707}{1psingleauthorgroup.pdf}%%{elstest-1p.pdf}%single author group\n",
    "\\def\\rulecolor{orange}\n",
    "\n",
    "\\def\\rulecolor{blue!70}\n",
    "\\src{Footer of the title page.}\n",
    "\\includeclip{1}{93 135 499 255}{1pseperateaug.pdf}%%{elstest-1p.pdf}%single author group\n",
    "\\def\\rulecolor{orange}\n",
    "\n",
    "Most of the commands such as \\verb+\\title+, \\verb+\\author+,\n",
    "\\verb+\\address+ are self explanatory.  Various components are\n",
    "linked to each other by a label--reference mechanism; for\n",
    "instance, title footnote is linked to the title with a footnote\n",
    "mark generated by referring to the \\verb+\\label+ string of\n",
    "the \\verb=\\tnotetext=.  We have used similar commands\n",
    "such as \\verb=\\tnoteref= (to link title note to title);\n",
    "\\verb=\\corref= (to link corresponding author text to\n",
    "corresponding author); \\verb=\\fnref= (to link footnote text to\n",
    "the relevant author names).  \\TeX{} needs two compilations to\n",
    "resolve the footnote marks in the preamble part.  \n",
    "Given below are the syntax of various note marks and note texts.\n",
    "\n",
    "\n",
    "\\begin{vquote}\n",
    "  \\tnoteref{<label(s)>}\n",
    "  \\corref{<label(s)>}\n",
    "  \\fnref{<label(s)>}\n",
    "  \\tnotetext[<label>]{<title note text>}\n",
    "  \\cortext[<label>]{<corresponding author note text>}\n",
    "  \\fntext[<label>]{<author footnote text>}\n",
    "\\end{vquote}\n",
    "\n",
    "\\noindent where \\verb=<label(s)>= can be either one or more comma\n",
    "delimited label strings. The optional arguments to the\n",
    "\\verb=\\author= command holds the ref label(s) of the address(es)\n",
    "to which the author is affiliated while each \\verb=\\address=\n",
    "command can have an optional argument of a label. In the same\n",
    "manner, \\verb=\\tnotetext=, \\verb=\\fntext=, \\verb=\\cortext= will\n",
    "have optional arguments as their respective labels and note text\n",
    "as their mandatory argument.\n",
    "\n",
    "The following example code provides the markup of the second type\n",
    "of author-affiliation.\n",
    "\n",
    "\\begin{vquote}\n",
    "\\author{Jos Migchielsen\\corref{cor1}%\n",
    "  \\fnref{fn1}}\n",
    "\\ead{J.Migchielsen@elsevier.com}\n",
    " \\address{Elsevier B.V., Radarweg 29, 1043 NX Amsterdam, \n",
    "          The Netherlands}\n",
    "\n",
    "\\author{CV Radhakrishnan\\fnref{fn2}}\n",
    "\\ead{cvr@sayahna.org}\n",
    " \\address{Sayahna Foundations, JWRA 34, Jagathy, \n",
    "    Trivandrum 695014, India}\n",
    "\n",
    "\\author{CV Rajagopal\\fnref{fn1,fn3}}\n",
    "\\ead[url]{www.stmdocs.in}\n",
    "  \\address{STM Document Engineering Pvt Ltd., Mepukada,\n",
    "    Malayinkil, Trivandrum 695571, India}\n",
    "\\end{vquote}\n",
    "\n",
    "\\vspace*{-.5pc}\n",
    "\n",
    "\\begin{vquote}\n",
    "\\cortext[cor1]{Corresponding author}\n",
    "\\fntext[fn1]{This is the first author footnote.}\n",
    "\\fntext[fn2]{Another author footnote, this is a very long \n",
    "  footnote and it should be a really long footnote. But this \n",
    "  footnote is not yet sufficiently long enough to make two lines \n",
    "  of footnote text.}\n",
    "\\end{vquote}\n",
    "\n",
    "The output of the above \\TeX{} source is given in Clip~\\ref{clip3}.\n",
    "\n",
    "\\def\\rulecolor{blue!70}\n",
    "\\src{Header of the title page..}\n",
    "\\includeclip{1}{119 563 468 709}{1pseperateaug.pdf}%%{elstest-1p.pdf}%seperate author groups\n",
    "\\def\\rulecolor{orange}\n",
    "\\pagebreak\n",
    "\n",
    "Clip~\\ref{clip4} shows the output after giving \\verb+doubleblind+ class option. \n",
    "\n",
    "\\def\\rulecolor{blue!70}\n",
    "\\src{Double blind article}\n",
    "\\includeclip{1}{124 567 477 670}{elstest-1pdoubleblind.pdf}%%{elstest-1p.pdf}%single author group%%doubleblind\n",
    "\\def\\rulecolor{orange}\n",
    "\n",
    "\\vspace*{-.5pc}\n",
    "The frontmatter part has further environments such as abstracts and\n",
    "keywords.  These can be marked up in the following manner:\n",
    "\n",
    "\\begin{vquote}\n",
    " \\begin{abstract}\n",
    "  In this work we demonstrate the formation of a new type of \n",
    "  polariton on the interface between a ....\n",
    " \\end{abstract}\n",
    "\\end{vquote} \n",
    "\n",
    "\\vspace*{-.5pc}\n",
    "\\begin{vquote}\n",
    " \\begin{keyword}\n",
    "  quadruple exiton \\sep polariton \\sep WGM\n",
    " \\end{keyword}\n",
    "\\end{vquote}\n",
    "\n",
    "\\noindent Each keyword shall be separated by a \\verb+\\sep+ command.\n",
    "\\textsc{msc} classifications shall be provided in \n",
    "the keyword environment with the commands\n",
    "\\verb+\\MSC+. \\verb+\\MSC+ accepts an optional\n",
    "argument to accommodate future revisions.\n",
    "eg., \\verb=\\MSC[2008]=. The default is 2000.\\looseness=-1\n",
    "\n",
    "\\subsection{New page}\n",
    "Sometimes you may need to give a page-break and start a new page after\n",
    "title, author or abstract. Following commands can be used for this\n",
    "purpose.\n",
    "\n",
    "\\begin{vquote}\n",
    "  \\newpageafter{title}\n",
    "  \\newpageafter{author}\n",
    "  \\newpageafter{abstract}\n",
    "\\end{vquote}\n",
    "\n",
    "\n",
    "\\begin{itemize}\n",
    "\\leftskip-2pc\n",
    "\\item [] {\\tt\\color{verbcolor} \\verb+\\newpageafter{title}+} typeset the title alone on one page.\n",
    "\n",
    "\\item [] {\\tt\\color{verbcolor} \\verb+\\newpageafter{author}+}  typeset the title\n",
    "and author details on one page.\n",
    "\n",
    "\\item [] {\\tt\\color{verbcolor} \\verb+\\newpageafter{abstract}+}\n",
    "typeset the title,\n",
    "author details and abstract \\& keywords one one page.\n",
    "\n",
    "\\end{itemize}\n",
    "\n",
    "\\section{Floats}\n",
    "{Figures} may be included using the command, \\verb+\\includegraphics+ in\n",
    "combination with or without its several options to further control\n",
    "graphic. \\verb+\\includegraphics+ is provided by \\file{graphic[s,x].sty}\n",
    "which is part of any standard \\LaTeX{} distribution.\n",
    "\\file{graphicx.sty} is loaded by default. \\LaTeX{} accepts figures in\n",
    "the postscript format while pdf\\LaTeX{} accepts \\file{*.pdf},\n",
    "\\file{*.mps} (metapost), \\file{*.jpg} and \\file{*.png} formats. \n",
    "pdf\\LaTeX{} does not accept graphic files in the postscript format. \n",
    "\n",
    "The \\verb+table+ environment is handy for marking up tabular\n",
    "material. If users want to use \\file{multirow.sty},\n",
    "\\file{array.sty}, etc., to fine control/enhance the tables, they\n",
    "are welcome to load any package of their choice and\n",
    "\\file{elsarticle.cls} will work in combination with all loaded\n",
    "packages.\n",
    "\n",
    "\\section[Theorem and ...]{Theorem and theorem like environments}\n",
    "\n",
    "\\file{elsarticle.cls} provides a few shortcuts to format theorems and\n",
    "theorem-like environments with ease. In all commands the options that\n",
    "are used with the \\verb+\\newtheorem+ command will work exactly in the same\n",
    "manner. \\file{elsarticle.cls} provides three commands to format theorem or\n",
    "theorem-like environments: \n",
    "\n",
    "\\begin{vquote}\n",
    " \\newtheorem{thm}{Theorem}\n",
    " \\newtheorem{lem}[thm]{Lemma}\n",
    " \\newdefinition{rmk}{Remark}\n",
    " \\newproof{pf}{Proof}\n",
    " \\newproof{pot}{Proof of Theorem \\ref{thm2}}\n",
    "\\end{vquote}\n",
    "\n",
    "The \\verb+\\newtheorem+ command formats a\n",
    "theorem in \\LaTeX's default style with italicized font, bold font\n",
    "for theorem heading and theorem number at the right hand side of the\n",
    "theorem heading.  It also optionally accepts an argument which\n",
    "will be printed as an extra heading in parentheses. \n",
    "\n",
    "\\begin{vquote}\n",
    "  \\begin{thm} \n",
    "   For system (8), consensus can be achieved with \n",
    "   $\\|T_{\\omega z}$\n",
    "   ...\n",
    "     \\begin{eqnarray}\\label{10}\n",
    "     ....\n",
    "     \\end{eqnarray}\n",
    "  \\end{thm}\n",
    "\\end{vquote}  \n",
    "\n",
    "Clip~\\ref{clip5} will show you how some text enclosed between the\n",
    "above code\\goodbreak \\noindent looks like:\n",
    "\n",
    "\\vspace*{6pt}\n",
    "\\def\\rulecolor{blue!70}\n",
    "\\src{{\\ttfamily\\color{verbcolor}\\bs newtheorem}}\n",
    "\\includeclip{2}{1 1 453 120}{jfigs.pdf}\n",
    "\\def\\rulecolor{orange}\n",
    "\n",
    "The \\verb+\\newdefinition+ command is the same in\n",
    "all respects as its\\linebreak \\verb+\\newtheorem+ counterpart except that\n",
    "the font shape is roman instead of italic.  Both\n",
    "\\verb+\\newdefinition+ and \\verb+\\newtheorem+ commands\n",
    "automatically define counters for the environments defined.\n",
    "\n",
    "\\vspace*{6pt}\n",
    "\\def\\rulecolor{blue!70}\n",
    "\\src{{\\ttfamily\\color{verbcolor}\\bs newdefinition}}\n",
    "\\includeclip{1}{1 1 453 105}{jfigs.pdf}\n",
    "\\def\\rulecolor{orange}\n",
    "\n",
    "The \\verb+\\newproof+ command defines proof environments with\n",
    "upright font shape.  No counters are defined. \n",
    "\n",
    "\\vspace*{6pt}\n",
    "\\def\\rulecolor{blue!70}\n",
    "\\src{{\\ttfamily\\color{verbcolor}\\bs newproof}}\n",
    "\\includeclip{3}{1 1 453 65}{jfigs.pdf}\n",
    "\\def\\rulecolor{orange}\n",
    "\n",
    "Users can also make use of \\verb+amsthm.sty+ which will override\n",
    "all the default definitions described above.\n",
    "\n",
    "\\section[Enumerated ...]{Enumerated and Itemized Lists}\n",
    "\\file{elsarticle.cls} provides an extended list processing macros\n",
    "which makes the usage a bit more user friendly than the default\n",
    "\\LaTeX{} list macros.   With an optional argument to the\n",
    "\\verb+\\begin{enumerate}+ command, you can change the list counter\n",
    "type and its attributes.\n",
    "\n",
    "\\begin{vquote}\n",
    " \\begin{enumerate}[1.]\n",
    " \\item The enumerate environment starts with an optional\n",
    "   argument `1.', so that the item counter will be suffixed\n",
    "   by a period.\n",
    " \\item You can use `a)' for alphabetical counter and '(i)' for\n",
    "   roman counter.\n",
    "  \\begin{enumerate}[a)]\n",
    "    \\item Another level of list with alphabetical counter.\n",
    "    \\item One more item before we start another.\n",
    "\\end{vquote}\n",
    "\n",
    "\\def\\rulecolor{blue!70}\n",
    "\\src{List -- Enumerate}\n",
    "\\includeclip{4}{1 1 453 185}{jfigs.pdf}\n",
    "\\def\\rulecolor{orange}\n",
    "\n",
    "Further, the enhanced list environment allows one to prefix a\n",
    "string like `step' to all the item numbers.  \n",
    "\n",
    "\\begin{vquote}\n",
    " \\begin{enumerate}[Step 1.]\n",
    "  \\item This is the first step of the example list.\n",
    "  \\item Obviously this is the second step.\n",
    "  \\item The final step to wind up this example.\n",
    " \\end{enumerate}\n",
    "\\end{vquote}\n",
    "\n",
    "\\def\\rulecolor{blue!70}\n",
    "\\src{List -- enhanced}\n",
    "\\includeclip{5}{1 1 313 83}{jfigs.pdf}\n",
    "\\def\\rulecolor{orange}\n",
    "\n",
    "\n",
    "\\section{Cross-references}\n",
    "In electronic publications, articles may be internally\n",
    "hyperlinked. Hyperlinks are generated from proper\n",
    "cross-references in the article.  For example, the words\n",
    "\\textcolor{black!80}{Fig.~1} will never be more than simple text,\n",
    "whereas the proper cross-reference \\verb+\\ref{tiger}+ may be\n",
    "turned into a hyperlink to the figure itself:\n",
    "\\textcolor{blue}{Fig.~1}.  In the same way,\n",
    "the words \\textcolor{blue}{Ref.~[1]} will fail to turn into a\n",
    "hyperlink; the proper cross-reference is \\verb+\\cite{Knuth96}+.\n",
    "Cross-referencing is possible in \\LaTeX{} for sections,\n",
    "subsections, formulae, figures, tables, and literature\n",
    "references.\n",
    "\n",
    "\\section[Mathematical ...]{Mathematical symbols and formulae}\n",
    "\n",
    "Many physical/mathematical sciences authors require more\n",
    "mathematical symbols than the few that are provided in standard\n",
    "\\LaTeX. A useful package for additional symbols is the\n",
    "\\file{amssymb} package, developed by the American Mathematical\n",
    "Society. This package includes such oft-used symbols as\n",
    "$\\lesssim$ (\\verb+\\lesssim+), $\\gtrsim$ (\\verb+\\gtrsim+)  or \n",
    "$\\hbar$ (\\verb+\\hbar+). Note that your \\TeX{}\n",
    "system should have the \\file{msam} and \\file{msbm} fonts installed. If\n",
    "you need only a few symbols, such as $\\Box$ (\\verb+\\Box+), you might try the\n",
    "package \\file{latexsym}.\n",
    "\n",
    "Another point which would require authors' attention is the\n",
    "breaking up of long equations.  When you use\n",
    "\\file{elsarticle.cls} for formatting your submissions in the \n",
    "\\verb+preprint+ mode, the document is formatted in single column\n",
    "style with a text width of 384pt or 5.3in.  When this document is\n",
    "formatted for final print and if the journal happens to be a double column\n",
    "journal, the text width will be reduced to 224pt at for 3+\n",
    "double column and 5+ journals respectively. All the nifty \n",
    "fine-tuning in equation breaking done by the author goes to waste in\n",
    "such cases.  Therefore, authors are requested to check this\n",
    "problem by typesetting their submissions in final format as well\n",
    "just to see if their equations are broken at appropriate places,\n",
    "by changing appropriate options in the document class loading\n",
    "command, which is explained in section~\\ref{sec:usage},\n",
    "\\nameref{sec:usage}. This allows authors to fix any equation breaking\n",
    "problem before submission for publication.\n",
    "\\file{elsarticle.cls} supports formatting the author submission\n",
    "in different types of final format.  This is further discussed in\n",
    "section \\ref{sec:final}, \\nameref{sec:final}.\n",
    "\n",
    "\n",
    "\\subsection*{Displayed equations and double column journals}\n",
    "\n",
    "Many Elsevier journals print their text in two columns. Since\n",
    "the preprint layout uses a larger line width than such columns,\n",
    "the formulae are too wide for the line width in print. Here is an\n",
    "example of an equation  (see equation 6) which is perfect in a\n",
    "single column preprint format:\n",
    "\n",
    "\\bigskip\n",
    "\\setlength\\Sep{6pt}\n",
    "\\src{See equation (6) }\n",
    "\\def\\rulecolor{blue!70}\n",
    "%\\includeclip{<page>}{l b scale }{file.pdf}\n",
    "\\includeclip{4}{105 500 500 700}{1psingleauthorgroup.pdf}\n",
    "\\def\\rulecolor{orange}\n",
    "                 \t\n",
    "\\noindent When this document is typeset for publication in a\n",
    "model 3+ journal with double columns, the equation will overlap\n",
    "the second column text matter if the equation is not broken at\n",
    "the appropriate location.\n",
    "\n",
    "\\vspace*{6pt}\n",
    "\\def\\rulecolor{blue!70}\n",
    "\\src{See equation (6) overprints into second column}\n",
    "\\includeclip{3}{59 421 532 635}{elstest-3pd.pdf}\n",
    "\\def\\rulecolor{orange}\n",
    "\\vspace*{6pt}\n",
    "\n",
    "\\noindent The typesetter will try to break the equation which\n",
    "need not necessarily be to the liking of the author or as it\n",
    "happens, typesetter's break point may be semantically incorrect.\n",
    "Therefore, authors may check their submissions for the incidence\n",
    "of such long equations and break the equations at the correct\n",
    "places so that the final typeset copy will be as they wish.\n",
    "\n",
    "\\section{Bibliography}\n",
    "\n",
    "Three bibliographic style files (\\verb+*.bst+) are provided ---\n",
    "\\file{elsarticle-num.bst}, \\file{elsarticle-num-names.bst} and\n",
    "\\file{elsarticle-harv.bst} --- the first one can be used for the\n",
    "numbered scheme, second one for numbered with new options of \n",
    "\\file{natbib.sty}. The third one is for the author year\n",
    "scheme.\n",
    "\n",
    "In \\LaTeX{} literature, references are listed in the\n",
    "\\verb+thebibliography+ environment.  Each reference is a\n",
    "\\verb+\\bibitem+ and each \\verb+\\bibitem+ is identified by a label,\n",
    "by which it can be cited in the text:\n",
    "\n",
    "\\verb+\\bibitem[Elson et al.(1996)]{ESG96}+ is cited as\n",
    "\\verb+\\citet{ESG96}+. \n",
    "\n",
    "\\noindent In connection with cross-referencing and\n",
    "possible future hyperlinking it is not a good idea to collect\n",
    "more that one literature item in one \\verb+\\bibitem+.  The\n",
    "so-called Harvard or author-year style of referencing is enabled\n",
    "by the \\LaTeX{} package \\file{natbib}. With this package the\n",
    "literature can be cited as follows:\n",
    "\n",
    "\\begin{enumerate}[\\textbullet]\n",
    "\\item Parenthetical: \\verb+\\citep{WB96}+ produces (Wettig \\& Brown, 1996).\n",
    "\\item Textual: \\verb+\\citet{ESG96}+ produces Elson et al. (1996).\n",
    "\\item An affix and part of a reference:\n",
    "\\verb+\\citep[e.g.][Ch. 2]{Gea97}+ produces (e.g. Governato et\n",
    "al., 1997, Ch. 2).\n",
    "\\end{enumerate}\n",
    "\n",
    "In the numbered scheme of citation, \\verb+\\cite{<label>}+ is used,\n",
    "since \\verb+\\citep+ or \\verb+\\citet+ has no relevance in the numbered\n",
    "scheme.  \\file{natbib} package is loaded by \\file{elsarticle} with\n",
    "\\verb+numbers+ as default option.  You can change this to author-year\n",
    "or harvard scheme by adding option \\verb+authoryear+ in the class\n",
    "loading command.  If you want to use more options of the \\file{natbib}\n",
    "package, you can do so with the \\verb+\\biboptions+ command, which is\n",
    "described in the section \\ref{sec:usage}, \\nameref{sec:usage}.  For\n",
    "details of various options of the \\file{natbib} package, please take a\n",
    "look at the \\file{natbib} documentation, which is part of any standard\n",
    "\\LaTeX{} installation.\n",
    "\n",
    "In addition to the above standard \\verb+.bst+ files, there are 10\n",
    "journal-specific \\verb+.bst+ files also available.\n",
    "Instruction for using these \\verb+.bst+ files can be found at \n",
    "\\href{http://support.stmdocs.in/wiki/index.php?title=Model-wise_bibliographic_style_files}\n",
    "{http://support.stmdocs.in}\n",
    "\n",
    "\\section{Graphical abstract and highlights}\n",
    "A template for adding graphical abstract and highlights are available\n",
    "now. This will appear as the first two pages of the PDF before the\n",
    "article content begins.\n",
    "\n",
    "\\pagebreak\n",
    "Please refer below to see how to code them.\n",
    "\n",
    "\\begin{vquote}\n",
    "....\n",
    "....\n",
    "\n",
    "\\end{abstract}\n",
    "\n",
    "%%Graphical abstract\n",
    "\\begin{graphicalabstract}\n",
    "%\\includegraphics{grabs}\n",
    "\\end{graphicalabstract}\n",
    "\n",
    "%%Research highlights\n",
    "\\begin{highlights}\n",
    "\\item Research highlight 1\n",
    "\\item Research highlight 2\n",
    "\\end{highlights}\n",
    "\n",
    "\\begin{keyword}\n",
    "%% keywords here, in the form: keyword \\sep keyword\n",
    "....\n",
    "....\n",
    "\\end{vquote}\n",
    "\n",
    "\\section{Final print}\\label{sec:final}\n",
    "\n",
    "The authors can format their submission to the page size and margins\n",
    "of their preferred journal.  \\file{elsarticle} provides four\n",
    "class options for the same. But it does not mean that using these\n",
    "options you can emulate the exact page layout of the final print copy. \n",
    "\n",
    "\n",
    "\\lmrgn=3em\n",
    "\\begin{description}\n",
    "\\item [\\texttt{1p}:] $1+$ journals with a text area of\n",
    "384pt $\\times$ 562pt or 13.5cm $\\times$ 19.75cm or 5.3in $\\times$\n",
    "7.78in, single column style only.\n",
    "\n",
    "\\item [\\texttt{3p}:] $3+$ journals with a text area of 468pt\n",
    "$\\times$ 622pt or 16.45cm $\\times$ 21.9cm or 6.5in $\\times$\n",
    "8.6in, single column style.\n",
    "\n",
    "\\item [\\texttt{twocolumn}:] should be used along with 3p option if the\n",
    "journal is $3+$ with the same text area as above, but double column\n",
    "style. \n",
    "\n",
    "\\item [\\texttt{5p}:] $5+$ with text area of 522pt $\\times$\n",
    "682pt or 18.35cm $\\times$ 24cm or 7.22in $\\times$ 9.45in,\n",
    "double column style only.\n",
    "\\end{description}\n",
    "\n",
    "Following pages have the clippings of different parts of\n",
    "the title page of different journal models typeset in final\n",
    "format.\n",
    "\n",
    "Model $1+$ and $3+$  will have the same look and\n",
    "feel in the typeset copy when presented in this document. That is\n",
    "also the case with the double column $3+$ and $5+$ journal article\n",
    "pages. The only difference will be wider text width of\n",
    "higher models.  Therefore we will look at the\n",
    "different portions of a typical single column journal page and\n",
    "that of a double column article in the final format.\n",
    "\n",
    "\n",
    "\\begin{center}\n",
    "\\hypertarget{bsc}{}\n",
    "\\hyperlink{sc}{\n",
    "{\\bf [Specimen single column article -- Click here]}\n",
    "}\n",
    "\n",
    "\n",
    "\\hypertarget{bsc}{}\n",
    "\\hyperlink{dc}{\n",
    "{\\bf [Specimen double column article -- Click here]}\n",
    "}\n",
    "\\end{center}\n",
    "\n",
    "\\src{}\\hypertarget{sc}{}\n",
    "\\def\\rulecolor{blue!70}\n",
    "\\hyperlink{bsc}{\\includeclip{1}{88 120 514 724}{elstest-1p.pdf}}\n",
    "\\def\\rulecolor{orange}\n",
    "\n",
    "\\src{}\\hypertarget{dc}{}\n",
    "\\def\\rulecolor{blue!70}\n",
    "\\hyperlink{bsc}{\\includeclip{1}{27 61 562 758}{elstest-5p.pdf}}\n",
    "\\def\\rulecolor{orange}\n",
    "\n",
    "\\end{document}\n",
    "\n",
    "\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "try:\n",
    "    TS.TexSoup(pre_format(min_example2), tolerance=1)\n",
    "except AssertionError as e:\n",
    "    print(e)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0419393b-a887-4716-9270-eb9b05f40a8f",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.DataFrame(np.random.randint(0,100,size=(10, 3)), columns=list('ABC')).to_csv('~/Expire/test_console_upload.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c008ea20-af5e-49c0-9304-72b3f4d0b9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_example1 == min_example2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb6110b-de7f-4241-81a0-ed39bfb5e0a9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
