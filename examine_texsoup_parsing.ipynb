{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5385a6ff-0507-42ae-8ed7-090bc79688be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/chrisjcameron/TexSoup.git@develop-main\n",
      "  Cloning https://github.com/chrisjcameron/TexSoup.git (to revision develop-main) to /private/var/folders/b4/3gwt7cpj48n9_chzk5570rc80000gp/T/pip-req-build-e422awf0\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/chrisjcameron/TexSoup.git /private/var/folders/b4/3gwt7cpj48n9_chzk5570rc80000gp/T/pip-req-build-e422awf0\n",
      "  Running command git checkout -b develop-main --track origin/develop-main\n",
      "  Switched to a new branch 'develop-main'\n",
      "  branch 'develop-main' set up to track 'origin/develop-main'.\n",
      "  Resolved https://github.com/chrisjcameron/TexSoup.git to commit 3f1333c76e38b48cf0b0def95d098922a9bee533\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: TexSoup\n",
      "  Building wheel for TexSoup (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for TexSoup: filename=TexSoup-0.3.1-py3-none-any.whl size=30273 sha256=4cd7cd510eb0e3e8fe6a3dc42f033a2b7a45e1629c256edce7acc5fc334e8871\n",
      "  Stored in directory: /private/var/folders/b4/3gwt7cpj48n9_chzk5570rc80000gp/T/pip-ephem-wheel-cache-bujenv79/wheels/44/75/a2/7b304f6fbc45ae359ac5d61530e1dd84bcd599b58371edb175\n",
      "Successfully built TexSoup\n",
      "Installing collected packages: TexSoup\n",
      "  Attempting uninstall: TexSoup\n",
      "    Found existing installation: TexSoup 0.3.1\n",
      "    Uninstalling TexSoup-0.3.1:\n",
      "      Successfully uninstalled TexSoup-0.3.1\n",
      "Successfully installed TexSoup-0.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --force-reinstall --no-deps git+https://github.com/chrisjcameron/TexSoup.git@develop-main\n",
    "#! pip install --editable /Users/cjc73/gits/arxiv/TexSoup/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cf5d0dc-f846-4026-973f-fc35f5488c1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import zipfile\n",
    "import tarfile\n",
    "import io\n",
    "import importlib\n",
    "import os\n",
    "import regex as re\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8e8fd8a-40da-4c8b-b4a5-2a9e753c85eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyperclip   #copy text to clipboard for inspecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9229d15f-0f9a-46fb-8de4-2e6bc4f31736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d172ce28-bd35-4aa2-b7e9-0566d744ae17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "# pretty print all cell's output and not just the last one\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0482c820-371e-4b81-a97c-2f10cd5fd72f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import TexSoup as TS\n",
    "from TexSoup.tokens import MATH_ENV_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a04457f2-1e95-47d5-a29d-63645a683a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/cjc73/miniconda3/envs/cforge/lib/python3.11/site-packages/TexSoup/__init__.py'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TS.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b6edafa-3ecb-4b38-b727-d26d6696235d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importlib.reload(TS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c3ebacc-89eb-454a-97c9-5068f77a0d71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LOCAL_DATA_PATH = './data/2201_00_all/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5171153-1316-4310-9251-ee1627762470",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pre_format(text):\n",
    "    '''Apply some substititions to make LaTeX easier to parse'''\n",
    "    source_text = (\n",
    "        text\n",
    "        .replace('\\\\}\\\\', '\\\\} \\\\')  # Due to escape rules \\\\ is equivalent to \\\n",
    "        .replace(')}', ') }')\n",
    "        .replace(')$', ') $')\n",
    "        #.replace(r'\\left [', r'\\left[ ')\n",
    "        #.replace(r'\\left (', r'\\left( ')\n",
    "        #.replace(r'\\left \\{', r'\\left\\{ ')\n",
    "    )\n",
    "    return source_text\n",
    "    #clean_lines = []\n",
    "    #for line in source_text.splitlines(False):\n",
    "    #    cleanline = line.strip()\n",
    "    #    if cleanline.startswith(r'\\newcommand'):\n",
    "    #        cleanline = r'%' + cleanline\n",
    "    #    elif cleanline.startswith(r'\\def'):\n",
    "    #        cleanline = r'%' + cleanline\n",
    "    #    clean_lines.append(cleanline)\n",
    "    #return '\\n'.join(clean_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6324bc82-02a7-4032-b3e5-de19e751be34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_doc_class(wrapped_file, name_match=False):\n",
    "    '''Search for document class related lines in a file  and return a code to represent the type'''\n",
    "    doc_class_pat = re.compile(r\"^\\s*\\\\document(?:style|class)\")\n",
    "    sub_doc_class = re.compile(r\"^\\s*\\\\document(?:style|class).*(?:\\{standalone\\}|\\{subfiles\\})\")\n",
    "\n",
    "    for line in wrapped_file:\n",
    "        if doc_class_pat.search(line):\n",
    "            if name_match:\n",
    "                # we can miss if there are two or more lines with documentclass \n",
    "                # and the first one is not the one that has standalone/subfile\n",
    "                if sub_doc_class.search(line):\n",
    "                    return -99999\n",
    "                return 1 #main_files[tf] = 1\n",
    "            \n",
    "    return 0 #main_files[tf] = 0\n",
    "\n",
    "\n",
    "def find_main_tex_source_in_tar(tar_path, encoding='uft-8'):\n",
    "    '''Identify the main Tex file in a tarfile.\n",
    "    \n",
    "    Args:\n",
    "        tar_path: A gzipped tar archive of a directory containing tex source and support files.\n",
    "    '''\n",
    "    \n",
    "    tex_names = set([\"paper.tex\", \"main.tex\", \"ms.tex\", \"article.tex\"])\n",
    "\n",
    "    with tarfile.open(tar_path, 'r') as in_tar:\n",
    "        tex_files = [f for f in in_tar.getnames() if f.endswith('.tex')]\n",
    "        \n",
    "        # got one file\n",
    "        if len(tex_files) == 1:\n",
    "            return tex_files[0]\n",
    "\n",
    "        main_files = {}\n",
    "        for tf in tex_files:\n",
    "            has_main_name = tf in tex_names\n",
    "            fp = in_tar.extractfile(tf)\n",
    "            wrapped_file = io.TextIOWrapper(fp, newline=None, encoding=encoding) #universal newlines\n",
    "            # does it have a doc class?\n",
    "            # get the type\n",
    "            main_files[tf] = find_doc_class(wrapped_file, name_match = has_main_name)\n",
    "            wrapped_file.close() \n",
    "        \n",
    "        # got one file with doc class\n",
    "        if len(main_files) == 1:\n",
    "            return(main_files.keys()[0])\n",
    "        \n",
    "        # account for multi-file submissions\n",
    "        return(max(main_files, key=main_files.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ae8ad8b-8fdd-45f0-92c2-70075213f2d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def soup_from_tar(tar_path, encoding='utf-8', tolerance=0):\n",
    "    tex_main = find_main_tex_source_in_tar(tar_path, encoding=encoding)\n",
    "    with tarfile.open(tar_path, 'r') as in_tar:\n",
    "        fp = in_tar.extractfile(tex_main)\n",
    "        wrapped_file = io.TextIOWrapper(fp, newline=None, encoding=encoding) #universal newlines\n",
    "        source_text = pre_format(wrapped_file.read())\n",
    "        soup = TS.TexSoup(source_text, tolerance=tolerance, skip_envs=MATH_ENV_NAMES)\n",
    "        return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d2720a35-9ddd-487d-8c83-ea8e41b6e5cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def source_from_tar(tar_path, encoding='utf-8'):\n",
    "    tex_main = find_main_tex_source_in_tar(tar_path, encoding=encoding)\n",
    "    with tarfile.open(tar_path, 'r') as in_tar:\n",
    "        fp = in_tar.extractfile(tex_main)\n",
    "        wrapped_file = io.TextIOWrapper(fp, newline=None, encoding=encoding) #universal newlines\n",
    "        source_text = pre_format(wrapped_file.read())\n",
    "        return source_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec617d2c-3d30-4546-8d1e-0e3215b32355",
   "metadata": {},
   "source": [
    "## Check a file with parse errors"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a6b801fc-d594-48dd-a522-f187ffe08a55",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85af346c-f0f4-4806-96c3-892a7b33bddf",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: ['Modeling Advection on Directed Graphs using  Mat', \"\\\\'\", 'e', 'rn Gaussian Processes for Traffic Flow']\n",
      " section: ['Introduction']\n",
      " section: ['Understanding the directed graph advection operator']\n",
      " section: ['Directed Graph Advection Mat', \"\\\\'\", 'e', 'rn Gaussian Process (DGAMGP) ']\n",
      " section: ['Numerical Results']\n",
      " section: ['Conclusions']\n",
      " section: ['Upwinding discretizations of linear advection']\n",
      " section: ['Examples of ', '$', 'L_', 'adv', '$', ' on balanced graphs resulting in finite difference discretizations of linear advection']\n",
      " section: ['Additional Experiments']\n"
     ]
    }
   ],
   "source": [
    "infile_path = \"./data/2201_00_all/2201.00001v1.tar.gz\" #'./data/2201_samp/2201.00048v1.tar.gz'\n",
    "\n",
    "text = source_from_tar(infile_path)\n",
    "pyperclip.copy(text)\n",
    "soup = soup_from_tar(infile_path, tolerance=1)\n",
    "\n",
    "\n",
    "title = soup.find('title')\n",
    "if title: print(f\"{title.name}: {title.text}\")\n",
    "for sec in soup.find_all('section'):\n",
    "    print(f' {sec.name}: {sec.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c008ea20-af5e-49c0-9304-72b3f4d0b9a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f6753f-a9f5-4f79-b054-87d4c46afeb7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab5bcbf9-305b-41a7-b283-39562489fe7c",
   "metadata": {},
   "source": [
    "## Quick check a folder of tar files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "999be077-8fdc-48e3-bdd3-65563e0b6e76",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006719112396240234,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "errors",
       "rate": null,
       "total": 405,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99100d5ddd014473b60b229dd767d3f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "errors:   0%|          | 0/405 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005033969879150391,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Progress",
       "rate": null,
       "total": 405,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d6e4a78b9f459c9a415717faefcaa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/405 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = glob.glob(f'{LOCAL_DATA_PATH}/*.tar.gz')\n",
    "files_count = len(files)\n",
    "utf_count = 0\n",
    "latin_count = 0 \n",
    "err_files = {}\n",
    "\n",
    "TOLERANCE = 0\n",
    "\n",
    "with tqdm(total=files_count, desc=\"errors\") as err_prog:\n",
    "    for tar_file in tqdm(files, desc=\"Progress\", display=True):\n",
    "        # Is it unicode?\n",
    "        try:\n",
    "            soup = soup_from_tar(tar_file, encoding='utf-8', tolerance=TOLERANCE)\n",
    "            utf_count += 1\n",
    "            continue\n",
    "        except EOFError as eof:\n",
    "            err_files[tar_file] = type(eof)\n",
    "            _ = err_prog.update(1)\n",
    "            continue\n",
    "        except UnicodeDecodeError as ue:\n",
    "            pass\n",
    "        except KeyboardInterrupt as KB_err:\n",
    "            break\n",
    "        except Exception as e:\n",
    "            err_files[tar_file] = type(e)\n",
    "            _ = err_prog.update(1)\n",
    "            continue\n",
    "\n",
    "        # Is it something else?\n",
    "        try:\n",
    "            soup = soup_from_tar(tar_file, encoding='latin-1', tolerance=TOLERANCE)\n",
    "            latin_count += 1\n",
    "            continue\n",
    "        except KeyboardInterrupt as KB_err:\n",
    "            break\n",
    "        except Exception as e:\n",
    "            err_files[tar_file] = type(e)\n",
    "            _ = err_prog.update(1)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e4a830f1-7cfa-4f64-9a50-e2e911b2c9e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405 processed, 45 failures.\n",
      "UTF8: 359; Latin1: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'./data/2201_00_all/2201.00468v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00556v2.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00560v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00035v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00823v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00892v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00491v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00295v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00875v2.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00683v2.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00441v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00931v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00685v2.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00972v1.tar.gz': EOFError,\n",
       " './data/2201_00_all/2201.00489v2.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00488v2.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00179v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00559v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00104v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00045v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00044v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00749v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00949v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00068v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00837v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00718v1.tar.gz': ValueError,\n",
       " './data/2201_00_all/2201.00875v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00683v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00062v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00325v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00556v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00460v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00488v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00489v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00138v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00685v3.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00740v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00104v2.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00864v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00907v1.tar.gz': ValueError,\n",
       " './data/2201_00_all/2201.00445v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00300v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00970v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00547v1.tar.gz': TypeError,\n",
       " './data/2201_00_all/2201.00685v1.tar.gz': TypeError}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{files_count} processed, {len(err_files)} failures.\")\n",
    "print(f\"UTF8: {utf_count}; Latin1: {latin_count}\")\n",
    "err_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e85ffb-2596-412a-9cfb-8ef432a52c67",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "source": [
    "## Scratch below here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45e8d6a6-b077-4ab4-9eb2-b09716eb27c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8fd897e-8a1c-44e8-bda8-f59f39e30ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: ['Classifying Subset Feedback Vertex Set', '\\\\\\\\', ' for ', '$', 'H', '$', '-Free Graphs']\n",
      " section: ['Introduction']\n",
      " section: ['Preliminaries']\n",
      " section: ['The Weighted Variant']\n",
      " section: ['The Unweighted Variant']\n",
      " section: ['Conclusions']\n",
      " section: ['Preliminaries']\n"
     ]
    }
   ],
   "source": [
    "TOLERANCE = 0\n",
    "infile_path = \"./data/2201_00_all/2201.00430v1.tar.gz\" #'./data/2201_samp/2201.00048v1.tar.gz'\n",
    "\n",
    "text = source_from_tar(infile_path)\n",
    "pyperclip.copy(text)\n",
    "soup = soup_from_tar(infile_path, encoding='utf-8', tolerance=TOLERANCE)\n",
    "\n",
    "\n",
    "title = soup.find('title')\n",
    "if title: print(f\"{title.name}: {title.text}\")\n",
    "for sec in soup.find_all('section'):\n",
    "    print(f' {sec.name}: {sec.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf6ba56-8143-418f-b8ff-6a341d3036c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tar_path = \"./data/2201_samp/2201.00008v2.tar.gz\"\n",
    "encoding = \"utf-8\"\n",
    "with tarfile.open(tar_path, 'r') as in_tar:\n",
    "    tex_files = [f for f in in_tar.getnames() if f.endswith('.tex')]\n",
    "\n",
    "    # got one file\n",
    "    if len(tex_files) == 1:\n",
    "        pass #return tex_files[0]\n",
    "\n",
    "    main_files = {}\n",
    "    for tf in tex_files:\n",
    "        fp = in_tar.extractfile(tf)\n",
    "        wrapped_file = io.TextIOWrapper(fp, newline=None, encoding=encoding) #universal newlines\n",
    "        # does it have a doc class?\n",
    "        # get the type\n",
    "        main_files[tf] = find_doc_class(wrapped_file)\n",
    "        wrapped_file.close() \n",
    "\n",
    "    # got one file with doc class\n",
    "    if len(main_files) == 1:\n",
    "        pass #return(main_files.keys()[0])\n",
    "\n",
    "    # account for multi-file submissions\n",
    "    #return(max(main_files, key=main_files.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66887585-19d1-4123-b7f3-033669132321",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a976e7d-0b45-493c-a11a-332475a297ed",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc_class_pat = re.compile(r\"^\\s*\\\\document(?:style|class)\")\n",
    "\n",
    "with tarfile.open(tar_path, 'r', encoding='utf-8') as in_tar:\n",
    "    #in_tar.getnames()\n",
    "    fp = in_tar.extractfile('main.tex')\n",
    "    wrapped_file = io.TextIOWrapper(fp, newline=None, encoding='utf-8') #universal newlines\n",
    "    for line in wrapped_file:\n",
    "        if doc_class_pat.search(line):\n",
    "            print(line)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d91077a-6e59-4b2e-a18a-f6e42308260a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "next(wrapped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa1d579-88e1-4d9f-be77-efbf09f60e3e",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c8b266-bf93-4630-96cc-7df4384ea622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3537486a-b084-4984-ac94-98d7d57e8f12",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "7fc63084-89a4-4025-b281-37484cfe6f8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Discover the file list:\n",
    "input_zip = '2201.00007v1.zip'\n",
    "infile_path = os.path.join(LOCAL_DATA_PATH, input_zip)\n",
    "if True: #False:\n",
    "    with zipfile.ZipFile(infile_path, \"r\") as in_zip:\n",
    "        files = in_zip.infolist()\n",
    "        for file_info in files:\n",
    "            if not '/.' in file_info.filename:\n",
    "                print(file_info.filename)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "42c354ee-5fbf-4fdb-a9ae-5a6734811272",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "source": [
    "main_tex = '2201.00007v1/main.tex'\n",
    "with zipfile.ZipFile(infile_path, \"r\") as in_zip:\n",
    "    with in_zip.open('2201.00007v1/main.tex') as in_tex:\n",
    "        #print(in_tex.read())\n",
    "        wrapped_file = io.TextIOWrapper(in_tex, newline=None, encoding='utf-8') #universal newlines\n",
    "        source_text = pre_format(wrapped_file.read())\n",
    "        soup = TS.TexSoup(source_text)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f76d8f8a-1108-427d-8ba0-8929708576ef",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "source": [
    "title = soup.find('title')\n",
    "print(f\"{title.name}: {title.text}\")\n",
    "for sec in soup.find_all('section'):\n",
    "    print(f' {sec.name}: {sec.text}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee9c4d1-97a9-4f76-8766-3f44fe3d30a5",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_example=r\"\"\"\n",
    "\\documentclass{article}\n",
    "\\begin{document}\n",
    "% \\renewcommand{\\shorttitle}{Avoiding Catastrophe}\n",
    "\\end{document}\n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828170bf-8ecd-42d9-8d7a-72ea96882d76",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "TS.TexSoup(r'\\newcommand{\\bra}[1]{\\left\\langle#1\\right|}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e9a622-30ec-494e-a74e-bc0bc3e71cda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TS.TexSoup(r'\\def\\be{\\foo{equation}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27395fa4-dafb-44c1-a1a6-9ef62e920672",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "TS.TexSoup(r'\\renewcommand{\\shorttitle}{Avoiding Catastrophe}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7f5085-5f09-4642-a45d-e9215eb3f508",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_example = r\"\\newenvironment{inlinemath}{$}{$}\".strip()\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88d4883-0e0c-48c8-a2f1-3f03623dc975",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_example = r\"In practice, the matrix $\\left [ 4 \\right]\\Inv\\M{D}^{(1)}_n $\".strip()\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef35d04-3cb7-4c84-8f27-10cfd07060f7",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_example = r\"In practice, the matrix $\\left[ 4 \\right]\\Inv\\M{D}^{(1)}_n $\"\n",
    "\n",
    "\n",
    "cats = TS.category.categorize(min_example)\n",
    "tokens = list(TS.tokens.tokenize(cats))\n",
    "\n",
    "char_codes = list(TS.category.categorize(min_example))\n",
    "\n",
    "buf = TS.reader.Buffer(TS.tokens.tokenize(TS.category.categorize(r'\\left[ 4 \\right]')))\n",
    "TS.reader.read_command(buf, n_required_args=-1, mode='mode:math', skip=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9deadd-c5ab-49f2-b955-5820e7cbc2d1",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_example = r\"$ t \\in [0,1] $$ t \\in [0,1] $\"\n",
    "\n",
    "\n",
    "cats = TS.category.categorize(min_example)\n",
    "tokens = list(TS.tokens.tokenize(cats))\n",
    "\n",
    "char_codes = list(TS.category.categorize(min_example))\n",
    "\n",
    "with pd.option_context('display.max.columns', None, 'display.max_colwidth', 0):\n",
    "    pd.DataFrame({'char':char_codes, 'code':(x.category for x in char_codes)}).transpose()\n",
    "    pd.DataFrame({'tokens':tokens})\n",
    "\n",
    "buf = TS.reader.Buffer(TS.tokens.tokenize(TS.category.categorize(min_example)))\n",
    "TS.reader.read_command(buf, n_required_args=-1, mode='mode:math', skip=3, tolerance=1)\n",
    "\n",
    "buf = TS.reader.Buffer(TS.tokens.tokenize(TS.category.categorize(min_example)))\n",
    "TS.read(buf, tolerance=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a69f130-a920-4bb7-aa06-aa4c9befa418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max.columns', None, 'display.max_colwidth', 0):\n",
    "    pd.DataFrame({'char':char_codes, 'code':(x.category for x in char_codes)}).transpose()\n",
    "    pd.DataFrame({'tokens':tokens})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257478aa-2037-49ef-8b70-d5cde86ad095",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_example = r\"In practice, the matrix $\\left [\\M{D}^{(1)}_n(\\M{D}^{(1)}_n)\\Tra\\right]\\Inv\\M{D}^{(1)}_n $\"\n",
    "print(min_example)\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "TS.TexSoup(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4658922-e3ad-4407-b85b-a28a49778c4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_example=r\"\"\"\n",
    "\\documentclass{article}\n",
    "\\begin{document}\n",
    "% \\renewcommand{\\shorttitle}{Avoiding Catastrophe}\n",
    "\\end{document}\n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737d580c-1063-4beb-b86c-742533e87c7b",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_example=r\"\"\"\n",
    "\\def\\bean {\\begin{foo}}  \\def\\eean {\\end{foo}}\n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "TS.TexSoup(min_example)\n",
    "print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7528b67-1e5e-46e3-81eb-eebb20f02f2a",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_example=r\"\"\"\n",
    "we {use $A=8B$ and $s=1$, then the scalar field becomes same with (\\Ref{scalarfield}) and\n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#TS.TexSoup(min_example)\n",
    "print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5821fc-c981-4408-a05c-5f5f0f02094f",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(pre_format(min_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ca3e54",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "BRACKETS_DELIMITERS = {\n",
    "    '(', ')', '<', '>', '[', ']', '{', '}', r'\\{', r'\\}', '.' '|', r'\\langle',\n",
    "    r'\\rangle', r'\\lfloor', r'\\rfloor', r'\\lceil', r'\\rceil', r'\\ulcorner',\n",
    "    r'\\urcorner', r'\\lbrack', r'\\rbrack'\n",
    "}\n",
    "# TODO: looks like left-right do have to match\n",
    "SIZE_PREFIX = ('left', 'right', 'big', 'Big', 'bigg', 'Bigg')\n",
    "PUNCTUATION_COMMANDS = {command + opt_space + bracket\n",
    "                        for command in SIZE_PREFIX\n",
    "                        for opt_space in {'', ' '}\n",
    "                        for bracket in BRACKETS_DELIMITERS.union({'|', '.'})}\n",
    "PUNCTUATION_COMMANDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c109f4-c5f0-4203-a6ac-2e01d52cbce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0c83d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ff873e-9a41-4291-bd8f-d7c760c4cef2",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_example=r\"\"\"\n",
    "\\def\\bean {\\begin{eqnarray*}}  \\def\\eean {\\end{eqnarray*}}\n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4148d5a9-5626-4819-9d50-bd95219177c7",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_example=r\"\"\"\n",
    "the interval $t\\in[0,1)$. \n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c83316-e0bb-4e25-8635-b256bf837edb",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_example=r\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\\beq\n",
    "[\\chF,\\chG\\}=\\{\\partial\\chF,\\chG\\}.\n",
    "\\eeq\n",
    "\n",
    "derivation $\\CA\\mapsto [\\CB,\\CA]$. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The following characterizations of UAL chains are all equivalent:\n",
    "\\begin{itemize}\n",
    "    \\item[(1)] A skew-symmetric function $\\cha:\\Lambda^{q+1}\\ra\\mfkdal$ defines an element of $C_{q}(\\mfkdal) $ if $\\|\\cha\\|_{\\alpha}<\\infty$ for any $\\alpha \\in \\NN$.\n",
    "    \\item[(2)] A skew-symmetric function $\\cha:\\Lambda^{q+1}\\ra\\mfkdal$ defines an element of $C_{q}(\\mfkdal) $ if there is a function $b(r) \\in \\Orf$  such that for any $j_0,...,j_q$ the observable $\\cha_{j_0...j_q}$ is $b$-localized at $j_a$ for any $a \\in \\{0,1,...,q\\}$.\n",
    "    \\item[(3)] $C_{q}(\\mfkdal) $ is the completion of $C_q(\\mfkdl) $ with respect to the norms $\\|\\cdot\\|_{\\alpha}$.\n",
    "\\end{itemize}\n",
    "\\end{lemma}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7311649a-3864-430f-9fcd-f8f15204b8aa",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_example=r\"\"\"\n",
    "\\newcommand\\const{\\operatorname{const}}\n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac29f7c5-97ef-485e-ba31-d333f2b4b9da",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_example=r\"\"\"\n",
    "\\newcommand{\\beq}{\\begin{equation}}\n",
    "\\newcommand{\\eeq}{\\end{equation}}\n",
    "\\newcommand{\\chF}{{\\mathsf f}}\n",
    "\\newcommand{\\chG}{{\\mathsf g}}\n",
    "\\beq  \n",
    "[\\chF,\\chG\\}=\\{\\partial\\chF,\\chG\\}.\n",
    "\\eeq\n",
    "derivation $\\CA\\mapsto [\\CB,\\CA]$. \n",
    "\"\"\".strip().replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72f01a6-23a6-42aa-a97c-ca67cb105861",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_example=r\"\"\"\n",
    "\\[\n",
    "r_p=d(p,\\cdot)\\colon \\Gamma \\to [0,\\infty)|~ p \\in M\\}\n",
    "\\]\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a4b795-603a-4f45-8fd6-967414de6514",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_example=r\"\"\"\n",
    "$\\bigl[ a \\bigr)$\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb82b287-0b71-42da-b29c-8e351133a722",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_example=r\"\"\"\n",
    "\n",
    "$\\varepsilon\\in]0,\\varepsilon_\\star[$,  \n",
    "\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaea408-fa6d-4b0b-a7db-1d8c4830e00a",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_example=r\"\"\"\n",
    "\\[\n",
    "i\\colon [0,\\infty) \n",
    "\\]\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1fc98177-9a34-4dbf-8117-8906e71d72dc",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cmd name not recognized in \\newcommand{\\}{1}.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\\newcommand{\\}{1}{{\\mathds 1}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_example=r\"\"\"\n",
    "\\newcommand\\1{{\\mathds 1}}\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91f919f8-73ed-49e0-ba51-016f9b93c5a8",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\\newcommand{\\linebreakand}{%\n",
       "    \\end{@IEEEauthorhalign}\n",
       "    \\hfill\\mbox{}\\par\n",
       "    \\mbox{}\\hfill\\begin{@IEEEauthorhalign}\n",
       "    }\\end{@IEEEauthorhalign}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !! This bug was specific to my fork\n",
    "min_example=r\"\"\"\n",
    "\\newcommand{\\linebreakand}{%\n",
    "    \\end{@IEEEauthorhalign}\n",
    "    \\hfill\\mbox{}\\par\n",
    "    \\mbox{}\\hfill\\begin{@IEEEauthorhalign}\n",
    "    }\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c3bbc1f-bd0f-45c8-9491-f053fe385e55",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$S \\subseteq \\{0\\} \\bigcup [1,\\infty) $ if $z^*_2=1$."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_example=r\"\"\"\n",
    " $S \\subseteq \\{0\\} \\bigcup [1,\\infty) $ if $z^*_2=1$.  \n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b60b5d80-5e79-42de-9c64-c19e24c13a33",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$\\rm{W_{cyc} }\\geq 0$$\\;\\;\\square$"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# two inline math envs next to eachother\n",
    "# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\n",
    "min_example=r\"\"\"\n",
    "$\\rm{W_{cyc} }\\geq 0$$\\;\\;\\square$\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b96d15d6-3c87-4672-a4f9-9a8156fb19bb",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "[Line: 0, Offset: 6] \"$\" env expecting $. Reached end of file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# \\verb{char}...{char} is also an issue for parser\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m min_example\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mverb+$TEXMF/tex/latex/elsevier/+, \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;66;03m#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mTS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTexSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmin_example\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#print(min_example)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.11/site-packages/TexSoup/__init__.py:89\u001b[0m, in \u001b[0;36mTexSoup\u001b[0;34m(tex_code, skip_envs, tolerance)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mAt a high-level, parses provided Tex into a navigable, searchable\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03mstructure. This is accomplished in two steps:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03mSOUP\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     88\u001b[0m MathModeTracker\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m---> 89\u001b[0m parsed, src \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtex_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_envs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_envs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TexNode(parsed, src\u001b[38;5;241m=\u001b[39msrc)\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.11/site-packages/TexSoup/tex.py:22\u001b[0m, in \u001b[0;36mread\u001b[0;34m(tex, skip_envs, tolerance)\u001b[0m\n\u001b[1;32m     20\u001b[0m buf \u001b[38;5;241m=\u001b[39m tokenize(buf)\n\u001b[1;32m     21\u001b[0m buf \u001b[38;5;241m=\u001b[39m read_tex(buf, skip_envs\u001b[38;5;241m=\u001b[39mskip_envs, tolerance\u001b[38;5;241m=\u001b[39mtolerance)\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTexEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m[tex]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbegin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m, tex\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.11/site-packages/TexSoup/data.py:897\u001b[0m, in \u001b[0;36mTexEnv.__init__\u001b[0;34m(self, name, begin, end, contents, args, preserve_whitespace, position)\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, begin, end, contents\u001b[38;5;241m=\u001b[39m(), args\u001b[38;5;241m=\u001b[39m(),\n\u001b[1;32m    877\u001b[0m              preserve_whitespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    878\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Initialization for Tex environment.\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \n\u001b[1;32m    880\u001b[0m \u001b[38;5;124;03m    :param str name: name of environment\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;124;03m    '^^\\\\$**'\u001b[39;00m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 897\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_whitespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_begin \u001b[38;5;241m=\u001b[39m begin\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_end \u001b[38;5;241m=\u001b[39m end\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.11/site-packages/TexSoup/data.py:646\u001b[0m, in \u001b[0;36mTexExpr.__init__\u001b[0;34m(self, name, contents, args, preserve_whitespace, position)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m TexArgs(args)\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 646\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_contents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(contents) \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreserve_whitespace \u001b[38;5;241m=\u001b[39m preserve_whitespace\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition \u001b[38;5;241m=\u001b[39m position\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.11/site-packages/TexSoup/reader.py:227\u001b[0m, in \u001b[0;36mread_tex\u001b[0;34m(buf, skip_envs, tolerance)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Parse all expressions in buffer\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m:param Buffer buf: a buffer of tokens\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03m:rtype: Iterable[TexExpr]\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m buf\u001b[38;5;241m.\u001b[39mhasNext():\n\u001b[0;32m--> 227\u001b[0m     expr \u001b[38;5;241m=\u001b[39m \u001b[43mread_expr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mskip_envs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSKIP_ENV_NAMES\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mskip_envs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m# update signatures for newly discovered commands\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     update_signatures(expr)\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.11/site-packages/TexSoup/reader.py:274\u001b[0m, in \u001b[0;36mread_expr\u001b[0;34m(src, skip_envs, tolerance, mode, is_arg)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m is_arg) \u001b[38;5;129;01mand\u001b[39;00m c\u001b[38;5;241m.\u001b[39mcategory \u001b[38;5;129;01min\u001b[39;00m MATH_TOKEN_TO_ENV\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    273\u001b[0m     expr \u001b[38;5;241m=\u001b[39m MATH_TOKEN_TO_ENV[c\u001b[38;5;241m.\u001b[39mcategory]([], position\u001b[38;5;241m=\u001b[39mc\u001b[38;5;241m.\u001b[39mposition)\n\u001b[0;32m--> 274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mread_math_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m c\u001b[38;5;241m.\u001b[39mcategory \u001b[38;5;241m==\u001b[39m TC\u001b[38;5;241m.\u001b[39mEscape:\n\u001b[1;32m    276\u001b[0m     name, args \u001b[38;5;241m=\u001b[39m read_command(src, tolerance\u001b[38;5;241m=\u001b[39mtolerance, mode\u001b[38;5;241m=\u001b[39mmode)\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.11/site-packages/TexSoup/reader.py:394\u001b[0m, in \u001b[0;36mread_math_env\u001b[0;34m(src, expr, tolerance)\u001b[0m\n\u001b[1;32m    391\u001b[0m     contents\u001b[38;5;241m.\u001b[39mappend(read_expr(src, tolerance\u001b[38;5;241m=\u001b[39mtolerance, mode\u001b[38;5;241m=\u001b[39mMODE_MATH))\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m src\u001b[38;5;241m.\u001b[39mhasNext() \u001b[38;5;129;01mor\u001b[39;00m src\u001b[38;5;241m.\u001b[39mpeek()\u001b[38;5;241m.\u001b[39mcategory \u001b[38;5;241m!=\u001b[39m expr\u001b[38;5;241m.\u001b[39mtoken_end:\n\u001b[0;32m--> 394\u001b[0m     \u001b[43munclosed_env_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpeek\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28mnext\u001b[39m(src)\n\u001b[1;32m    396\u001b[0m expr\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m*\u001b[39mcontents)\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.11/site-packages/TexSoup/reader.py:367\u001b[0m, in \u001b[0;36munclosed_env_handler\u001b[0;34m(src, expr, end)\u001b[0m\n\u001b[1;32m    365\u001b[0m explanation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInstead got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m end \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReached end of file.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    366\u001b[0m line, offset \u001b[38;5;241m=\u001b[39m clo(src\u001b[38;5;241m.\u001b[39mposition)\n\u001b[0;32m--> 367\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[Line: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, Offset: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m env expecting \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    368\u001b[0m     line, offset, expr\u001b[38;5;241m.\u001b[39mname, expr\u001b[38;5;241m.\u001b[39mend, explanation))\n",
      "\u001b[0;31mEOFError\u001b[0m: [Line: 0, Offset: 6] \"$\" env expecting $. Reached end of file."
     ]
    }
   ],
   "source": [
    "# \\verb{char}...{char} is also an issue for parser\n",
    "# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\n",
    "min_example=r\"\"\"\n",
    "\\verb+$TEXMF/tex/latex/elsevier/+, %$%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec142f53-1371-43a4-aade-483fb01fb539",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$\\sqrt{\\frac{3}{2}} >p >1$"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# does not handle missing optional braces around arguments\n",
    "min_example=r\"\"\"\n",
    "$\\sqrt {\\frac 3 2} >p >1$\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7e17698-be31-4eff-9e3a-bc1e73b2514e",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "&$\\rm{N_{Diskbb}}$$(\\times 10^4) $"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \\verb{char}...{char} is also an issue for parser\n",
    "# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\n",
    "min_example=r\"\"\"\n",
    "&$\\rm{N_{Diskbb}}$$(\\times 10^4) $\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8aa1625-0ba4-4ffb-ac6a-cbe1d32cad6f",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$\\frac{j+1+\\epsilon}{m^{\\alpha}}[$"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \\verb{char}...{char} is also an issue for parser\n",
    "# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\n",
    "min_example=r\"\"\"\n",
    "$\\frac{j+1+\\epsilon}{m^{\\alpha}}[$\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62bcafac-4179-4524-b682-ff901aaedbd1",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$1\\le k< \\frac{n}{2}$"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \\verb{char}...{char} is also an issue for parser\n",
    "# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\n",
    "min_example=r\"\"\"\n",
    "$1\\le k< \\frac n2 $ \n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eadf35b9-d577-455f-89f4-64ecffdf6b08",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\\begin{equation}\n",
       "\\begin{aligned}[t][T\\tensor*[]{]}{_{\\CT}^{\\sp}} \\\\\n",
       "[T]{_{\\CT}^{\\sp}}\n",
       "\\end{aligned}\n",
       "\\end{equation}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \\verb{char}...{char} is also an issue for parser\n",
    "# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\n",
    "min_example=r\"\"\"\n",
    "\\begin{equation}\n",
    "\\begin{aligned}[t]\n",
    "[T\\tensor*[]{]}{_{\\CT}^{\\sp}} \\\\\n",
    "[T]{_{\\CT}^{\\sp}}\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ca9a1b9-a70f-4681-ba67-03a06d7f4f5d",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Let $A$ be the center component of a $3$-part solution $F$ with center $u$. By Lemma~\\ref{l-sep2}, we find that $A-u$ consists of exactly three connected components $D_1$, $D_2$ and $D_3$. We say that $F$ is {\\it full} if every $D_i$ $(i=1,2,3) $ has size at least~$2$. We now prove the following structural lemma for $(2P_1+P_4) $-free graphs.\n",
       "\n",
       "\\begin{lemma}\\label{l-full}\n",
       "Let $G$ be a $(2P_1+P_4) $-free graph.\n",
       "Let $A$ be the center component of a full $3$-part solution $F$ for $G$ that has center $u$. Then $F=A$ and every connected component of $A-u$ is a complete graph.\n",
       "\\end{lemma}\n",
       "\n",
       "\\begin{proof}\n",
       "Let $v_1,v_2,v_3$ be the center neighbours of $F$.\n",
       "By Lemma~\\ref{l-sep2}, we find that $A-u$ consists of exactly three connected components $D_1$, $D_2$ and $D_3$, where we assume that $v_i\\in V(D_i) $ for $i\\in \\{1,2,3\\}$. As $F$ is full, we \n",
       "find that for $i\\in \\{1,2,3\\}$, $D_i$ contains a vertex $x_i$ adjacent to $v_i$.\n",
       "\n",
       "We will first prove that $F=A$. Suppose that $F$ contains a vertex $y\\notin V(A) $. Then $x_1,v_1,u,v_2,x_3,y$ induce a $2P_1+P_4$ in $G$, contradicting the $(2P_1+P_4) $-freeness of $G$.\n",
       "\n",
       "We will now prove that every $D_i$ is complete. We consider $D_1$, as the arguments for $D_2$ and $D_3$ will be the same. First suppose that $D_1$ contains a vertex $z$ not adjacent to $v_1$. \n",
       "As $D_1$ is connected we may assume without loss of generality that $z$ has distance~$2$ from $v_1$ in $D_1$, and so $D_1$ contains a vertex $z'$ that is adjacent to both $v_1$ and $z$. \n",
       "Then $z,z',v_1,u,x_2,x_3$ induce a $2P_1+P_4$ in $G$, a contradiction. Hence, $v_1$ is adjacent to every other vertex in $D_1$. Now suppose that $D_1$ still contains two non-adjacent vertices $p$ and $q$. As $v_1$ is adjacent to every vertex of $V(D_1)\\setminus \\{v_1\\}$, we find that $v_1\\notin \\{p,q\\}$. Then $x_2,v_2,u,v_3,p,q$ induce a $2P_1+P_4$ in $G$, a contradiction.\n",
       "\\qed\n",
       "\\end{proof}\n",
       "\n",
       "\\noindent\n",
       "We are now ready to prove the following lemma.\n",
       "\n",
       "\\begin{lemma}\\label{l-3part}\n",
       "For a $(2P_1+P_4) $-free graph $G=(V,E) $ with a positive vertex weighting~$w$ and a set $T\\subseteq V$, it is possible to find a $3$-part solution of maximum weight in polynomial time.\n",
       "\\end{lemma} \n",
       "\n",
       "\\begin{proof}\n",
       "Let $|V|=n$.\n",
       "We consider every possible choice of center vertex $u$ and center neighbours $v_1,v_2,v_3$. Note that there are $O(n^4) $ options. For each choice of $u,v_1,v_2,v_3$ we do as follows. \n",
       "First we check that $u\\in T$, $\\{v_1,v_2,v_3\\}$ is disjoint from $T$ and independent, $u$ is adjacent to $v_1$, $v_2$ and $v_3$. If the check fails, the guess is discarded.\n",
       "We remove every neighbour of $u$ that is not in $\\{v_1,v_2,v_3\\}$. This gives us a graph $G'$. Note that $G'$ contains the $3$-part solution $F$ of $G$ if $u$ is the center of $F$ and $v_1,v_2,v_3$ are the center neighbours. Say $A$ is the center component of $F$. Then, by Lemma~\\ref{l-sep2}, we find that $A-u$ consists of exactly three connected components $D_1$, $D_2$ and $D_3$, say $v_i\\in V(D_i) $ for $i\\in \\{1,2,3\\}$.\n",
       "\n",
       "We first search for a maximum weight $3$-part solution of $G'$ with center~$u$ and center neighbours $v_1,v_2,v_3$ that is not full. This means that at least one of the connected components $D_1,D_2,D_3$ has size~$1$, so at least one of $v_1,v_2,v_3$ is only adjacent to $u$ in $F$. We consider each of the three options. We first examine the case where $v_1$ has degree~$1$ in $F$. In order to do this, we remove $u$ and $v_1$ from $G'$, and we also remove all neighbours of $v_1$ from $G'$. This gives us a graph $G_1$. It remains to solve {\\sc Weighted Vertex Cut} for the instance that consists of $G'$, with $v_2$ and $v_3$ as terminals and the restriction of $w$ to $V(G_1) $.\n",
       "This takes polynomial time by Lemma~\\ref{l-easy}. We repeat the same steps with respect to~$v_2$ and also with respect to $v_3$. From all the non-full $3$-part solutions found we remember one with largest weight.\n",
       "\n",
       "We now search for a maximum weight $3$-part solution of $G'$ with center $u$ and center neighbours $v_1,v_2,v_3$ that is full. \n",
       "We remove every vertex not equal to $u$ that is adjacent to at least two vertices from $\\{v_1,v_2,v_3\\}$ from $G'$. We may do the latter, as $D_1,D_2,D_3$ are distinct connected components of $A-u$, so such a vertex will not be in any of $D_1,D_2$, or $D_3$. By Lemma~\\ref{l-full}, every vertex in $F$ is adjacent to one of $v_1,v_2,v_3$.\n",
       "Hence, we may also remove every vertex not adjacent to any vertex from $\\{v_1,v_2,v_3\\}$ from~$G'$. Finally, we remove every vertex of $T\\setminus \\{u\\}$ from $G'$, as $u$ will be the only vertex of $F$ that belongs to $T$. We denote the resulting graph by $G''$; see also Fig.~\\ref{f-gdo}. By construction, every vertex of $G''-\\{u,v_1,v_2,v_3\\}$ is adjacent to exactly one of $\\{v_1,v_2,v_3\\}$. Moreover, we constructed $G''$ in polynomial time.\n",
       "\n",
       "\\begin{figure}\n",
       "\\begin{center}\n",
       "\\begin{tikzpicture}[scale=0.8] \\draw[color=black,fill=white] (-1,2) ellipse (0.6cm and 0.6cm); \\draw[color=black,fill=white] (-1,0) ellipse (0.6cm and 0.6cm); \\draw[color=black,fill=white] (-1,-2) ellipse (0.6cm and 0.6cm); \\draw[dotted] (-3,2)--(-3,-2) to[out=60,in=300] (-3,2); \\draw[dashed] (-3.25,2.7)--(-3.25,1.3)--(-0.15,1.3)--(-0.15,2.7)--(-3.25,2.7) (-3.25,-0.7)--(-3.25,0.7)--(-0.15,0.7)--(-0.15,-0.7)--(-3.25,-0.7) (-3.25,-2.7)--(-3.25,-1.3)--(-0.15,-1.3)--(-0.15,-2.7)--(-3.25,-2.7); \\draw\n",
       "(-5,0)--(-3,0)--(-1.2,0.566) (-3,0)--(-1.2,-0.566) (-5,0)--(-3,2)--(-1.2,2.566) (-3,2)--(-1.2,1.434) (-5,0)--(-3,-2)--(-1.2,-2.566) (-3,-2)--(-1.2,-1.434) (-1,1.3)--(-0.5,0.7) (-1.2,1.3)--(-1.2,0.7) (-1.2,-1.3)--(-0.5,-0.7) (-1,-1.3)--(-0.8,-0.7) (-0.15,-1.5) to[out=60,in=300] (-0.15,2) (-0.15,-2) to[out=60,in=300] (-0.15,2.5); \\draw[fill=black] (-5,0) circle [radius=3pt] (-3,0) circle [radius=3pt] (-3,2) circle [radius=3pt] (-3,-2) circle [radius=3pt]; \\node[above] at (-3,2.2) {$v_1$}; \\node[above right] at (-3,0.2) {$v_2$}; \\node[below] at (-3,-2.2) {$v_3$}; \\node[below] at (-5.1,-0.25) {$u\\in T$};\n",
       "\\end{tikzpicture}\n",
       "\\end{center}\n",
       "\\caption{The graph $G''$ constructed in the proof of Lemma~\\ref{l-3part}. Note that $\\{v_1,v_2,v_3\\}$ is an independent set and that every vertex not in $\\{u,v_1,v_2,v_3\\}$ is adjacent to exactly one of $v_1,v_2,v_3$. The desired components $D_1$, $D_2$ and $D_3$ of $G''-u$ are, if they exist, subgraphs of the rectangular boxes. However, there might be edges between two vertices from two different boxes and we must deal with this situation.}\\label{f-gdo}\n",
       "\\end{figure}\n",
       "\n",
       "We will now consider all $O(n^3) $ options for choosing neighbours $x_1,x_2,x_3$ of $v_1,v_2,v_3$, respectively; note that these vertices are guessed to be in $D_1-v_1,D_2-v_2,D_3-v_3$, respectively.\n",
       "As $F$ is full, these vertices $x_1,x_2,x_3$ exist by definition. For each chosen triple $x_1,x_2,x_3$, we do as follows. \n",
       "We first check if $\\{x_1,x_2,x_3\\}$ forms an independent set. This must hold, as $D_1,D_2,D_3$ are distinct connected components of $A-u$. So, if the check fails, the guess is discarded.\n",
       "From $G''$, we remove every neighbour of $v_1$ that is adjacent to at least one of $\\{x_2,x_3\\}$; every neighbour of $v_2$ that is adjacent to at least one of $\\{x_1,x_3\\}$; and every neighbour of $v_3$ that is adjacent to at least one of $\\{x_1,x_2\\}$. By Lemma~\\ref{l-full}, we also remove for $i\\in \\{1,2,3\\}$, every neighbour of $v_i$ that is not adjacent to $x_i$. We denote the resulting graph by $F^*$.\n",
       "\n",
       "By construction, every vertex not in $\\{u,v_1,v_2,v_3,x_1,x_2,x_3\\}$ is not adjacent to $u$ and is adjacent to both vertices of exactly one of the pairs $\\{v_1,x_1\\}$, $\\{v_2,x_2\\}$ or $\\{v_3,x_3\\}$.\n",
       "We claim that $F^*$ is the desired full $3$-part solution (for this particular branch).\\footnote{For the remainder of the proof, the fact that $G$ is $(2P_1+P_4) $-free is again crucial. If $G$ is $5P_1$-free and thus $(3P_1+P_4) $-free, but not $(2P_1+P_4) $-free, the proof will not work. Namely, in that case, we would obtain the gadget of Papadopoulos and Tzimas~\\cite{PT20}\n",
       "for proving \\NP-hardness of {\\sc Subset Feedback Vertex Set} for $5P_1$-free graphs (in their proof the center $u$ and the three center neighbours each have large weight while $T=\\{u\\}$ and a reduction from {\\sc Vertex Cover} for $3$-partite graphs is used).} In order to see this, assume that $F^*-u$ is not the disjoint union of three complete graphs $D_1$, $D_2$, $D_3$. By construction, this means that one of the following two cases must hold:\n",
       "\n",
       "\\begin{figure}\n",
       "\\centering\n",
       "\\begin{minipage}[b]{0.4\\textwidth}\n",
       "\\begin{tikzpicture}[scale=0.8] \\draw (-2,-1)--(-2,0)--(0,1)--(0,-1) (0,1)--(2,0)--(2,-1) (-2,-2) to[out=60,in=300] (-2,0)\n",
       "(0,-2) to[out=120,in=240] (0,0); \\draw[very thick] (-2,-1)--(-2,-2)--(0,-2)--(0,-1); \\draw[fill=white] (0,0) circle [radius=3pt] (-2,0) circle [radius=3pt] (2,0) circle [radius=3pt]; \\draw[fill=black]\n",
       "(0,1) circle [radius=3pt] (-2,-1) circle [radius=3pt] (0,-1) circle [radius=3pt] (2,-1) circle [radius=3pt] (-2,-2) circle [radius=3pt] (0,-2) circle [radius=3pt]; \\node[above] at (0,1) {$u\\in T$}; \\node[left] at (-2,0) {$v_1$}; \\node[right] at (0,0) {$v_2$}; \\node[right] at (2,0) {$v_3$}; \\node[left] at (-2,-1) {$x_1$}; \\node[right] at (0,-1) {$x_2$}; \\node[right] at (2,-1) {$x_3$}; \\node[left] at (-2,-2) {$r$}; \\node[right] at (0,-2) {$r'$};\n",
       "\\end{tikzpicture}\n",
       "\\end{minipage}\n",
       "\\qquad\n",
       "\\begin{minipage}[b]{0.2\\textwidth}\n",
       "\\begin{tikzpicture}[scale=0.8] \\draw (-2,-1)--(-2,0)--(0,1) (-3,-2.2)--(-3,0.2)--(-1,0.2)--(-1,-2.2)--(-3,-2.2) (2,0)--(2,-1) (-2.5,-2) to[out=120,in=220] (-2,0) (-1.5,-2) to[out=60,in=320] (-2,0); \\draw[dotted] (-2.5,-2)--(-1.5,-2); \\draw[very thick] (0,-1)--(0,1)--(2,0); \\draw[dashed] (-2.5,-2)--(-2,-1)--(-1.5,-2); \\draw[fill=white] (-2,0) circle [radius=3pt] (-2,-1) circle [radius=3pt] (2,-1) circle [radius=3pt]; \\draw[fill=black] (2,0) circle [radius=3pt] (0,1) circle [radius=3pt] (0,0) circle [radius=3pt] (0,-1) circle [radius=3pt] (-2.5,-2) circle [radius=3pt] (-1.5,-2) circle [radius=3pt]; \\node[above] at (0,1) {$u\\in T$}; \\node[left] at (-2,0) {$v_1$}; \\node[right] at (0,0) {$v_2$}; \\node[right] at (2,0) {$v_3$}; \\node[left] at (-2,-1) {$x_1$}; \\node[right] at (0,-1) {$x_2$}; \\node[right] at (2,-1) {$x_3$}; \\node[left] at (-2.5,-2) {$y$}; \\node[right] at (-1.5,-2) {$y'$};\\node[above] at (-2,0.3) {$$};\n",
       "\\end{tikzpicture}\n",
       "\\end{minipage}\n",
       "\\caption{The contradictions obtained in Lemma~\\ref{l-3part}. On the left we have Case~(i) and on the right, Case (ii): in both cases we obtain an induced $2P_1+P_4$ (highlighted by the black vertices and thick edges).}\\label{f-nn}\n",
       "\\end{figure}\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item[(i)] $F^*-u$ has two adjacent vertices $r$ and $r'$ that have a different neighbour in $\\{v_1,v_2,v_3\\}$, or\n",
       "\\item[(ii)] $F^*-u$ has a connected component that is not a complete graph.\n",
       "\\end{itemize}\n",
       "For a contradiction, assume that Case~(i) holds. Say, $r$ is adjacent to $v_1$ and $r'$ is adjacent to $v_2$.\n",
       "By construction of $F^*$, we find that $r$ is adjacent to $x_1$ but not to $x_2$ or $x_3$, whereas $r'$ is adjacent to $x_2$ but not to $x_1$ or $x_3$. \n",
       "Recall also that $\\{x_1,x_2,x_3\\}$ is an independent set and that $u$ is not adjacent to any vertex of $\\{r,r',x_1,x_2,x_3\\}$.\n",
       "However, now the vertices $x_1,r,r',x_2,u,x_3$ induce a $2P_1+P_4$ in $F^*$, a contradiction as $F^*$ being an induced subgraph of $G$ is $(2P_1+P_4) $-free (see also Fig.~\\ref{f-nn}).\n",
       "Hence, Case (i) does not hold, and thus $F^*-u$ consists of three different connected components that contain the sets $\\{v_1,x_1\\}$, $\\{v_2,x_2\\}$ and $\\{v_3,x_3\\}$, respectively.\n",
       "\n",
       "We conclude that Case~(ii) must hold if $F^*$ is not a full $3$-part solution.\n",
       "We prove that this leads to another contradiction. Let $y,y'$ be two non-adjacent vertices in say the connected component of $F^*-u$ that contains $v_1$. As $v_1$ is adjacent to every vertex of that component, we find that $v_1$ is not equal to $y$ or $y'$. However, now $x_2,v_2,u,v_3,y,y'$ induce a $2P_1+P_4$, a contradiction; see also Fig.~\\ref{f-nn}. \n",
       "Hence, we conclude that $F^*$ is indeed the desired full $3$-part solution. \n",
       "\n",
       "From all the full $3$-part solutions we found we remember one with largest weight.\n",
       "It remains to compare the maximum weight non-full solution with the maximum weight full solution and pick one with largest weight.\n",
       "The correctness of the algorithm follows from the arguments above. As the total number of branches is polynomial and processing each of them takes polynomial time as well, the running time of the algorithm is polynomial. \\qed\n",
       "\\end{proof}\n",
       "\n",
       "\\subsection{Mim-Width}\\label{s-mim}\n",
       "\n",
       "We also need some known results that involve the mim-width of a graph. This width parameter was introduced by Vatshelle~\\cite{Va12}. For the definition of mim-width we refer to~\\cite{Va12}, as we do not need it here. A graph class~${\\cal G}$ has {\\it bounded} mim-width if there exists a constant $c$ such that every graph in ${\\cal G}$ has mim-width at most~$c$. The mim-width of a graph class ${\\cal G}$ is {\\it quickly computable} if it is possible to compute in polynomial time a so-called branch decomposition for a graph~$G\\in {\\cal G}$ whose mim-width is bounded by some function in the mim-width of $G$. We can now state the aforementioned result of Bergougnoux, Papadopoulos and Telle in a more detailed way.\n",
       "\n",
       "\\begin{theorem}[\\cite{BPT19}]\\label{t-bpt19}\n",
       "{\\sc Weighted Subset Feedback Vertex Set} is polynomial-time solvable for every graph class whose mim-width is bounded and quickly computable.\n",
       "\\end{theorem}\n",
       "\n",
       "\\noindent\n",
       "Belmonte and Vatshelle~\\cite{BV13} proved that the mim-width of the class of permutation graphs is bounded and quickly computable. As $P_4$-free graphs form a subclass of the class of permutation graphs, we obtain the following lemma.\\footnote{It is well-known that $P_4$-free graphs have clique-width at most~$2$, and instead of Theorem~\\ref{t-bpt19} we could have used a corresponding result for clique-width.}\n",
       "\n",
       "\\begin{lemma}[\\cite{BV13}]\\label{l-p4}\n",
       "The mim-width of the class of $P_4$-free graphs is bounded and quickly computable.\n",
       "\\end{lemma}\n",
       "\n",
       "\\noindent\n",
       "For a graph class ${\\cal G}$ and an integer $p\\geq 0$, we let ${\\cal G}+pv$ be the graph class that consists of all graphs that can be modified into a graph from ${\\cal G}$ by deleting at most $p$ vertices. The following lemma follows in a straightforward way from a result of Vatshelle.\n",
       "\n",
       "\\begin{lemma}[\\cite{Va12}]\\label{l-au}\n",
       "If ${\\cal G}$ is a graph class whose mim-width is bounded and quickly computable, then the same holds for the class ${\\cal G}+pv$, for every constant $p\\geq 0$.\n",
       "\\end{lemma}\n",
       "\n",
       "\\noindent\n",
       "We will now explain the relevance of the above results in a slightly more general way (such that we can apply the next lemma in Section~\\ref{s-2p1p4u} as well).\n",
       "Let $G=(V,E) $ be an $(sP_1+P_4) $-free graph for some $s\\geq 2$ and let $T\\subseteq V$. Let $F$ be a $T$-forest of $G$. We define the {\\it core} of $F$ as the set of vertices of $F$ that have at most $2s-1$ neighbours in $F$.\n",
       "We say that $F$ is {\\it core-complete} if the core of $F$ has no independent set of size at least~$s$; otherwise $F$ is\n",
       "{\\it core-incomplete}.\\footnote{These notions are not meaningful if $s\\in \\{0,1\\}$. Hence, we defined them for $s\\geq 2$.}\n",
       "We prove the following algorithmic result. \n",
       "\n",
       "\\begin{figure}\n",
       "\\begin{center}\n",
       "\\begin{tikzpicture}[scale=0.8] \\draw[color=black,fill=white] (1,0) ellipse (1cm and 2.5cm); \\draw (-2.3,2.3)--(-2.6,2.3)--(-2.6,-2.3)--(-2.3,-2.3) (2.3,2.8)--(2.6,2.8)--(2.6,-2.8)--(2.3,-2.8) (3,1.7)--(3,-1.7)--(5,-1.7)--(5,1.7)--(3,1.7) (-2,2)--(0.4,2)\n",
       "(-2,1.5)--(0.2,1.5) (-2,1)--(0.08,1) (-2,0.5)--(0.028,0.5) (-2,0)--(0,0) (-2,-2)--(0.4,-2) (-2,-1.5)--(0.2,-1.5) (-2,-1)--(0.08,-1) (-2,-0.5)--(0.028,-0.5); \\draw[fill=black] (-2,2) circle [radius=2pt] (-2,1.5) circle [radius=2pt] (-2,-2) circle [radius=2pt] (-2,1) circle [radius=1.5pt] (-2,0.5) circle [radius=1pt] (-2,0) circle [radius=1pt] (-2,-0.5) circle [radius=1pt] (-2,-1) circle [radius=1pt](-2,-1.5) circle [radius=1pt]; \\node[left] at (-2.7,0) {$s$}; \\node[above] at (-2, 2.4) {$U$}; \\node[above] at (1,2.6) {$Z$}; \\node[right] at (2.7,-2.8) {$\\leq s(2s-1) $}; \\node[above] at (4,1.8) {$\\;\\;\\;\\;\\;V(G')\\setminus (U\\cup Z) $}; \n",
       "\\end{tikzpicture}\n",
       "\\end{center}\n",
       "\\caption{An example of the graph $G'$ as described in the proof of Lemma~\\ref{l-poss}. Since $U$ is an independent set of size $s$, we have that $G'-(U\\cup Z) $ is $P_4$-free.}\\label{f-poss}\n",
       "\\end{figure}\n",
       "\n",
       "\\begin{lemma}\\label{l-poss}\n",
       "Let $s\\geq 2$.\n",
       "For an $(sP_1+P_4) $-free graph $G=(V,E) $ with a positive vertex weighting~$w$ and a set $T\\subseteq V$, it is possible to find a core-incomplete solution of maximum weight in polynomial time.\n",
       "\\end{lemma}\n",
       "\n",
       "\\begin{proof}\n",
       "Let $|V|=n$.\n",
       "A core-incomplete solution $F$ has a core that contains an independent set $U=\\{u_1,\\ldots,u_s\\}$ of size~$s$. By definition, core vertices have degree at most~$2s-1$ in $F$. We consider all $O(n^s) $ options of choosing the vertices $u_1,\\ldots,u_s$. \n",
       "We check if $U$ is an independent set. If the check fails, the guess is discarded.\n",
       "For each choice, we consider all $O(n^{s(2s-1) }) $ options of choosing a set $Z$ of size at most $s(2s-1) $ that contains the (at most $2s-1$) neighbours of each $u_i$\n",
       "$(1\\leq i \\leq s) $ in $F$. For each choice of  $Z$ we now do as follows. We delete every neighbour of every $u_i$ that is not in $Z$ from $G$, that is $N(U)\\setminus Z$. Let $G'$ be the new graph; see also Fig.~\\ref{f-poss}. Let $w'$ be the restriction of $w$ to $V(G') $ and let $T'=T\\cap V(G') $.\n",
       "\n",
       "As $U$ is an independent set, $G'-(Z\\cup U) $ is $P_4$-free. Let ${\\cal G}$ be the class of $P_4$-free graphs. Then, as $|Z\\cup U|\\leq s(2s-1)+s=2s^2$, we find that $G'$ belong to ${\\cal G}+2s^2v$.\n",
       "As the mim-width of the class ${\\cal G}$ of $P_4$-free graphs is bounded and quickly computable by Lemma~\\ref{l-p4}, we can apply Lemma~\\ref{l-au} and then we can use Theorem~\\ref{t-bpt19} on $(G',w',T') $. Since the number of branches is $O(n^{2s^2}) $, the running time of our algorithm is polynomial.\n",
       "\\qed\n",
       "\\end{proof}\n",
       "\n",
       "\n",
       "\\subsection{The Algorithm}\\label{s-algo}\n",
       "\n",
       "In this section we present our algorithm for {\\sc Weighted Subset Feedback Vertex Set} restricted to $(2P_1+P_4) $-free graphs.  We first need to prove one more structural lemma for core-complete solutions. We prove this lemma for any value $s\\geq 2$, such that we can use this lemma in the next section as well. However, for $s=2$ we have a more accurate upper bound on the size of the core.\n",
       "\n",
       "\\begin{figure}\n",
       "\\begin{center}\n",
       "\\begin{tikzpicture}[scale=0.8] \\draw[very thick] (2,2)--(0,2)--(-2,0)--(0,-0.5); \\draw(-2,0)--(0,1.5)--(2,1.5) (-2,0)--(0,1)--(2,1) (-2,0)--(0,0.5)--(2,0.5) (-2,0)--(0,0)--(2,0) (-0.3,2.3)--(-0.6,2.3)--(-0.6,-2.3)--(-0.3,-2.3) (1.7,2.3)--(1.4,2.3)--(1.4,-0.3)-- (1.7,-0.3) (-2,0)--(0,-1) (-2,0)--(0,-1.5) (-2,0)--(0,-2); \\draw[fill=black] (-2,0) circle [radius=3pt] (0,2) circle [radius=3pt] (0,-0.5) circle [radius=3pt] (2,2) circle [radius=3pt] (2,1.5) circle [radius=3pt] (2,1) circle [radius=2pt] (2,0.5) circle [radius=2pt] (2,0) circle [radius=3pt]; \\draw[fill=white] (0,1.5) circle [radius=3pt] (0,1) circle [radius=2pt] (0,0.5) circle [radius=2pt] (0,0) circle [radius=3pt] (0,-1) circle [radius=2pt] (0,-1.5) circle [radius=2pt] (0,-2) circle [radius=3pt]; \\node[below left] at (-2,-0.2) {$u\\in T$}; \\node[left] at (-0.6,-2) {$p\\geq 2s$}; \\node[below] at (2,-0.3) {$s+1$}; \\node[above] at (0,2.4) {$V_u$}; \\node[above] at (2.2,2.4) {$\\{w_1,\\ldots,w_{s+1}\\}$}; \\node[right] at (2.2,2) {$w_1$}; \\node[right] at (2.2,0) {$w_{s+1}$}; \\node[above] at (0,2) {$v_1$};  \\node[right] at (0.2,-0.5) {$v_{s+2}$}; \\node[right] at (0.2,-2) {$v_p$}; \\end{tikzpicture}\n",
       "\\end{center}\n",
       "\\caption{An example of the contradiction obtained in Lemma~\\ref{l-two}: the assumption that a vertex $u\\in T$ does not belong to the core of a core-complete solution leads to the presence of an induced $sP_1+P_4$ (highlighted by the black vertices and thick edges).}\\label{f-two}\n",
       "\\end{figure}\n",
       "\n",
       "\\begin{lemma}\\label{l-two}\n",
       "For some $s\\geq 2$, let $G=(V,E) $ be an $(sP_1+P_4) $-free graph. Let $T\\subseteq V$. Let $F$ be a core-complete $T$-forest of $G$ such that $T\\cap V(F)\\neq \\emptyset$. Then the core of $F$ \n",
       "contains every vertex of $T\\cap V(F) $, and $T\\cap V(F) $ has size at most $2s-2$. If $s=2$, the core of $F$ is a clique of size at most~$2$ (so, in this case, $T\\cap V(F) $ has size at most~$2$ as well).\n",
       "\\end{lemma}\n",
       "\n",
       "\\begin{proof}\n",
       "Consider a vertex $u\\in T\\cap V(F) $.\n",
       "For a contradiction, assume that $u$ does not belong to the core of $F$. Then $u$ has at least $2s$ neighbours in $F$. Let $V_u=\\{v_1,\\ldots,v_p\\}$ for some $p\\geq 2s$ be the set of neighbours of $u$ in $F$.\n",
       "\n",
       "Let $A$ be the connected component of $F$ that contains $u$. As $F$ is a $T$-forest, $A-u$ consists of $p$ connected components $D_1,\\ldots, D_p$ such that $v_i\\in V(D_i) $ for $i\\in \\{1,\\ldots,p\\}$. In particular, this implies that $V_u=\\{v_1,\\ldots,v_p\\}$ must be an independent set. As the core of $F$ has no independent set of size~$s$ and $p\\geq 2s$, this means that at most $s-1$ vertices of $V_u$ may belong to the core of $F$.\n",
       "Hence, we may assume without loss of generality that $v_1,\\ldots,v_{s+1}$ do {\\it not} belong to the core of $F$. This means that $v_1,\\ldots, v_{s+1}$ each have degree at least~$2s$ in $A$. Hence, for $i\\in \\{1,\\ldots,s+1\\}$, vertex $v_i$ is adjacent to some vertex $w_i$ in $D_i$. As $s\\geq 2$, we have that $2s>s+1$ and hence, vertex $v_{s+2}$ exists.\n",
       "However, now the vertices $w_1,v_1,u,v_{s+2},w_2,w_3,\\ldots,w_{s+1}$ induce an $sP_1+P_4$, a contradiction (see also Fig.~\\ref{f-two}).\n",
       "\n",
       "From the above, we conclude that every vertex of $T\\cap V(F) $ belongs to the core of $F$.\n",
       "As $F$ is a $T$-forest, $T\\cap V(F) $ induces a forest, and thus a bipartite graph. As $F$ is core-complete, every independent set in the core has size at most $s-1$. Hence, $T\\cap V(F) $ has size at most $2(s-1)=2s-2$.\n",
       "\n",
       "Now suppose that $s=2$. As $F$ is core-complete, the core of $F$ must be a clique. As the core of $F$ contains $T\\cap V(F) $ and $T\\cap V(F) $ induces a forest, this means that the core of $F$, and thus also $T\\cap V(F) $, has  size at most~$2$. This completes the proof of the lemma.\n",
       "\\qed\n",
       "\\end{proof}\n",
       "\n",
       "\n",
       "\\section{The Unweighted Variant}\\label{s-2p1p4u}\n",
       "\n",
       "In this section, we present our polynomial-time algorithm for {\\sc Subset Feedback Vertex Set} on $(sP_1+P_4) $-free graphs for every $s\\geq 0$. As this problem is a special case of {\\sc Weighted Subset Feedback Vertex Set} (namely when $w\\equiv 1$), we can use some of the structural results of the previous section.\n",
       "\n",
       "\\begin{theorem}\\label{t-unw}\n",
       "{\\sc Subset Feedback Vertex Set} is polynomial-time solvable on $(sP_1+P_4) $-free graphs for every $s\\geq 0$.\n",
       "\\end{theorem}\n",
       "\n",
       "\\begin{proof}\n",
       "Let $G=(V,E) $ be an $(sP_1+P_4) $-free graph for some integer $s$, and let $T\\subseteq V$. Let $|V|=n$. As the class of $(sP_1+P_4) $-free graphs is a subclass of the class of $((s+1)P_1+P_4) $-free graphs, we may impose any lower bound on $s$; we set $s\\geq 2$. \n",
       "We aim to find a $T$-forest $F$ of $G$ of maximum size (recall that we call $T$-forests solutions for our problem).\n",
       "We let $F^*$ denote the induced subgraph of $F$ that consists of the vertices in $T\\cap V(F) $, that is $F[T]$. As $F$ is a solution, thus a $T$-forest, we find that $F^*$ must be a forest.\n",
       "\n",
       "We first compute a maximum-size core-incomplete solution for $(G,T) $. By Lemma~\\ref{l-poss} this takes polynomial time. It remains to compare the size of this solution with a maximum-size core-complete solution, which we compute below.\n",
       "\n",
       "By Lemma~\\ref{l-two}, we find that $T\\cap V(F) $ has size at most $2s-2$ for every core-complete solution~$F$; see also Fig.~\\ref{f-scheme}. We consider all $O(n^{2s-2}) $ possibilities of choosing the vertices of $T\\cap V(F) $. For each choice of $T\\cap V(F) $ we do as follows. We note that the set of vertices of $G-T$ that do not belong to $F$ has size at most $|T\\cap V(F)|$; otherwise $F'=V\\setminus T$ would be a larger solution than $F$. Hence, we can consider all $O(n^{|T\\cap V(F)|})=O(n^{2s-2}) $ possibilities of choosing the set of vertices of $G-T$ that do not belong to $F$, or equivalently, of choosing the set of vertices of $G-T$ that {\\it do} belong to $F$. In other words, we guessed $F$ by brute force, and the number of guesses is $O(n^{4s-4}) $. In the end we found in polynomial time a maximum-size core-complete solution. We compare it with the maximum-size core-incomplete solution found above and pick one of largest size. \n",
       "\\qed\n",
       "\\end{proof}\n",
       "\n",
       "\\noindent\n",
       "By using the above results and the results from Sections~\\ref{s-special} and~\\ref{s-mim}, we are now able to prove our main result. \n",
       "\n",
       "\\begin{theorem}\\label{t-mm}\n",
       "{\\sc Weighted Subset Feedback Vertex Set} is polynomial-time solvable for $(2P_1+P_4) $-free graphs.\n",
       "\\end{theorem}\n",
       "\n",
       "\\begin{proof}\n",
       "Let $G=(V,E) $ be a $(2P_1+P_4) $-free graph, $T$ some subset of $V$, and let $w$ be a positive vertex weighting of $G$. We aim to find a maximum weight $T$-forest of $G$ (recall that we call $T$-forests solutions for our problem).\n",
       "\n",
       "We first compute a $\\leq$$1$-part solution, $2$-part solution and $3$-part solution for $(G,T,w) $ of maximum weight. By Lemmas~\\ref{l-1part},~\\ref{l-2part} and~\\ref{l-3part}, respectively, this takes polynomial time. \n",
       "We also compute, in polynomial time by Lemma~\\ref{l-poss} (in which we set $s=2$), a core-incomplete solution of maximum weight.\n",
       "Observe that the latter covers also the case where a solution contains only one vertex $u$ from~$T$, and this vertex has degree at least~$4$ in $F$.\n",
       "Out of these four solutions we remember one with largest weight.\n",
       "\n",
       "It now remains to compute a core-complete solution $F$ of maximum weight for $(G,w) $ with $|T\\cap V(F)|\\geq 2$. \n",
       "By Lemma~\\ref{l-two}, we have that  $|T\\cap V(F)|=2$ and moreover both vertices of $T\\cap V(F) $ are adjacent and are the only vertices that belong to the core of $F$.\n",
       "\n",
       "We consider all $O(n^2) $ possibilities of choosing two adjacent vertices of $T$ to be the two core vertices of $F$. Consider such a choice $u_1,u_2$. So, $u_1$ and $u_2$ are adjacent, are the only vertices of degree at most~$3$ in the solution $F$ that we are looking for, and moreover, all other vertices of $T$ do not belong to $F$.\n",
       "\n",
       "Suppose one of $u_1,u_2$ has degree~$1$ in $F$. First let this vertex be $u_1$. Then we remove $u_1$ and all its neighbours except for $u_2$ from $G$. Let $G'$ be the resulting graph. Let $T'=T\\setminus \\{u_1\\}$ and let $w'$ be the restriction of $w$ to $G'$. We now compute for $(G',w',T') $, a $\\leq$$1$-part solution and  $2$-part solution of maximum weight with $u_2$ as center.\n",
       "By Lemmas~\\ref{l-1part} and~\\ref{l-2part}, respectively, this takes polynomial time.\\footnote{Strictly speaking, this statement follows from the proofs of these two lemmas, as we have fixed $u_2$ as the center.} We then add $u_1$ back to the solution to get a solution for $(G,w,T) $. We do the same steps with respect to $u_2$. In the end we take a solution with largest weight.\n",
       "\n",
       "\n",
       "From the above we conclude that each of $u_1$ and $u_2$ has exactly one other neighbour in $F$, call these vertices $v_1$ and $v_2$, respectively. We consider all $O(n^2) $ possibilities of choosing $v_1$ and $v_2$. As $F$ is a $T$-forest, $G-\\{u_1,u_2\\}$ consists of two connected components $D_1$ and $D_2$, such that $v_1$ belongs to $D_1$ and $v_2$ belongs to $D_2$.\n",
       "\n",
       "Let $G'$ be the graph obtained from removing every vertex of $T$, every neighbour of $u_1$ except $v_1$ and every neighbour of $u_2$ except $v_2$. Let $w'$ be the restriction of $w$ to $G'$.\n",
       "Then, it remains to solve {\\sc Weighted Vertex Cut} for the instance $(G',v_1,v_2,w') $. By Lemma~\\ref{l-easy}, we can do this in polynomial time. Out of all the solutions found for different pairs $u_1,u_2$ we take one with largest weight. Note that we found this solution in polynomial time, as the number of branches is $O(n^4) $. \n",
       "\n",
       "It remains to take a solution of maximum weight from all the solutions found in the above steps. The correctness of our algorithm follows from the fact that we exhaustively considered all possible situations. Moreover, the number of situations is polynomial and processing each situation takes polynomial time. Hence, the running time of our algorithm is polynomial.\n",
       "\\qed\n",
       "\\end{proof}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \\verb{char}...{char} is also an issue for parser\n",
    "# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\n",
    "with open('./data/test.txt', 'r') as infile:\n",
    "    min_example=infile.read().strip()\n",
    "\n",
    "TS.TexSoup(pre_format(min_example), tolerance=0)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0419393b-a887-4716-9270-eb9b05f40a8f",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.DataFrame(np.random.randint(0,100,size=(10, 3)), columns=list('ABC')).to_csv('~/Expire/test_console_upload.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2c2cc0-fb23-4e5e-af5a-f97ba0eeeea5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
