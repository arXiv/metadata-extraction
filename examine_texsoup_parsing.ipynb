{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea05e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --force-reinstall --no-deps git+https://github.com/chrisjcameron/TexSoup.git@nested-math\n",
    "#! pip install --editable /Users/cjc73/gits/arxiv/TexSoup/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c438b72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import zipfile\n",
    "import tarfile\n",
    "import io\n",
    "import importlib\n",
    "import os\n",
    "import regex as re\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6efd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyperclip   #copy text to clipboard for inspecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c34461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8462bec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "# pretty print all cell's output and not just the last one\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b78ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import TexSoup as TS\n",
    "from TexSoup.tokens import MATH_ENV_NAMES\n",
    "# -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4130379e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "TS.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe2aa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "TS.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e415899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importlib.reload(TS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af501b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_DATA_PATH = './data/2201_00_all/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d91d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_format(text):\n",
    "    '''Apply some substititions to make LaTeX easier to parse'''\n",
    "    source_text = (\n",
    "        text\n",
    "        .replace('\\\\}\\\\', '\\\\} \\\\')  # Due to escape rules \\\\ is equivalent to \\\n",
    "        .replace(')}', ') }')\n",
    "        .replace(')$', ') $')\n",
    "        #.replace(r'\\left [', r'\\left[ ')\n",
    "        #.replace(r'\\left (', r'\\left( ')\n",
    "        #.replace(r'\\left \\{', r'\\left\\{ ')\n",
    "    )\n",
    "    return source_text\n",
    "    #clean_lines = []\n",
    "    #for line in source_text.splitlines(False):\n",
    "    #    cleanline = line.strip()\n",
    "    #    if cleanline.startswith(r'\\newcommand'):\n",
    "    #        cleanline = r'%' + cleanline\n",
    "    #    elif cleanline.startswith(r'\\def'):\n",
    "    #        cleanline = r'%' + cleanline\n",
    "    #    clean_lines.append(cleanline)\n",
    "    #return '\\n'.join(clean_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86ca386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_doc_class(wrapped_file, name_match=False):\n",
    "    '''Search for document class related lines in a file  and return a code to represent the type'''\n",
    "    doc_class_pat = re.compile(r\"^\\s*\\\\document(?:style|class)\")\n",
    "    sub_doc_class = re.compile(r\"^\\s*\\\\document(?:style|class).*(?:\\{standalone\\}|\\{subfiles\\})\")\n",
    "\n",
    "    for line in wrapped_file:\n",
    "        if doc_class_pat.search(line):\n",
    "            if name_match:\n",
    "                # we can miss if there are two or more lines with documentclass \n",
    "                # and the first one is not the one that has standalone/subfile\n",
    "                if sub_doc_class.search(line):\n",
    "                    return -99999\n",
    "                return 1 #main_files[tf] = 1\n",
    "            \n",
    "    return 0 #main_files[tf] = 0\n",
    "\n",
    "\n",
    "def find_main_tex_source_in_tar(tar_path, encoding='uft-8'):\n",
    "    '''Identify the main Tex file in a tarfile.\n",
    "    \n",
    "    Args:\n",
    "        tar_path: A gzipped tar archive of a directory containing tex source and support files.\n",
    "    '''\n",
    "    \n",
    "    tex_names = set([\"paper\", \"main\", \"ms.\", \"article\"])\n",
    "\n",
    "    with tarfile.open(tar_path, 'r') as in_tar:\n",
    "        tex_files = [f for f in in_tar.getnames() if f.endswith('.tex')]\n",
    "        \n",
    "        # got one file\n",
    "        if len(tex_files) == 1:\n",
    "            return tex_files[0]\n",
    "\n",
    "        main_files = {}\n",
    "        for tf in tex_files:\n",
    "            depth = len(tf.split('/')) - 1\n",
    "            has_main_name = any(kw in tf for kw in tex_names)\n",
    "            fp = in_tar.extractfile(tf)\n",
    "            wrapped_file = io.TextIOWrapper(fp, newline=None, encoding=encoding) #universal newlines\n",
    "            # does it have a doc class?\n",
    "            # get the type\n",
    "            main_files[tf] = find_doc_class(wrapped_file, name_match = has_main_name) - depth \n",
    "            wrapped_file.close() \n",
    "        \n",
    "        # got one file with doc class\n",
    "        if len(main_files) == 1:\n",
    "            return(main_files.keys()[0])\n",
    "        \n",
    "        # account for multi-file submissions\n",
    "        return(max(main_files, key=main_files.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79afaed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soup_from_tar(tar_path, encoding='utf-8', tolerance=0):\n",
    "    tex_main = find_main_tex_source_in_tar(tar_path, encoding=encoding)\n",
    "    with tarfile.open(tar_path, 'r') as in_tar:\n",
    "        fp = in_tar.extractfile(tex_main)\n",
    "        wrapped_file = io.TextIOWrapper(fp, newline=None, encoding=encoding) #universal newlines\n",
    "        source_text = pre_format(wrapped_file.read())\n",
    "        soup = TS.TexSoup(source_text, tolerance=tolerance, skip_envs=MATH_ENV_NAMES)\n",
    "        return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24c3ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_from_tar(tar_path, encoding='utf-8'):\n",
    "    tex_main = find_main_tex_source_in_tar(tar_path, encoding=encoding)\n",
    "    with tarfile.open(tar_path, 'r') as in_tar:\n",
    "        fp = in_tar.extractfile(tex_main)\n",
    "        wrapped_file = io.TextIOWrapper(fp, newline=None, encoding=encoding) #universal newlines\n",
    "        source_text = pre_format(wrapped_file.read())\n",
    "        return source_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72727d0-01b6-45cb-9f1e-20e3e3498d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bad(current_text_lines):\n",
    "    mid = int(len(current_text_lines)/2)\n",
    "    part_a = current_text_lines[0:mid]\n",
    "    part_b = current_text_lines[mid:]\n",
    "    if next(swap):\n",
    "        part_b, part_a = part_a, part_b\n",
    "    bad = \"\\\"\n",
    "    try:\n",
    "        soup = TS.TexSoup(\"\\n\".join(part_a), tolerance=tolerance, skip_envs=MATH_ENV_NAMES)\n",
    "    except KeyboardInterrupt:\n",
    "        raise\n",
    "    except:\n",
    "        return part_a\n",
    "    try:\n",
    "        soup = TS.TexSoup(\"\\n\".join(part_b), tolerance=tolerance, skip_envs=MATH_ENV_NAMES)\n",
    "    except KeyboardInterrupt:\n",
    "        raise\n",
    "    except:\n",
    "        return part_b\n",
    "    return \"--\"\n",
    "    \n",
    "\n",
    "def find_bad_lines(tar_path, encoding='utf-8'):\n",
    "    tex_main = find_main_tex_source_in_tar(tar_path, encoding=encoding)\n",
    "    with tarfile.open(tar_path, 'r') as in_tar:\n",
    "        fp = in_tar.extractfile(tex_main)\n",
    "        wrapped_file = io.TextIOWrapper(fp, newline=None, encoding=encoding) #universal newlines\n",
    "        source_text = pre_format(wrapped_file.read())\n",
    "        current_text = source_text.splitlines()\n",
    "\n",
    "    while len(current_text) > 1:\n",
    "        bad_half = find_bad(current_text)\n",
    "        if current_text == bad_half:\n",
    "            break\n",
    "        current_text = bad_half\n",
    "        \n",
    "    return bad_half"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7934e59",
   "metadata": {},
   "source": [
    "## Check a file with parse errors"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b3cba00b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296ca1a5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "infile_path = \"./data/2201_00_all/2201.00001v1.tar.gz\" #'./data/2201_samp/2201.00048v1.tar.gz'\n",
    "\n",
    "text = source_from_tar(infile_path)\n",
    "pyperclip.copy(text)\n",
    "soup = soup_from_tar(infile_path, tolerance=1)\n",
    "\n",
    "\n",
    "title = soup.find('title')\n",
    "if title: print(f\"{title.name}: {title.text}\")\n",
    "for sec in soup.find_all('section'):\n",
    "    print(f' {sec.name}: {sec.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88160210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d616df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bfd7cd8",
   "metadata": {},
   "source": [
    "## Quick check a folder of tar files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56f9923",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "files = glob.glob(f'{LOCAL_DATA_PATH}/*.tar.gz')\n",
    "files_count = len(files)\n",
    "utf_count = 0\n",
    "latin_count = 0 \n",
    "err_files = {}\n",
    "\n",
    "TOLERANCE = 0\n",
    "\n",
    "with tqdm(total=files_count, desc=\"errors\") as err_prog:\n",
    "    for tar_file in tqdm(files, desc=\"Progress\", display=True):\n",
    "        # Is it unicode?\n",
    "        try:\n",
    "            soup = soup_from_tar(tar_file, encoding='utf-8', tolerance=TOLERANCE)\n",
    "            utf_count += 1\n",
    "            continue\n",
    "        except EOFError as eof:\n",
    "            err_files[tar_file] = type(eof)\n",
    "            _ = err_prog.update(1)\n",
    "            continue\n",
    "        except UnicodeDecodeError as ue:\n",
    "            pass\n",
    "        except KeyboardInterrupt as KB_err:\n",
    "            break\n",
    "        except Exception as e:\n",
    "            err_files[tar_file] = type(e)\n",
    "            _ = err_prog.update(1)\n",
    "            continue\n",
    "\n",
    "        # Is it something else?\n",
    "        try:\n",
    "            soup = soup_from_tar(tar_file, encoding='latin-1', tolerance=TOLERANCE)\n",
    "            latin_count += 1\n",
    "            continue\n",
    "        except KeyboardInterrupt as KB_err:\n",
    "            break\n",
    "        except Exception as e:\n",
    "            err_files[tar_file] = type(e)\n",
    "            _ = err_prog.update(1)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98150de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{files_count} processed, {len(err_files)} failures.\")\n",
    "print(f\"UTF8: {utf_count}; Latin1: {latin_count}\")\n",
    "err_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed04efe",
   "metadata": {},
   "source": [
    "## Scratch below here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9f0e46",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5835cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOLERANCE = 0\n",
    "infile_path = \"./data/2201_00_all/2201.00430v1.tar.gz\" #'./data/2201_samp/2201.00048v1.tar.gz'\n",
    "\n",
    "text = source_from_tar(infile_path)\n",
    "pyperclip.copy(text)\n",
    "soup = soup_from_tar(infile_path, tolerance=1)\n",
    "\n",
    "\n",
    "title = soup.find('title')\n",
    "if title: print(f\"{title.name}: {title.text}\")\n",
    "for sec in soup.find_all('section'):\n",
    "    print(f' {sec.name}: {sec.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8f87f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_path = \"./data/2201_samp/2201.00008v2.tar.gz\"\n",
    "encoding = \"utf-8\"\n",
    "with tarfile.open(tar_path, 'r') as in_tar:\n",
    "    tex_files = [f for f in in_tar.getnames() if f.endswith('.tex')]\n",
    "\n",
    "    # got one file\n",
    "    if len(tex_files) == 1:\n",
    "        pass #return tex_files[0]\n",
    "\n",
    "    main_files = {}\n",
    "    for tf in tex_files:\n",
    "        fp = in_tar.extractfile(tf)\n",
    "        wrapped_file = io.TextIOWrapper(fp, newline=None, encoding=encoding) #universal newlines\n",
    "        # does it have a doc class?\n",
    "        # get the type\n",
    "        main_files[tf] = find_doc_class(wrapped_file)\n",
    "        wrapped_file.close() \n",
    "\n",
    "    # got one file with doc class\n",
    "    if len(main_files) == 1:\n",
    "        pass #return(main_files.keys()[0])\n",
    "\n",
    "    # account for multi-file submissions\n",
    "    #return(max(main_files, key=main_files.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6dfe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6599642e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "doc_class_pat = re.compile(r\"^\\s*\\\\document(?:style|class)\")\n",
    "\n",
    "with tarfile.open(tar_path, 'r', encoding='utf-8') as in_tar:\n",
    "    #in_tar.getnames()\n",
    "    fp = in_tar.extractfile('main.tex')\n",
    "    wrapped_file = io.TextIOWrapper(fp, newline=None, encoding='utf-8') #universal newlines\n",
    "    for line in wrapped_file:\n",
    "        if doc_class_pat.search(line):\n",
    "            print(line)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d09b0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(wrapped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881bb489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e6a81b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db76411f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "310b8fa6",
   "metadata": {},
   "source": [
    "# Discover the file list:\n",
    "input_zip = '2201.00007v1.zip'\n",
    "infile_path = os.path.join(LOCAL_DATA_PATH, input_zip)\n",
    "if True: #False:\n",
    "    with zipfile.ZipFile(infile_path, \"r\") as in_zip:\n",
    "        files = in_zip.infolist()\n",
    "        for file_info in files:\n",
    "            if not '/.' in file_info.filename:\n",
    "                print(file_info.filename)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9cebe3e5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "main_tex = '2201.00007v1/main.tex'\n",
    "with zipfile.ZipFile(infile_path, \"r\") as in_zip:\n",
    "    with in_zip.open('2201.00007v1/main.tex') as in_tex:\n",
    "        #print(in_tex.read())\n",
    "        wrapped_file = io.TextIOWrapper(in_tex, newline=None, encoding='utf-8') #universal newlines\n",
    "        source_text = pre_format(wrapped_file.read())\n",
    "        soup = TS.TexSoup(source_text)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1661978",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "title = soup.find('title')\n",
    "print(f\"{title.name}: {title.text}\")\n",
    "for sec in soup.find_all('section'):\n",
    "    print(f' {sec.name}: {sec.text}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d750e7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "min_example=r\"\"\"\n",
    "\\documentclass{article}\n",
    "\\begin{document}\n",
    "% \\renewcommand{\\shorttitle}{Avoiding Catastrophe}\n",
    "\\end{document}\n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "#print(min_example)\n",
    "TS.TexSoup(r'\\newcommand{\\bra}[1]{\\left\\langle#1\\right|}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9e4c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TS.TexSoup(r'\\def\\be{\\foo{equation}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808772c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TS.TexSoup(r'\\renewcommand{\\shorttitle}{Avoiding Catastrophe}')\n",
    "min_example = r\"\\newenvironment{inlinemath}{$}{$}\".strip()\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de28dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_example = r\"In practice, the matrix $\\left [ 4 \\right]\\Inv\\M{D}^{(1)}_n $\".strip()\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5c12bd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "min_example = r\"In practice, the matrix $\\left[ 4 \\right]\\Inv\\M{D}^{(1)}_n $\"\n",
    "\n",
    "\n",
    "cats = TS.category.categorize(min_example)\n",
    "tokens = list(TS.tokens.tokenize(cats))\n",
    "\n",
    "char_codes = list(TS.category.categorize(min_example))\n",
    "\n",
    "buf = TS.reader.Buffer(TS.tokens.tokenize(TS.category.categorize(r'\\left[ 4 \\right]')))\n",
    "TS.reader.read_command(buf, n_required_args=-1, mode='mode:math', skip=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd810bd0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "min_example = r\"$ t \\in [0,1] $$ t \\in [0,1] $\"\n",
    "\n",
    "\n",
    "cats = TS.category.categorize(min_example)\n",
    "tokens = list(TS.tokens.tokenize(cats))\n",
    "\n",
    "char_codes = list(TS.category.categorize(min_example))\n",
    "\n",
    "with pd.option_context('display.max.columns', None, 'display.max_colwidth', 0):\n",
    "    pd.DataFrame({'char':char_codes, 'code':(x.category for x in char_codes)}).transpose()\n",
    "    pd.DataFrame({'tokens':tokens})\n",
    "\n",
    "buf = TS.reader.Buffer(TS.tokens.tokenize(TS.category.categorize(min_example)))\n",
    "TS.reader.read_command(buf, n_required_args=-1, mode='mode:math', skip=3, tolerance=1)\n",
    "\n",
    "buf = TS.reader.Buffer(TS.tokens.tokenize(TS.category.categorize(min_example)))\n",
    "TS.read(buf, tolerance=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd10981",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max.columns', None, 'display.max_colwidth', 0):\n",
    "    pd.DataFrame({'char':char_codes, 'code':(x.category for x in char_codes)}).transpose()\n",
    "    pd.DataFrame({'tokens':tokens})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f060dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_example = r\"In practice, the matrix $\\left [\\M{D}^{(1)}_n(\\M{D}^{(1)}_n)\\Tra\\right]\\Inv\\M{D}^{(1)}_n $\"\n",
    "print(min_example)\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "TS.TexSoup(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39668cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_example=r\"\"\"\n",
    "\\documentclass{article}\n",
    "\\begin{document}\n",
    "% \\renewcommand{\\shorttitle}{Avoiding Catastrophe}\n",
    "\\end{document}\n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf651b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_example=r\"\"\"\n",
    "\\def\\bean {\\begin{foo}}  \\def\\eean {\\end{foo}}\n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "TS.TexSoup(min_example)\n",
    "print(min_example)\n",
    "min_example=r\"\"\"\n",
    "we {use $A=8B$ and $s=1$, then the scalar field becomes same with (\\Ref{scalarfield}) and\n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#TS.TexSoup(min_example)\n",
    "print(min_example)\n",
    "print(pre_format(min_example))\n",
    "BRACKETS_DELIMITERS = {\n",
    "    '(', ')', '<', '>', '[', ']', '{', '}', r'\\{', r'\\}', '.' '|', r'\\langle',\n",
    "    r'\\rangle', r'\\lfloor', r'\\rfloor', r'\\lceil', r'\\rceil', r'\\ulcorner',\n",
    "    r'\\urcorner', r'\\lbrack', r'\\rbrack'\n",
    "}\n",
    "# TODO: looks like left-right do have to match\n",
    "SIZE_PREFIX = ('left', 'right', 'big', 'Big', 'bigg', 'Bigg')\n",
    "PUNCTUATION_COMMANDS = {command + opt_space + bracket\n",
    "                        for command in SIZE_PREFIX\n",
    "                        for opt_space in {'', ' '}\n",
    "                        for bracket in BRACKETS_DELIMITERS.union({'|', '.'})}\n",
    "PUNCTUATION_COMMANDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2772868",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c382d997",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "min_example=r\"\"\"\n",
    "\\def\\bean {\\begin{eqnarray*}}  \\def\\eean {\\end{eqnarray*}}\n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "#print(min_example)\n",
    "min_example=r\"\"\"\n",
    "the interval $t\\in[0,1)$. \n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "#print(min_example)\n",
    "min_example=r\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\\beq\n",
    "[\\chF,\\chG\\}=\\{\\partial\\chF,\\chG\\}.\n",
    "\\eeq\n",
    "\n",
    "derivation $\\CA\\mapsto [\\CB,\\CA]$. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The following characterizations of UAL chains are all equivalent:\n",
    "\\begin{itemize}\n",
    "    \\item[(1)] A skew-symmetric function $\\cha:\\Lambda^{q+1}\\ra\\mfkdal$ defines an element of $C_{q}(\\mfkdal) $ if $\\|\\cha\\|_{\\alpha}<\\infty$ for any $\\alpha \\in \\NN$.\n",
    "    \\item[(2)] A skew-symmetric function $\\cha:\\Lambda^{q+1}\\ra\\mfkdal$ defines an element of $C_{q}(\\mfkdal) $ if there is a function $b(r) \\in \\Orf$  such that for any $j_0,...,j_q$ the observable $\\cha_{j_0...j_q}$ is $b$-localized at $j_a$ for any $a \\in \\{0,1,...,q\\}$.\n",
    "    \\item[(3)] $C_{q}(\\mfkdal) $ is the completion of $C_q(\\mfkdl) $ with respect to the norms $\\|\\cdot\\|_{\\alpha}$.\n",
    "\\end{itemize}\n",
    "\\end{lemma}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)\n",
    "min_example=r\"\"\"\n",
    "\\newcommand\\const{\\operatorname{const}}\n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)\n",
    "min_example=r\"\"\"\n",
    "\\newcommand{\\beq}{\\begin{equation}}\n",
    "\\newcommand{\\eeq}{\\end{equation}}\n",
    "\\newcommand{\\chF}{{\\mathsf f}}\n",
    "\\newcommand{\\chG}{{\\mathsf g}}\n",
    "\\beq  \n",
    "[\\chF,\\chG\\}=\\{\\partial\\chF,\\chG\\}.\n",
    "\\eeq\n",
    "derivation $\\CA\\mapsto [\\CB,\\CA]$. \n",
    "\"\"\".strip().replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)\n",
    "min_example=r\"\"\"\n",
    "\\[\n",
    "r_p=d(p,\\cdot)\\colon \\Gamma \\to [0,\\infty)|~ p \\in M\\}\n",
    "\\]\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)\n",
    "min_example=r\"\"\"\n",
    "$\\bigl[ a \\bigr)$\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)\n",
    "min_example=r\"\"\"\n",
    "\n",
    "$\\varepsilon\\in]0,\\varepsilon_\\star[$,  \n",
    "\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)\n",
    "min_example=r\"\"\"\n",
    "\\[\n",
    "i\\colon [0,\\infty) \n",
    "\\]\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2251ce9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "min_example=r\"\"\"\n",
    "\\newcommand\\1{{\\mathds 1}}\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)\n",
    "# !! This bug was specific to my fork\n",
    "min_example=r\"\"\"\n",
    "\\newcommand{\\linebreakand}{%\n",
    "    \\end{@IEEEauthorhalign}\n",
    "    \\hfill\\mbox{}\\par\n",
    "    \\mbox{}\\hfill\\begin{@IEEEauthorhalign}\n",
    "    }\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)\n",
    "min_example=r\"\"\"\n",
    " $S \\subseteq \\{0\\} \\bigcup [1,\\infty) $ if $z^*_2=1$.  \n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)\n",
    "# two inline math envs next to eachother\n",
    "# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\n",
    "min_example=r\"\"\"\n",
    "$\\rm{W_{cyc} }\\geq 0$$\\;\\;\\square$\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)\n",
    "# \\verb{char}...{char} is also an issue for parser\n",
    "# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\n",
    "min_example=r\"\"\"\n",
    "\\verb+$TEXMF/tex/latex/elsevier/+, %$%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)\n",
    "# does not handle missing optional braces around arguments\n",
    "min_example=r\"\"\"\n",
    "$\\sqrt {\\frac 3 2} >p >1$\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)\n",
    "# \\verb{char}...{char} is also an issue for parser\n",
    "# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\n",
    "min_example=r\"\"\"\n",
    "&$\\rm{N_{Diskbb}}$$(\\times 10^4) $\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)\n",
    "# \\verb{char}...{char} is also an issue for parser\n",
    "# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\n",
    "min_example=r\"\"\"\n",
    "$\\frac{j+1+\\epsilon}{m^{\\alpha}}[$\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)\n",
    "# \\verb{char}...{char} is also an issue for parser\n",
    "# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\n",
    "min_example=r\"\"\"\n",
    "$1\\le k< \\frac n2 $ \n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)\n",
    "# \\verb{char}...{char} is also an issue for parser\n",
    "# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\n",
    "min_example=r\"\"\"\n",
    "\\begin{equation}\n",
    "\\begin{aligned}[t]\n",
    "[T\\tensor*[]{]}{_{\\CT}^{\\sp}} \\\\\n",
    "[T]{_{\\CT}^{\\sp}}\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\"\"\".strip()#.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example), tolerance=1)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071e937d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# \\verb{char}...{char} is also an issue for parser\n",
    "# !! probably not fixable given the approach used in TexSoup (needs stateful tokenization)\n",
    "with open('./data/test.txt', 'r') as infile:\n",
    "    min_example=infile.read().strip()\n",
    "\n",
    "TS.TexSoup(pre_format(min_example), tolerance=0)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa8b273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.DataFrame(np.random.randint(0,100,size=(10, 3)), columns=list('ABC')).to_csv('~/Expire/test_console_upload.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e5e1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
