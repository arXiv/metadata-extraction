{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete: 'Russia' replaced with 'Russian Federation'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"matching_data/ror_id.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Replace \"Russia\" with \"Russian Federation\" in the \"Country Name\" column\n",
    "df[\"Country Name\"] = df[\"Country Name\"].replace(\"Russia\", \"Russian Federation\")\n",
    "\n",
    "# Save the modified CSV\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"Preprocessing complete: 'Russia' replaced with 'Russian Federation'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1, exact matching only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching completed. Results saved to 'matching_data/matched_results.csv'.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Step 1: Read ror_id.csv and create the hashmap\n",
    "ror_map = {}\n",
    "\n",
    "with open('matching_data/ror_id.csv', mode='r', encoding='utf-8') as ror_file:\n",
    "    ror_reader = csv.DictReader(ror_file)\n",
    "    for row in ror_reader:\n",
    "        country = row['Country Name']\n",
    "        institution = row['Institution Name']\n",
    "        ror_id = row['ROR ID']\n",
    "        \n",
    "        if country not in ror_map:\n",
    "            ror_map[country] = {}\n",
    "        ror_map[country][institution] = ror_id\n",
    "\n",
    "# Step 2: Read scopus_id.csv and match ROR IDs\n",
    "matched_data = []\n",
    "\n",
    "with open('matching_data/scopus_id.csv', mode='r', encoding='utf-8') as scopus_file:\n",
    "    scopus_reader = csv.DictReader(scopus_file)\n",
    "    for row in scopus_reader:\n",
    "        country = row['Country Name']\n",
    "        primary_org = row['Primary Org Name']\n",
    "        scopus_id = row['Scopus ID']\n",
    "        \n",
    "        ror_id = None\n",
    "        if country in ror_map and primary_org in ror_map[country]:\n",
    "            ror_id = ror_map[country][primary_org]\n",
    "        \n",
    "        matched_data.append({\n",
    "            'Scopus ID': scopus_id,\n",
    "            'Primary Org Name': primary_org,\n",
    "            'Country Name': country,\n",
    "            'ROR ID': ror_id\n",
    "        })\n",
    "\n",
    "# Step 3: Save the matched data to a new CSV file\n",
    "with open('matching_data/matched_results.csv', mode='w', encoding='utf-8', newline='') as output_file:\n",
    "    fieldnames = ['Scopus ID', 'Primary Org Name', 'Country Name', 'ROR ID']\n",
    "    writer = csv.DictWriter(output_file, fieldnames=fieldnames)\n",
    "    \n",
    "    writer.writeheader()\n",
    "    for row in matched_data:\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(\"Matching completed. Results saved to 'matching_data/matched_results.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2, exact matching combined with elastic searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from fuzzywuzzy import process\n",
    "from tqdm import tqdm  # Import tqdm for progress bars\n",
    "\n",
    "# Step 1: Read ror_id.csv and create the hashmap\n",
    "ror_map = {}\n",
    "\n",
    "with open('matching_data/ror_id.csv', mode='r', encoding='utf-8') as ror_file:\n",
    "    ror_reader = csv.DictReader(ror_file)\n",
    "    for row in tqdm(ror_reader, desc=\"Reading ROR data\"):  # Add progress bar\n",
    "        country = row['Country Name']\n",
    "        institution = row['Institution Name']\n",
    "        ror_id = row['ROR ID']\n",
    "        \n",
    "        if country not in ror_map:\n",
    "            ror_map[country] = {}\n",
    "        ror_map[country][institution] = ror_id\n",
    "\n",
    "# Step 2: Read scopus_id.csv and match ROR IDs\n",
    "matched_data = []\n",
    "\n",
    "with open('matching_data/scopus_id.csv', mode='r', encoding='utf-8') as scopus_file:\n",
    "    scopus_reader = csv.DictReader(scopus_file)\n",
    "    for row in tqdm(scopus_reader, desc=\"Matching Scopus data\"):  # Add progress bar\n",
    "        country = row['Country Name']\n",
    "        primary_org = row['Primary Org Name']\n",
    "        scopus_id = row['Scopus ID']\n",
    "        \n",
    "        ror_id = None\n",
    "        if country in ror_map:\n",
    "            # Try exact match first\n",
    "            if primary_org in ror_map[country]:\n",
    "                ror_id = ror_map[country][primary_org]\n",
    "            else:\n",
    "                # If exact match fails, try fuzzy matching\n",
    "                choices = list(ror_map[country].keys())\n",
    "                best_match, score = process.extractOne(primary_org, choices)\n",
    "                print(best_match)\n",
    "                if score >= 80:  # You can adjust the threshold as needed\n",
    "                    ror_id = ror_map[country][best_match]\n",
    "        \n",
    "        matched_data.append({\n",
    "            'Scopus ID': scopus_id,\n",
    "            'Primary Org Name': primary_org,\n",
    "            'Country Name': country,\n",
    "            'ROR ID': ror_id\n",
    "        })\n",
    "\n",
    "# Step 3: Save the matched data to a new CSV file\n",
    "with open('matching_data/matched_results.csv', mode='w', encoding='utf-8', newline='') as output_file:\n",
    "    fieldnames = ['Scopus ID', 'Primary Org Name', 'Country Name', 'ROR ID']\n",
    "    writer = csv.DictWriter(output_file, fieldnames=fieldnames)\n",
    "    \n",
    "    writer.writeheader()\n",
    "    for row in tqdm(matched_data, desc=\"Writing results\"):  # Add progress bar\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(\"Matching completed. Results saved to 'matching_data/matched_results_elastic.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with empty ROR ID: 200\n",
      "Percentage of rows with empty ROR ID: 1.50%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"matching_data/matched_results_fuzzy.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Create a mask for rows where 'ROR ID' is empty (NaN or only whitespace)\n",
    "empty_mask = df[\"ROR ID\"].isna() | (df[\"ROR ID\"].astype(str).str.strip() == \"\")\n",
    "empty_count = empty_mask.sum()\n",
    "\n",
    "# Calculate the total number of rows\n",
    "total_rows = len(df)\n",
    "\n",
    "# Calculate the percentage of rows with empty ROR ID\n",
    "percentage_empty = (empty_count / total_rows * 100) if total_rows > 0 else 0\n",
    "\n",
    "print(\"Number of rows with empty ROR ID:\", empty_count)\n",
    "print(\"Percentage of rows with empty ROR ID: {:.2f}%\".format(percentage_empty))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arxiv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
