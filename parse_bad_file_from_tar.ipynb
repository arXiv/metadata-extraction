{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5385a6ff-0507-42ae-8ed7-090bc79688be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cf5d0dc-f846-4026-973f-fc35f5488c1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import zipfile\n",
    "import tarfile\n",
    "import io\n",
    "import importlib\n",
    "import os\n",
    "import regex as re\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9229d15f-0f9a-46fb-8de4-2e6bc4f31736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d172ce28-bd35-4aa2-b7e9-0566d744ae17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "# pretty print all cell's output and not just the last one\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80dbee31-8e2c-4401-be72-e403dac3885e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import TexSoup as TS\n",
    "#importlib.reload(TS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c3ebacc-89eb-454a-97c9-5068f77a0d71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LOCAL_DATA_PATH = './data/2201_samp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e5171153-1316-4310-9251-ee1627762470",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pre_format(text):\n",
    "    '''Apply some substititions to make LaTeX easier to parse'''\n",
    "    source_text = (\n",
    "        text\n",
    "        .replace('\\\\}\\\\', '\\\\} \\\\')  # Due to escape rules \\\\ is equivalent to \\\n",
    "        .replace(')}', ') }')\n",
    "        .replace(')$', ') $')\n",
    "    )\n",
    "    clean_lines = []\n",
    "    for line in source_text.splitlines(False):\n",
    "        cleanline = line.strip()\n",
    "        if cleanline.startswith(r'\\newcommand'):\n",
    "            cleanline = r'%' + cleanline\n",
    "        elif cleanline.startswith(r'\\def'):\n",
    "            cleanline = r'%' + cleanline\n",
    "        clean_lines.append(cleanline)\n",
    "    return '\\n'.join(clean_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6324bc82-02a7-4032-b3e5-de19e751be34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_doc_class(wrapped_file, name_match=False):\n",
    "    '''Search for document class related lines in a file  and return a code to represent the type'''\n",
    "    doc_class_pat = re.compile(r\"^\\s*\\\\document(?:style|class)\")\n",
    "    sub_doc_class = re.compile(r\"^\\s*\\\\document(?:style|class).*(?:\\{standalone\\}|\\{subfiles\\})\")\n",
    "\n",
    "    for line in wrapped_file:\n",
    "        if doc_class_pat.search(line):\n",
    "            if name_match:\n",
    "                # we can miss if there are two or more lines with documentclass \n",
    "                # and the first one is not the one that has standalone/subfile\n",
    "                if sub_doc_class.search(line):\n",
    "                    return -99999\n",
    "                return 1 #main_files[tf] = 1\n",
    "            \n",
    "    return 0 #main_files[tf] = 0\n",
    "\n",
    "\n",
    "def find_main_tex_source_in_tar(tar_path, encoding='uft-8'):\n",
    "    '''Identify the main Tex file in a tarfile.\n",
    "    \n",
    "    Args:\n",
    "        tar_path: A gzipped tar archive of a directory containing tex source and support files.\n",
    "    '''\n",
    "    \n",
    "    tex_names = set([\"paper.tex\", \"main.tex\", \"ms.tex\", \"article.tex\"])\n",
    "\n",
    "    with tarfile.open(tar_path, 'r') as in_tar:\n",
    "        tex_files = [f for f in in_tar.getnames() if f.endswith('.tex')]\n",
    "        \n",
    "        # got one file\n",
    "        if len(tex_files) == 1:\n",
    "            return tex_files[0]\n",
    "\n",
    "        main_files = {}\n",
    "        for tf in tex_files:\n",
    "            has_main_name = tf in tex_names\n",
    "            fp = in_tar.extractfile(tf)\n",
    "            wrapped_file = io.TextIOWrapper(fp, newline=None, encoding=encoding) #universal newlines\n",
    "            # does it have a doc class?\n",
    "            # get the type\n",
    "            main_files[tf] = find_doc_class(wrapped_file, name_match = has_main_name)\n",
    "            wrapped_file.close() \n",
    "        \n",
    "        # got one file with doc class\n",
    "        if len(main_files) == 1:\n",
    "            return(main_files.keys()[0])\n",
    "        \n",
    "        # account for multi-file submissions\n",
    "        return(max(main_files, key=main_files.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3ae8ad8b-8fdd-45f0-92c2-70075213f2d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def soup_from_tar(tar_path, encoding='utf-8'):\n",
    "    tex_main = find_main_tex_source_in_tar(tar_path, encoding=encoding)\n",
    "    with tarfile.open(tar_path, 'r') as in_tar:\n",
    "        fp = in_tar.extractfile(tex_main)\n",
    "        wrapped_file = io.TextIOWrapper(fp, newline=None, encoding=encoding) #universal newlines\n",
    "        source_text = pre_format(wrapped_file.read())\n",
    "        soup = TS.TexSoup(source_text)\n",
    "        return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5bcbf9-305b-41a7-b283-39562489fe7c",
   "metadata": {},
   "source": [
    "## Quick check a folder of tar files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "999be077-8fdc-48e3-bdd3-65563e0b6e76",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db01c65f98649bab7e137b8137f99fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "errors:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c45a9c818764f2b845f03447bb3bd03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = glob.glob(f'{LOCAL_DATA_PATH}/*.tar.gz')\n",
    "files_count = len(files)\n",
    "utf_count = 0\n",
    "latin_count = 0 \n",
    "err_files = {}\n",
    "\n",
    "with tqdm(total=files_count, desc=\"errors\") as err_prog:\n",
    "    for tar_file in tqdm(files, desc=\"Progress\", display=True):\n",
    "        # Is it unicode?\n",
    "        try:\n",
    "            soup = soup_from_tar(tar_file, encoding='utf-8')\n",
    "            utf_count += 1\n",
    "            continue\n",
    "        except EOFError as eof:\n",
    "            err_files[tar_file] = type(eof)\n",
    "            _ = err_prog.update(1)\n",
    "            continue\n",
    "        except UnicodeDecodeError as ue:\n",
    "            pass\n",
    "        except KeyboardInterrupt as KB_err:\n",
    "            break\n",
    "        except Exception as e:\n",
    "            err_files[tar_file] = type(e)\n",
    "            _ = err_prog.update(1)\n",
    "            continue\n",
    "\n",
    "        # Is it something else?\n",
    "        try:\n",
    "            soup = soup_from_tar(tar_file, encoding='latin-1')\n",
    "            latin_count += 1\n",
    "            continue\n",
    "        except KeyboardInterrupt as KB_err:\n",
    "            break\n",
    "        except Exception as e:\n",
    "            err_files[tar_file] = type(e)\n",
    "            _ = err_prog.update(1)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e4a830f1-7cfa-4f64-9a50-e2e911b2c9e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 processed, 4 failures.\n",
      "UTF8: 42; Latin1:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'./data/2201_samp/2201.00092v1.tar.gz': TypeError,\n",
       " './data/2201_samp/2201.00035v1.tar.gz': TypeError,\n",
       " './data/2201_samp/2201.00068v1.tar.gz': EOFError,\n",
       " './data/2201_samp/2201.00062v1.tar.gz': TypeError}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{files_count} processed, {len(err_files)} failures.\")\n",
    "print(f\"UTF8: {utf_count}; Latin1:{latin_count}\")\n",
    "err_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f912c4aa-6006-4051-86e7-906d18cc8041",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e8fd897e-8a1c-44e8-bda8-f59f39e30ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: ['Avoiding Catastrophe: Active Dendrites Enable Multi-Task Learning in Dynamic Environments']\n",
      " section: ['Introduction']\n",
      " section: ['Background']\n",
      " section: ['Active Dendrites Network Model']\n",
      " section: ['Results']\n",
      " section: ['Discussion']\n",
      " section: ['Methods']\n",
      " section: ['Understanding Parameters in the Model']\n",
      " section: ['Active Dendrites Network with a Fixed Number of Parameters']\n",
      " section: ['Number of Clusters Formed when Inferring Prototypes']\n"
     ]
    }
   ],
   "source": [
    "infile_path = \"./data/2201_samp/2201.00042v1.tar.gz\" #'./data/2201_samp/2201.00048v1.tar.gz'\n",
    "\n",
    "soup = soup_from_tar(infile_path)\n",
    "\n",
    "\n",
    "title = soup.find('title')\n",
    "print(f\"{title.name}: {title.text}\")\n",
    "for sec in soup.find_all('section'):\n",
    "    print(f' {sec.name}: {sec.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dcf6ba56-8143-418f-b8ff-6a341d3036c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tar_path = \"./data/2201_samp/2201.00008v2.tar.gz\"\n",
    "encoding = \"utf-8\"\n",
    "with tarfile.open(tar_path, 'r') as in_tar:\n",
    "    tex_files = [f for f in in_tar.getnames() if f.endswith('.tex')]\n",
    "\n",
    "    # got one file\n",
    "    if len(tex_files) == 1:\n",
    "        pass #return tex_files[0]\n",
    "\n",
    "    main_files = {}\n",
    "    for tf in tex_files:\n",
    "        fp = in_tar.extractfile(tf)\n",
    "        wrapped_file = io.TextIOWrapper(fp, newline=None, encoding=encoding) #universal newlines\n",
    "        # does it have a doc class?\n",
    "        # get the type\n",
    "        main_files[tf] = find_doc_class(wrapped_file)\n",
    "        wrapped_file.close() \n",
    "\n",
    "    # got one file with doc class\n",
    "    if len(main_files) == 1:\n",
    "        pass #return(main_files.keys()[0])\n",
    "\n",
    "    # account for multi-file submissions\n",
    "    #return(max(main_files, key=main_files.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "66887585-19d1-4123-b7f3-033669132321",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1_introduction.tex': 0,\n",
       " '2_related_work.tex': 0,\n",
       " '3_preliminary.tex': 0,\n",
       " '4_methodology.tex': 0,\n",
       " '5_evaluation.tex': 0,\n",
       " '6_case_study.tex': 0,\n",
       " '7_appendix.tex': 0,\n",
       " '7_conclusion.tex': 0,\n",
       " 'main.tex': 0}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3a976e7d-0b45-493c-a11a-332475a297ed",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\documentclass[10pt,journal,compsoc]{IEEEtran}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_class_pat = re.compile(r\"^\\s*\\\\document(?:style|class)\")\n",
    "\n",
    "with tarfile.open(tar_path, 'r', encoding='utf-8') as in_tar:\n",
    "    #in_tar.getnames()\n",
    "    fp = in_tar.extractfile('main.tex')\n",
    "    wrapped_file = io.TextIOWrapper(fp, newline=None, encoding='utf-8') #universal newlines\n",
    "    for line in wrapped_file:\n",
    "        if doc_class_pat.search(line):\n",
    "            print(line)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d91077a-6e59-4b2e-a18a-f6e42308260a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\usepackage{spconf,amsmath,graphicx,booktabs,multirow,float,amssymb,amsfonts,array}\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(wrapped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "daa1d579-88e1-4d9f-be77-efbf09f60e3e",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m fp:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(line)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/tarfile.py:696\u001b[0m, in \u001b[0;36m_FileInFile.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadinto\u001b[39m(\u001b[38;5;28mself\u001b[39m, b):\n\u001b[0;32m--> 696\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    697\u001b[0m     b[:\u001b[38;5;28mlen\u001b[39m(buf)] \u001b[38;5;241m=\u001b[39m buf\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buf)\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/tarfile.py:684\u001b[0m, in \u001b[0;36m_FileInFile.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    682\u001b[0m length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(size, stop \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition)\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[0;32m--> 684\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfileobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseek\u001b[49m\u001b[43m(\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    685\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfileobj\u001b[38;5;241m.\u001b[39mread(length)\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;241m!=\u001b[39m length:\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/gzip.py:392\u001b[0m, in \u001b[0;36mGzipFile.seek\u001b[0;34m(self, offset, whence)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\0\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m (count \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1024\u001b[39m))\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m READ:\n\u001b[0;32m--> 392\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_not_closed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer\u001b[38;5;241m.\u001b[39mseek(offset, whence)\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffset\n",
      "File \u001b[0;32m~/miniconda3/envs/cforge/lib/python3.10/_compression.py:14\u001b[0m, in \u001b[0;36mBaseStream._check_not_closed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_not_closed\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclosed:\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI/O operation on closed file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c8b266-bf93-4630-96cc-7df4384ea622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3537486a-b084-4984-ac94-98d7d57e8f12",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "7fc63084-89a4-4025-b281-37484cfe6f8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Discover the file list:\n",
    "input_zip = '2201.00007v1.zip'\n",
    "infile_path = os.path.join(LOCAL_DATA_PATH, input_zip)\n",
    "if True: #False:\n",
    "    with zipfile.ZipFile(infile_path, \"r\") as in_zip:\n",
    "        files = in_zip.infolist()\n",
    "        for file_info in files:\n",
    "            if not '/.' in file_info.filename:\n",
    "                print(file_info.filename)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "42c354ee-5fbf-4fdb-a9ae-5a6734811272",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "source": [
    "main_tex = '2201.00007v1/main.tex'\n",
    "with zipfile.ZipFile(infile_path, \"r\") as in_zip:\n",
    "    with in_zip.open('2201.00007v1/main.tex') as in_tex:\n",
    "        #print(in_tex.read())\n",
    "        wrapped_file = io.TextIOWrapper(in_tex, newline=None, encoding='utf-8') #universal newlines\n",
    "        source_text = pre_format(wrapped_file.read())\n",
    "        soup = TS.TexSoup(source_text)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f76d8f8a-1108-427d-8ba0-8929708576ef",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "source": [
    "title = soup.find('title')\n",
    "print(f\"{title.name}: {title.text}\")\n",
    "for sec in soup.find_all('section'):\n",
    "    print(f' {sec.name}: {sec.text}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9ee9c4d1-97a9-4f76-8766-3f44fe3d30a5",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\\documentclass{article}\n",
       "\\begin{document}\n",
       "% \\renewcommand{\\shorttitle}{Avoiding Catastrophe}\n",
       "\\end{document}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_example=r\"\"\"\n",
    "\\documentclass{article}\n",
    "\\begin{document}\n",
    "% \\renewcommand{\\shorttitle}{Avoiding Catastrophe}\n",
    "\\end{document}\n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "828170bf-8ecd-42d9-8d7a-72ea96882d76",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\\newcommand{\\bra}[1]{\\left\\langle#1\\right|}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TS.TexSoup(r'\\newcommand{\\bra}[1]{\\left\\langle#1\\right|}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30e9a622-30ec-494e-a74e-bc0bc3e71cda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\\def{\\}{be}{\\foo{equation}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TS.TexSoup(r'\\def\\be{\\foo{equation}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27395fa4-dafb-44c1-a1a6-9ef62e920672",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\\renewcommand{\\shorttitle}{Avoiding Catastrophe}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TS.TexSoup(r'\\renewcommand{\\shorttitle}{Avoiding Catastrophe}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257478aa-2037-49ef-8b70-d5cde86ad095",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "737d580c-1063-4beb-b86c-742533e87c7b",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\\documentclass{article}\n",
       "\\title{Foo}\n",
       "\n",
       "\\begin{document}\n",
       "\n",
       "\\renewcommand{\\shorttitle}{Avoiding Catastrophe}\n",
       "\n",
       "\\maketitle\n",
       "\n",
       "\\begin{abstract}\n",
       " A key challenge for AI is to build embodied systems.\n",
       "\\end{abstract}\n",
       "\n",
       "\\section{Introduction}\n",
       "\n",
       "Creating embodied systems that thrive in dynamically changing environments is a fundamental challenge for building intelligent systems. \n",
       "\n",
       "\\end{document}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_example=r\"\"\"\n",
    "\\documentclass{article}\n",
    "\\title{Foo}\n",
    "\n",
    "\\begin{document}\n",
    "\n",
    "\\renewcommand{\\shorttitle}{Avoiding Catastrophe}\n",
    "\n",
    "\\maketitle\n",
    "\n",
    "\\begin{abstract}\n",
    " A key challenge for AI is to build embodied systems.\n",
    "\\end{abstract}\n",
    "\n",
    "\\section{Introduction}\n",
    "\n",
    "Creating embodied systems that thrive in dynamically changing environments is a fundamental challenge for building intelligent systems. \n",
    "\n",
    "\\end{document}\n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "#TS.TexSoup(pre_format(min_example))\n",
    "TS.TexSoup(min_example)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2c5821fc-c981-4408-a05c-5f5f0f02094f",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\documentclass{article}\n",
      "\\title{Foo}\n",
      "\n",
      "\\begin{document}\n",
      "\n",
      "%\\renewcommand{\\shorttitle}{Avoiding Catastrophe}\n",
      "\n",
      "\\maketitle\n",
      "\n",
      "\\begin{abstract}\n",
      "A key challenge for AI is to build embodied systems.\n",
      "\\end{abstract}\n",
      "\n",
      "\\section{Introduction}\n",
      "\n",
      "Creating embodied systems that thrive in dynamically changing environments is a fundamental challenge for building intelligent systems.\n",
      "\n",
      "\\end{document}\n"
     ]
    }
   ],
   "source": [
    "print(pre_format(min_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4658922-e3ad-4407-b85b-a28a49778c4c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
