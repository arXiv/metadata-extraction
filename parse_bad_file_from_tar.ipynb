{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5385a6ff-0507-42ae-8ed7-090bc79688be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cf5d0dc-f846-4026-973f-fc35f5488c1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import zipfile\n",
    "import tarfile\n",
    "import io\n",
    "import importlib\n",
    "import os\n",
    "import regex as re\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9229d15f-0f9a-46fb-8de4-2e6bc4f31736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d172ce28-bd35-4aa2-b7e9-0566d744ae17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "# pretty print all cell's output and not just the last one\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80dbee31-8e2c-4401-be72-e403dac3885e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import TexSoup as TS\n",
    "#importlib.reload(TS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c3ebacc-89eb-454a-97c9-5068f77a0d71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LOCAL_DATA_PATH = './data/2201_samp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5171153-1316-4310-9251-ee1627762470",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pre_format(text):\n",
    "    '''Apply some substititions to make LaTeX easier to parse'''\n",
    "    source_text = (\n",
    "        text\n",
    "        .replace('\\\\}\\\\', '\\\\} \\\\')  # Due to escape rules \\\\ is equivalent to \\\n",
    "        .replace(')}', ') }')\n",
    "        .replace(')$', ') $')\n",
    "    )\n",
    "    return source_text\n",
    "    #clean_lines = []\n",
    "    #for line in source_text.splitlines(False):\n",
    "    #    cleanline = line.strip()\n",
    "    #    if cleanline.startswith(r'\\newcommand'):\n",
    "    #        cleanline = r'%' + cleanline\n",
    "    #    elif cleanline.startswith(r'\\def'):\n",
    "    #        cleanline = r'%' + cleanline\n",
    "    #    clean_lines.append(cleanline)\n",
    "    #return '\\n'.join(clean_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6324bc82-02a7-4032-b3e5-de19e751be34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_doc_class(wrapped_file, name_match=False):\n",
    "    '''Search for document class related lines in a file  and return a code to represent the type'''\n",
    "    doc_class_pat = re.compile(r\"^\\s*\\\\document(?:style|class)\")\n",
    "    sub_doc_class = re.compile(r\"^\\s*\\\\document(?:style|class).*(?:\\{standalone\\}|\\{subfiles\\})\")\n",
    "\n",
    "    for line in wrapped_file:\n",
    "        if doc_class_pat.search(line):\n",
    "            if name_match:\n",
    "                # we can miss if there are two or more lines with documentclass \n",
    "                # and the first one is not the one that has standalone/subfile\n",
    "                if sub_doc_class.search(line):\n",
    "                    return -99999\n",
    "                return 1 #main_files[tf] = 1\n",
    "            \n",
    "    return 0 #main_files[tf] = 0\n",
    "\n",
    "\n",
    "def find_main_tex_source_in_tar(tar_path, encoding='uft-8'):\n",
    "    '''Identify the main Tex file in a tarfile.\n",
    "    \n",
    "    Args:\n",
    "        tar_path: A gzipped tar archive of a directory containing tex source and support files.\n",
    "    '''\n",
    "    \n",
    "    tex_names = set([\"paper.tex\", \"main.tex\", \"ms.tex\", \"article.tex\"])\n",
    "\n",
    "    with tarfile.open(tar_path, 'r') as in_tar:\n",
    "        tex_files = [f for f in in_tar.getnames() if f.endswith('.tex')]\n",
    "        \n",
    "        # got one file\n",
    "        if len(tex_files) == 1:\n",
    "            return tex_files[0]\n",
    "\n",
    "        main_files = {}\n",
    "        for tf in tex_files:\n",
    "            has_main_name = tf in tex_names\n",
    "            fp = in_tar.extractfile(tf)\n",
    "            wrapped_file = io.TextIOWrapper(fp, newline=None, encoding=encoding) #universal newlines\n",
    "            # does it have a doc class?\n",
    "            # get the type\n",
    "            main_files[tf] = find_doc_class(wrapped_file, name_match = has_main_name)\n",
    "            wrapped_file.close() \n",
    "        \n",
    "        # got one file with doc class\n",
    "        if len(main_files) == 1:\n",
    "            return(main_files.keys()[0])\n",
    "        \n",
    "        # account for multi-file submissions\n",
    "        return(max(main_files, key=main_files.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ae8ad8b-8fdd-45f0-92c2-70075213f2d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def soup_from_tar(tar_path, encoding='utf-8'):\n",
    "    tex_main = find_main_tex_source_in_tar(tar_path, encoding=encoding)\n",
    "    with tarfile.open(tar_path, 'r') as in_tar:\n",
    "        fp = in_tar.extractfile(tex_main)\n",
    "        wrapped_file = io.TextIOWrapper(fp, newline=None, encoding=encoding) #universal newlines\n",
    "        source_text = pre_format(wrapped_file.read())\n",
    "        soup = TS.TexSoup(source_text)\n",
    "        return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5bcbf9-305b-41a7-b283-39562489fe7c",
   "metadata": {},
   "source": [
    "## Quick check a folder of tar files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "999be077-8fdc-48e3-bdd3-65563e0b6e76",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c801e9fdb6e4745ac0ce93916f394e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "errors:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ef8595012f74d90b4da7e1cf0f8e67d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = glob.glob(f'{LOCAL_DATA_PATH}/*.tar.gz')\n",
    "files_count = len(files)\n",
    "utf_count = 0\n",
    "latin_count = 0 \n",
    "err_files = {}\n",
    "\n",
    "with tqdm(total=files_count, desc=\"errors\") as err_prog:\n",
    "    for tar_file in tqdm(files, desc=\"Progress\", display=True):\n",
    "        # Is it unicode?\n",
    "        try:\n",
    "            soup = soup_from_tar(tar_file, encoding='utf-8')\n",
    "            utf_count += 1\n",
    "            continue\n",
    "        except EOFError as eof:\n",
    "            err_files[tar_file] = type(eof)\n",
    "            _ = err_prog.update(1)\n",
    "            continue\n",
    "        except UnicodeDecodeError as ue:\n",
    "            pass\n",
    "        except KeyboardInterrupt as KB_err:\n",
    "            break\n",
    "        except Exception as e:\n",
    "            err_files[tar_file] = type(e)\n",
    "            _ = err_prog.update(1)\n",
    "            continue\n",
    "\n",
    "        # Is it something else?\n",
    "        try:\n",
    "            soup = soup_from_tar(tar_file, encoding='latin-1')\n",
    "            latin_count += 1\n",
    "            continue\n",
    "        except KeyboardInterrupt as KB_err:\n",
    "            break\n",
    "        except Exception as e:\n",
    "            err_files[tar_file] = type(e)\n",
    "            _ = err_prog.update(1)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4a830f1-7cfa-4f64-9a50-e2e911b2c9e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 processed, 21 failures.\n",
      "UTF8: 25; Latin1: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'./data/2201_samp/2201.00048v1.tar.gz': EOFError,\n",
       " './data/2201_samp/2201.00092v1.tar.gz': TypeError,\n",
       " './data/2201_samp/2201.00042v1.tar.gz': AssertionError,\n",
       " './data/2201_samp/2201.00091v2.tar.gz': TypeError,\n",
       " './data/2201_samp/2201.00035v1.tar.gz': TypeError,\n",
       " './data/2201_samp/2201.00082v1.tar.gz': TypeError,\n",
       " './data/2201_samp/2201.00058v1.tar.gz': AssertionError,\n",
       " './data/2201_samp/2201.00065v2.tar.gz': EOFError,\n",
       " './data/2201_samp/2201.00070v1.tar.gz': EOFError,\n",
       " './data/2201_samp/2201.00045v1.tar.gz': AssertionError,\n",
       " './data/2201_samp/2201.00044v1.tar.gz': EOFError,\n",
       " './data/2201_samp/2201.00056v1.tar.gz': AssertionError,\n",
       " './data/2201_samp/2201.00068v1.tar.gz': AssertionError,\n",
       " './data/2201_samp/2201.00087v1.tar.gz': EOFError,\n",
       " './data/2201_samp/2201.00062v1.tar.gz': EOFError,\n",
       " './data/2201_samp/2201.00036v1.tar.gz': TypeError,\n",
       " './data/2201_samp/2201.00091v1.tar.gz': TypeError,\n",
       " './data/2201_samp/2201.00078v1.tar.gz': AssertionError,\n",
       " './data/2201_samp/2201.00072v1.tar.gz': TypeError,\n",
       " './data/2201_samp/2201.00073v1.tar.gz': AssertionError,\n",
       " './data/2201_samp/2201.00065v1.tar.gz': EOFError}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{files_count} processed, {len(err_files)} failures.\")\n",
    "print(f\"UTF8: {utf_count}; Latin1: {latin_count}\")\n",
    "err_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e85ffb-2596-412a-9cfb-8ef432a52c67",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "source": [
    "## Scratch below here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fd897e-8a1c-44e8-bda8-f59f39e30ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "infile_path = \"./data/2201_samp/2201.00092v1.tar.gz\" #'./data/2201_samp/2201.00048v1.tar.gz'\n",
    "\n",
    "soup = soup_from_tar(infile_path)\n",
    "\n",
    "\n",
    "title = soup.find('title')\n",
    "print(f\"{title.name}: {title.text}\")\n",
    "for sec in soup.find_all('section'):\n",
    "    print(f' {sec.name}: {sec.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf6ba56-8143-418f-b8ff-6a341d3036c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tar_path = \"./data/2201_samp/2201.00008v2.tar.gz\"\n",
    "encoding = \"utf-8\"\n",
    "with tarfile.open(tar_path, 'r') as in_tar:\n",
    "    tex_files = [f for f in in_tar.getnames() if f.endswith('.tex')]\n",
    "\n",
    "    # got one file\n",
    "    if len(tex_files) == 1:\n",
    "        pass #return tex_files[0]\n",
    "\n",
    "    main_files = {}\n",
    "    for tf in tex_files:\n",
    "        fp = in_tar.extractfile(tf)\n",
    "        wrapped_file = io.TextIOWrapper(fp, newline=None, encoding=encoding) #universal newlines\n",
    "        # does it have a doc class?\n",
    "        # get the type\n",
    "        main_files[tf] = find_doc_class(wrapped_file)\n",
    "        wrapped_file.close() \n",
    "\n",
    "    # got one file with doc class\n",
    "    if len(main_files) == 1:\n",
    "        pass #return(main_files.keys()[0])\n",
    "\n",
    "    # account for multi-file submissions\n",
    "    #return(max(main_files, key=main_files.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66887585-19d1-4123-b7f3-033669132321",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a976e7d-0b45-493c-a11a-332475a297ed",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc_class_pat = re.compile(r\"^\\s*\\\\document(?:style|class)\")\n",
    "\n",
    "with tarfile.open(tar_path, 'r', encoding='utf-8') as in_tar:\n",
    "    #in_tar.getnames()\n",
    "    fp = in_tar.extractfile('main.tex')\n",
    "    wrapped_file = io.TextIOWrapper(fp, newline=None, encoding='utf-8') #universal newlines\n",
    "    for line in wrapped_file:\n",
    "        if doc_class_pat.search(line):\n",
    "            print(line)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d91077a-6e59-4b2e-a18a-f6e42308260a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "next(wrapped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa1d579-88e1-4d9f-be77-efbf09f60e3e",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c8b266-bf93-4630-96cc-7df4384ea622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3537486a-b084-4984-ac94-98d7d57e8f12",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "7fc63084-89a4-4025-b281-37484cfe6f8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Discover the file list:\n",
    "input_zip = '2201.00007v1.zip'\n",
    "infile_path = os.path.join(LOCAL_DATA_PATH, input_zip)\n",
    "if True: #False:\n",
    "    with zipfile.ZipFile(infile_path, \"r\") as in_zip:\n",
    "        files = in_zip.infolist()\n",
    "        for file_info in files:\n",
    "            if not '/.' in file_info.filename:\n",
    "                print(file_info.filename)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "42c354ee-5fbf-4fdb-a9ae-5a6734811272",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "source": [
    "main_tex = '2201.00007v1/main.tex'\n",
    "with zipfile.ZipFile(infile_path, \"r\") as in_zip:\n",
    "    with in_zip.open('2201.00007v1/main.tex') as in_tex:\n",
    "        #print(in_tex.read())\n",
    "        wrapped_file = io.TextIOWrapper(in_tex, newline=None, encoding='utf-8') #universal newlines\n",
    "        source_text = pre_format(wrapped_file.read())\n",
    "        soup = TS.TexSoup(source_text)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f76d8f8a-1108-427d-8ba0-8929708576ef",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "source": [
    "title = soup.find('title')\n",
    "print(f\"{title.name}: {title.text}\")\n",
    "for sec in soup.find_all('section'):\n",
    "    print(f' {sec.name}: {sec.text}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee9c4d1-97a9-4f76-8766-3f44fe3d30a5",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_example=r\"\"\"\n",
    "\\documentclass{article}\n",
    "\\begin{document}\n",
    "% \\renewcommand{\\shorttitle}{Avoiding Catastrophe}\n",
    "\\end{document}\n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828170bf-8ecd-42d9-8d7a-72ea96882d76",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "TS.TexSoup(r'\\newcommand{\\bra}[1]{\\left\\langle#1\\right|}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e9a622-30ec-494e-a74e-bc0bc3e71cda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TS.TexSoup(r'\\def\\be{\\foo{equation}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27395fa4-dafb-44c1-a1a6-9ef62e920672",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "TS.TexSoup(r'\\renewcommand{\\shorttitle}{Avoiding Catastrophe}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257478aa-2037-49ef-8b70-d5cde86ad095",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "r\"In practice, the matrix $\\left [\\M{D}^{(1)}_n(\\M{D}^{(1)}_n)\\Tra\\right]\\Inv\\M{D}^{(1)}_n$\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737d580c-1063-4beb-b86c-742533e87c7b",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_example=r\"\"\"\n",
    "In practice, the matrix $\\left[\\M{D}^{(1)}_n(\\M{D}^{(1)}_n)\\Tra\\right]\\Inv\\M{D}^{(1)}_n$ \n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "#TS.TexSoup(min_example)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5821fc-c981-4408-a05c-5f5f0f02094f",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(pre_format(min_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4658922-e3ad-4407-b85b-a28a49778c4c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
