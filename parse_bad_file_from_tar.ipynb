{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e9d79f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6776ae91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import zipfile\n",
    "import tarfile\n",
    "import io\n",
    "import importlib\n",
    "import os\n",
    "import regex as re\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a31b0f74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c96c6bea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "# pretty print all cell's output and not just the last one\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa85bc9c",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import TexSoup as TS\n",
    "#importlib.reload(TS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4bc952",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ad953ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LOCAL_DATA_PATH = './data/2201_01_all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6c6f45f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pre_format(text):\n",
    "    '''Apply some substititions to make LaTeX easier to parse'''\n",
    "    source_text = (\n",
    "        text\n",
    "        .replace('\\\\}\\\\', '\\\\} \\\\')  # Due to escape rules \\\\ is equivalent to \\\n",
    "        .replace(')}', ') }')\n",
    "        .replace(')$', ') $')\n",
    "    )\n",
    "    return source_text\n",
    "    #clean_lines = []\n",
    "    #for line in source_text.splitlines(False):\n",
    "    #    cleanline = line.strip()\n",
    "    #    if cleanline.startswith(r'\\newcommand'):\n",
    "    #        cleanline = r'%' + cleanline\n",
    "    #    elif cleanline.startswith(r'\\def'):\n",
    "    #        cleanline = r'%' + cleanline\n",
    "    #    clean_lines.append(cleanline)\n",
    "    #return '\\n'.join(clean_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b6c40d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_doc_class(wrapped_file, name_match=False):\n",
    "    '''Search for document class related lines in a file  and return a code to represent the type'''\n",
    "    doc_class_pat = re.compile(r\"^\\s*\\\\document(?:style|class)\")\n",
    "    sub_doc_class = re.compile(r\"^\\s*\\\\document(?:style|class).*(?:\\{standalone\\}|\\{subfiles\\})\")\n",
    "\n",
    "    for line in wrapped_file:\n",
    "        if doc_class_pat.search(line):\n",
    "            if name_match:\n",
    "                # we can miss if there are two or more lines with documentclass \n",
    "                # and the first one is not the one that has standalone/subfile\n",
    "                if sub_doc_class.search(line):\n",
    "                    return -99999\n",
    "                return 1 #main_files[tf] = 1\n",
    "            \n",
    "    return 0 #main_files[tf] = 0\n",
    "\n",
    "\n",
    "def find_main_tex_source_in_tar(tar_path, encoding='uft-8'):\n",
    "    '''Identify the main Tex file in a tarfile.\n",
    "    \n",
    "    Args:\n",
    "        tar_path: A gzipped tar archive of a directory containing tex source and support files.\n",
    "    '''\n",
    "    \n",
    "    tex_names = set([\"paper.tex\", \"main.tex\", \"ms.tex\", \"article.tex\"])\n",
    "\n",
    "    with tarfile.open(tar_path, 'r') as in_tar:\n",
    "        tex_files = [f for f in in_tar.getnames() if f.endswith('.tex')]\n",
    "        \n",
    "        # got one file\n",
    "        if len(tex_files) == 1:\n",
    "            return tex_files[0]\n",
    "\n",
    "        main_files = {}\n",
    "        for tf in tex_files:\n",
    "            has_main_name = tf in tex_names\n",
    "            fp = in_tar.extractfile(tf)\n",
    "            wrapped_file = io.TextIOWrapper(fp, newline=None, encoding=encoding) #universal newlines\n",
    "            # does it have a doc class?\n",
    "            # get the type\n",
    "            main_files[tf] = find_doc_class(wrapped_file, name_match = has_main_name)\n",
    "            wrapped_file.close() \n",
    "        \n",
    "        # got one file with doc class\n",
    "        if len(main_files) == 1:\n",
    "            return(main_files.keys()[0])\n",
    "        \n",
    "        # account for multi-file submissions\n",
    "        return(max(main_files, key=main_files.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f74f5f8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "MATH_ENV_NAMES = (\n",
    "    'align', 'align*', 'alignat', 'array', 'displaymath', 'eqnarray',\n",
    "    'eqnarray*', 'equation', 'equation*', 'flalign', 'flalign*', 'gather',\n",
    "    'gather*', 'math', 'multline', 'multline*', 'split'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7260efbb-ee02-4a73-878a-cc754831f9d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def soup_from_tar(tar_path, encoding='utf-8', tolerance=0):\n",
    "    tex_main = find_main_tex_source_in_tar(tar_path, encoding=encoding)\n",
    "    with tarfile.open(tar_path, 'r') as in_tar:\n",
    "        fp = in_tar.extractfile(tex_main)\n",
    "        wrapped_file = io.TextIOWrapper(fp, newline=None, encoding=encoding) #universal newlines\n",
    "        source_text = pre_format(wrapped_file.read())\n",
    "        soup = TS.TexSoup(source_text, tolerance=tolerance, skip_envs=MATH_ENV_NAMES)\n",
    "        return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3660fe45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def source_from_tar(tar_path, encoding='utf-8'):\n",
    "    tex_main = find_main_tex_source_in_tar(tar_path, encoding=encoding)\n",
    "    with tarfile.open(tar_path, 'r') as in_tar:\n",
    "        fp = in_tar.extractfile(tex_main)\n",
    "        wrapped_file = io.TextIOWrapper(fp, newline=None, encoding=encoding) #universal newlines\n",
    "        source_text = pre_format(wrapped_file.read())\n",
    "        return source_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faedf1be",
   "metadata": {},
   "source": [
    "## Quick check a folder of tar files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "703ee32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/2201_01_all/*.tar.gz'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(LOCAL_DATA_PATH, '*.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9701452d-b517-4d9c-b974-404088cfedd4",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = glob.glob(f'{LOCAL_DATA_PATH}/*.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6060d5b0-827d-4c49-969c-03e14731f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_files = {}\n",
    "if 'err_files' in locals():\n",
    "    if err_files: print('\\n'.join(err_files.keys()))\n",
    "    files = \"\"\"\n",
    "        ./data/2201_01_all/2201.01576v2.tar.gz\n",
    "        ./data/2201_01_all/2201.01664v2.tar.gz\n",
    "        ./data/2201_01_all/2201.01050v1.tar.gz\n",
    "        ./data/2201_01_all/2201.01445v1.tar.gz\n",
    "        ./data/2201_01_all/2201.01073v1.tar.gz\n",
    "        ./data/2201_01_all/2201.01782v1.tar.gz\n",
    "        ./data/2201_01_all/2201.01576v1.tar.gz\n",
    "        ./data/2201_01_all/2201.01647v3.tar.gz\n",
    "        ./data/2201_01_all/2201.01207v1.tar.gz\n",
    "        ./data/2201_01_all/2201.01664v1.tar.gz\n",
    "        ./data/2201_01_all/2201.01980v1.tar.gz\n",
    "        ./data/2201_01_all/2201.01445v2.tar.gz\n",
    "    \"\"\".strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53967567-e068-4576-83e7-110efbf02e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fab9ec2b-73da-4d37-875b-49efd352e552",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf5af82b5b7453382b36694fced40ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "errors:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b00e6214ac4297b029b39ed6de88ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files_count = len(files)\n",
    "utf_count = 0\n",
    "latin_count = 0 \n",
    "err_files = {}\n",
    "\n",
    "TOLERANCE = 1\n",
    "\n",
    "with tqdm(total=files_count, desc=\"errors\") as err_prog:\n",
    "    for tar_file in tqdm(files, desc=\"Progress\", display=True):\n",
    "        # Is it unicode?\n",
    "        try:\n",
    "            soup = soup_from_tar(tar_file, encoding='utf-8', tolerance=TOLERANCE)\n",
    "            utf_count += 1\n",
    "            continue\n",
    "        except EOFError as eof:\n",
    "            err_files[tar_file] = type(eof)\n",
    "            _ = err_prog.update(1)\n",
    "            continue\n",
    "        except UnicodeDecodeError as ue:\n",
    "            pass\n",
    "        except KeyboardInterrupt as KB_err:\n",
    "            break\n",
    "        except Exception as e:\n",
    "            err_files[tar_file] = type(e)\n",
    "            _ = err_prog.update(1)\n",
    "            continue\n",
    "\n",
    "        # Is it something else?\n",
    "        try:\n",
    "            soup = soup_from_tar(tar_file, encoding='latin-1', tolerance=TOLERANCE)\n",
    "            latin_count += 1\n",
    "            continue\n",
    "        except KeyboardInterrupt as KB_err:\n",
    "            break\n",
    "        except Exception as e:\n",
    "            err_files[tar_file] = type(e)\n",
    "            _ = err_prog.update(1)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e0d99c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 processed, 8 failures.\n",
      "UTF8: 4; Latin1: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'./data/2201_01_all/2201.01576v2.tar.gz': AssertionError,\n",
       " './data/2201_01_all/2201.01664v2.tar.gz': AssertionError,\n",
       " './data/2201_01_all/2201.01050v1.tar.gz': AssertionError,\n",
       " './data/2201_01_all/2201.01576v1.tar.gz': AssertionError,\n",
       " './data/2201_01_all/2201.01647v3.tar.gz': AssertionError,\n",
       " './data/2201_01_all/2201.01207v1.tar.gz': AssertionError,\n",
       " './data/2201_01_all/2201.01664v1.tar.gz': AssertionError,\n",
       " './data/2201_01_all/2201.01980v1.tar.gz': AssertionError}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{files_count} processed, {len(err_files)} failures.\")\n",
    "print(f\"UTF8: {utf_count}; Latin1: {latin_count}\")\n",
    "err_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af707602",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "source": [
    "## Scratch below here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ac4681",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "infile_path = \"./data/2201_samp/2201.00092v1.tar.gz\" #'./data/2201_samp/2201.00048v1.tar.gz'\n",
    "\n",
    "text = source_from_tar(infile_path)\n",
    "soup = soup_from_tar(infile_path)\n",
    "\n",
    "title = soup.find('title')\n",
    "print(f\"{title.name}: {title.text}\")\n",
    "for sec in soup.find_all('section'):\n",
    "    print(f' {sec.name}: {sec.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4850dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc52381a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ab4196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tar_path = \"./data/2201_samp/2201.00008v2.tar.gz\"\n",
    "encoding = \"utf-8\"\n",
    "with tarfile.open(tar_path, 'r') as in_tar:\n",
    "    tex_files = [f for f in in_tar.getnames() if f.endswith('.tex')]\n",
    "\n",
    "    # got one file\n",
    "    if len(tex_files) == 1:\n",
    "        pass #return tex_files[0]\n",
    "\n",
    "    main_files = {}\n",
    "    for tf in tex_files:\n",
    "        fp = in_tar.extractfile(tf)\n",
    "        wrapped_file = io.TextIOWrapper(fp, newline=None, encoding=encoding) #universal newlines\n",
    "        # does it have a doc class?\n",
    "        # get the type\n",
    "        main_files[tf] = find_doc_class(wrapped_file)\n",
    "        wrapped_file.close() \n",
    "\n",
    "    # got one file with doc class\n",
    "    if len(main_files) == 1:\n",
    "        pass #return(main_files.keys()[0])\n",
    "\n",
    "    # account for multi-file submissions\n",
    "    #return(max(main_files, key=main_files.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef200b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf9248d",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc_class_pat = re.compile(r\"^\\s*\\\\document(?:style|class)\")\n",
    "\n",
    "with tarfile.open(tar_path, 'r', encoding='utf-8') as in_tar:\n",
    "    #in_tar.getnames()\n",
    "    fp = in_tar.extractfile('main.tex')\n",
    "    wrapped_file = io.TextIOWrapper(fp, newline=None, encoding='utf-8') #universal newlines\n",
    "    for line in wrapped_file:\n",
    "        if doc_class_pat.search(line):\n",
    "            print(line)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e186b2d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "next(wrapped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e17e72",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904c42bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795c5ab9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "14f6920d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Discover the file list:\n",
    "input_zip = '2201.00007v1.zip'\n",
    "infile_path = os.path.join(LOCAL_DATA_PATH, input_zip)\n",
    "if True: #False:\n",
    "    with zipfile.ZipFile(infile_path, \"r\") as in_zip:\n",
    "        files = in_zip.infolist()\n",
    "        for file_info in files:\n",
    "            if not '/.' in file_info.filename:\n",
    "                print(file_info.filename)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0c7eac7",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "source": [
    "main_tex = '2201.00007v1/main.tex'\n",
    "with zipfile.ZipFile(infile_path, \"r\") as in_zip:\n",
    "    with in_zip.open('2201.00007v1/main.tex') as in_tex:\n",
    "        #print(in_tex.read())\n",
    "        wrapped_file = io.TextIOWrapper(in_tex, newline=None, encoding='utf-8') #universal newlines\n",
    "        source_text = pre_format(wrapped_file.read())\n",
    "        soup = TS.TexSoup(source_text)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c30e921",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "source": [
    "title = soup.find('title')\n",
    "print(f\"{title.name}: {title.text}\")\n",
    "for sec in soup.find_all('section'):\n",
    "    print(f' {sec.name}: {sec.text}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43095243",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_example=r\"\"\"\n",
    "\\documentclass{article}\n",
    "\\begin{document}\n",
    "% \\renewcommand{\\shorttitle}{Avoiding Catastrophe}\n",
    "\\end{document}\n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eca66d",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "TS.TexSoup(r'\\newcommand{\\bra}[1]{\\left\\langle#1\\right|}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dc53e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TS.TexSoup(r'\\def\\be{\\foo{equation}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e522f276",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "TS.TexSoup(r'\\renewcommand{\\shorttitle}{Avoiding Catastrophe}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc29642",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "r\"In practice, the matrix $\\left [\\M{D}^{(1)}_n(\\M{D}^{(1)}_n)\\Tra\\right]\\Inv\\M{D}^{(1)}_n$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eb0c43",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "In practice, the matrix $\\left [\\M{D}^{(1) }_n(\\M{D}^{(1) }_n)\\Tra\\right]\\Inv\\M{D}^{(1) }_n$ is pre-computed and cached for repeated use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65258321",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_example=r\"\"\"\n",
    "$\\left [\\M{D}^{(1) }_n(\\M{D}^{(1) }_n)\\Tra \\right] $\n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "#TS.TexSoup(min_example)\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2ca778",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(pre_format(min_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3bfcb2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89af4ff",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_example=r\"\"\"\n",
    "\\documentclass{article}\n",
    "\\begin{document}\n",
    "\\catcode\\day\\month\n",
    "\\end{document}\n",
    "\"\"\".strip() #.replace('\\\\}\\\\', '\\\\} \\\\').replace(')}', ') }')\n",
    "TS.TexSoup(pre_format(min_example))\n",
    "#print(min_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8658d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TS.TexSoup(r'\\renewcommand{\\shorttitle}{Avoiding Catastrophe}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7422a592",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.14.4"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
